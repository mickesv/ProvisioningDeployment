<!DOCTYPE html>
<html>
<!-- Created by GNU Texinfo 7.0.3, https://www.gnu.org/software/texinfo/ -->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<!-- This is part of a course on Applied Cloud Computing and Big Data, offered by Blekinge Institute of Technology. Version 1.0

Copyright © 2023 Mikael Svahnberg, Mikael.Svahnberg@bth.se

MIT License

Copyright (c) 2023 Mikael Svahnberg

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
 -->
<title>Provisioning and Deployment</title>

<meta name="description" content="Provisioning and Deployment">
<meta name="keywords" content="Provisioning and Deployment">
<meta name="resource-type" content="document">
<meta name="distribution" content="global">
<meta name="Generator" content="texi2any">
<meta name="viewport" content="width=device-width,initial-scale=1">

<link href="#Top" rel="start" title="Top">
<link href="#Concept-Index" rel="index" title="Concept Index">
<link href="#SEC_Contents" rel="contents" title="Table of Contents">
<link href="#Document-Overview" rel="next" title="Document Overview">
<style type="text/css">
<!--
a.summary-letter-printindex {text-decoration: none}
div.example {margin-left: 3.2em}
td.printindex-index-entry {vertical-align: top}
td.printindex-index-section {vertical-align: top}
th.entries-header-printindex {text-align:left}
th.sections-header-printindex {text-align:left}
ul.mark-bullet {list-style-type: disc}
ul.toc-numbered-mark {list-style: none}
-->
</style>


</head>

<body lang="en">




<div class="top-level-extent" id="Top">
<div class="nav-panel">
<p>
Next: <a href="#Document-Overview" accesskey="n" rel="next">Document Overview</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h1 class="top" id="Provisioning-and-Deployment">Provisioning and Deployment</h1>


<p>This is part of a course on Applied Cloud Computing and Big Data, offered by Blekinge Institute of Technology. Version 1.0
</p>
<p>Copyright &copy; 2023 Mikael Svahnberg, Mikael.Svahnberg@bth.se
</p>
<blockquote class="quotation">
<p>MIT License
</p>
<p>Copyright (c) 2023 Mikael Svahnberg
</p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the &ldquo;Software&rdquo;), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:
</p>
<p>The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
</p>
<p>THE SOFTWARE IS PROVIDED &ldquo;AS IS&rdquo;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</p>
</blockquote>

<p>Version 1.0:
This is part of a course on Applied Cloud Computing and Big Data, offered by Blekinge Institute of Technology.
This document introduces and provides a study track through the material for the two parts:
</p><ul class="itemize mark-bullet">
<li>Cloud Provisioning and Deployment
</li><li>The Business Case for Cloud Computing
</li></ul>

<p>Copyright © 2023 Mikael Svahnberg, Mikael.Svahnberg@bth.se
</p>

<div class="element-contents" id="SEC_Contents">
<h2 class="contents-heading">Table of Contents</h2>

<div class="contents">

<ul class="toc-numbered-mark">
  <li><a id="toc-Document-Overview-1" href="#Document-Overview">1 Document Overview</a></li>
  <li><a id="toc-A-Note-on-Reading-Research-Articles-1" href="#A-Note-on-Reading-Research-Articles">2 A Note on Reading Research Articles</a></li>
  <li><a id="toc-Introduction-to-Orchestration-and-Provisioning-1" href="#Introduction-to-Orchestration-and-Provisioning">3 Introduction to Orchestration and Provisioning</a>
  <ul class="toc-numbered-mark">
    <li><a id="toc-Learning-Outcomes-1" href="#Learning-Outcomes">3.1 Learning Outcomes</a></li>
  </ul></li>
  <li><a id="toc-Microservices-and-Lightweight-Containers-1" href="#Microservices-and-Lightweight-Containers">4 Microservices and Lightweight Containers</a>
  <ul class="toc-numbered-mark">
    <li><a id="toc-Building-Microservices-1" href="#Building-Microservices">4.1 Building Microservices</a></li>
    <li><a id="toc-A-Quick-Rundown-of-Docker-Terminology-1" href="#A-Quick-Rundown-of-Docker-Terminology">4.2 A Quick Rundown of Docker Terminology</a></li>
    <li><a id="toc-Dockerfile-1" href="#Dockerfile">4.3 Dockerfile</a></li>
    <li><a id="toc-Docker-Commands-1" href="#Docker-Commands">4.4 Docker Commands</a></li>
    <li><a id="toc-Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service-1" href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service">4.5 Not Building Microservices &ndash; Infrastructure As A Service</a></li>
    <li><a id="toc-Provisioning-your-Virtual-Machine-1" href="#Provisioning-your-Virtual-Machine">4.6 Provisioning your Virtual Machine</a></li>
    <li><a id="toc-Communicating-Microservices-and-REST-APIs-1" href="#Communicating-Microservices-and-REST-APIs">4.7 Communicating Microservices and REST APIs</a></li>
    <li><a id="toc-Other-communication-means-1" href="#Other-communication-means">4.8 Other communication means</a></li>
  </ul></li>
  <li><a id="toc-Quiz_003a-Hypervisors-and-Lightweight-Virtual-Machines" href="#Quiz-Hypervisors-and-Lightweight-Virtual-Machines">5 Quiz: Hypervisors and Lightweight Virtual Machines</a></li>
  <li><a id="toc-Let_0027s-get-Practical-1" href="#Let_0027s-get-Practical">6 Let&rsquo;s get Practical</a>
  <ul class="toc-numbered-mark">
    <li><a id="toc-Introducing-the-QuoteFinder-application-1" href="#Introducing-the-QuoteFinder-application">6.1 Introducing the QuoteFinder application</a></li>
    <li><a id="toc-Install-relevant-software-1" href="#Install-relevant-software">6.2 Install relevant software</a></li>
    <li><a id="toc-Installing-and-Running-QFStandalone-1" href="#Installing-and-Running-QFStandalone">6.3 Installing and Running QFStandalone</a></li>
    <li><a id="toc-A-Minimal-Qemu-Vagrantfile-1" href="#A-Minimal-Qemu-Vagrantfile">6.4 A Minimal Qemu Vagrantfile</a></li>
  </ul></li>
  <li><a id="toc-Quiz_003a-Let_0027s-get-Practical" href="#Quiz-Let_0027s-get-Practical">7 Quiz: Let&rsquo;s get Practical</a></li>
  <li><a id="toc-Provisioning-and-Orchestration-1" href="#Provisioning-and-Orchestration">8 Provisioning and Orchestration</a>
  <ul class="toc-numbered-mark">
    <li><a id="toc-Provisioning-1" href="#Provisioning">8.1 Provisioning</a></li>
    <li><a id="toc-Orchestration-1" href="#Orchestration">8.2 Orchestration</a></li>
    <li><a id="toc-Docker-Compose-1" href="#Docker-Compose">8.3 Docker Compose</a></li>
    <li><a id="toc-Cloud-Orchestration-1" href="#Cloud-Orchestration">8.4 Cloud Orchestration</a></li>
  </ul></li>
  <li><a id="toc-Quiz_003a-Provisioning-and-Orchestration" href="#Quiz-Provisioning-and-Orchestration">9 Quiz: Provisioning and Orchestration</a></li>
  <li><a id="toc-Application-Design-and-Development-1" href="#Application-Design-and-Development">10 Application Design and Development</a>
  <ul class="toc-numbered-mark">
    <li><a id="toc-Principles-of-Microservice-Architectures-1" href="#Principles-of-Microservice-Architectures">10.1 Principles of Microservice Architectures</a></li>
    <li><a id="toc-Cloud-Architecture-Patterns-1" href="#Cloud-Architecture-Patterns">10.2 Cloud Architecture Patterns</a></li>
    <li><a id="toc-Introduction-to-YAML-and-Docker_002dCompose_002eyml" href="#Introduction-to-YAML-and-Docker_002dComposeyml">10.3 Introduction to YAML and Docker-Compose.yml</a></li>
  </ul></li>
  <li><a id="toc-Let_0027s-get-Practical-Again-1" href="#Let_0027s-get-Practical-Again">11 Let&rsquo;s get Practical Again</a>
  <ul class="toc-numbered-mark">
    <li><a id="toc-Introducing-Version-2-of-the-QuoteFinder-app-1" href="#Introducing-Version-2-of-the-QuoteFinder-app">11.1 Introducing Version 2 of the QuoteFinder app</a></li>
    <li><a id="toc-Installing-and-Running-Version-2-of-QuoteFinder-1" href="#Installing-and-Running-Version-2-of-QuoteFinder">11.2 Installing and Running Version 2 of QuoteFinder</a></li>
    <li><a id="toc-Editing-the-Running-Application-1" href="#Editing-the-Running-Application">11.3 Editing the Running Application</a></li>
    <li><a id="toc-Scaling-the-Deployment-1" href="#Scaling-the-Deployment">11.4 Scaling the Deployment</a></li>
    <li><a id="toc-Cleanup-and-Summary-1" href="#Cleanup-and-Summary">11.5 Cleanup and Summary</a></li>
    <li><a id="toc-Introducing-Version-3-of-the-QuoteFinder-app-1" href="#Introducing-Version-3-of-the-QuoteFinder-app">11.6 Introducing Version 3 of the QuoteFinder app</a></li>
  </ul></li>
  <li><a id="toc-Quiz_003a-Design-Decisions-and-Development-Setup" href="#Quiz-Design-Decisions-and-Development-Setup">12 Quiz: Design Decisions and Development Setup</a></li>
  <li><a id="toc-Deployment-with-Kubernetes-1" href="#Deployment-with-Kubernetes">13 Deployment with Kubernetes</a>
  <ul class="toc-numbered-mark">
    <li><a id="toc-Introduction-to-Kubernetes-1" href="#Introduction-to-Kubernetes">13.1 Introduction to Kubernetes</a></li>
    <li><a id="toc-Get-Started-with-Kubernetes-1" href="#Get-Started-with-Kubernetes">13.2 Get Started with Kubernetes</a></li>
    <li><a id="toc-Attach-the-Database-1" href="#Attach-the-Database">13.3 Attach the Database</a></li>
  </ul></li>
  <li><a id="toc-Quiz_003a-Deployment-with-Kubernetes" href="#Quiz-Deployment-with-Kubernetes">14 Quiz: Deployment with Kubernetes</a></li>
  <li><a id="toc-Scaling-the-Database-1" href="#Scaling-the-Database">15 Scaling the Database</a>
  <ul class="toc-numbered-mark">
    <li><a id="toc-Database-Scaling-1" href="#Database-Scaling">15.1 Database Scaling</a></li>
    <li><a id="toc-MongoDB-ReplicaSet-1" href="#MongoDB-ReplicaSet">15.2 MongoDB ReplicaSet</a></li>
    <li><a id="toc-Setting-up-a-MongoDB-ReplicaSet-in-Kubernetes-1" href="#Setting-up-a-MongoDB-ReplicaSet-in-Kubernetes">15.3 Setting up a MongoDB ReplicaSet in Kubernetes</a></li>
  </ul></li>
  <li><a id="toc-Edit-a-Container-in-a-Pod-in-a-Node-in-a-Cluster-1" href="#Edit-a-Container-in-a-Pod-in-a-Node-in-a-Cluster">16 Edit a Container in a Pod in a Node in a Cluster</a></li>
  <li><a id="toc-Additional-Concepts-1" href="#Additional-Concepts">17 Additional Concepts</a></li>
  <li><a id="toc-Summary-1" href="#Summary">18 Summary</a></li>
  <li><a id="toc-Assignment_003a-Build-Something" href="#Assignment-Build-Something">19 Assignment: Build Something</a></li>
  <li><a id="toc-Concept-Index-1" href="#Concept-Index" rel="index">Concept Index</a></li>
  <li><a id="toc-Program-Index-1" href="#Program-Index" rel="index">Program Index</a></li>
  <li><a id="toc-Files-and-Data-Types-Index-1" href="#Files-and-Data-Types-Index" rel="index">Files and Data Types Index</a></li>
  <li><a id="toc-Functions-and-Commands-Index-1" href="#Functions-and-Commands-Index" rel="index">Functions and Commands Index</a></li>
</ul>
</div>
</div>
<hr>
<div class="chapter-level-extent" id="Document-Overview">
<div class="nav-panel">
<p>
Next: <a href="#A-Note-on-Reading-Research-Articles" accesskey="n" rel="next">A Note on Reading Research Articles</a>, Previous: <a href="#Top" accesskey="p" rel="prev">Provisioning and Deployment</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Document-Overview-1">1 Document Overview</h2>

<p>The course Applied Cloud Computing and Big Data is a 7.5 ECTS course offered by Blekinge Institute of Technology. The course is organised around three themes, and all three themes must be completed to complete the course:
</p>
<ul class="itemize mark-bullet">
<li>Cloud Provisioning and Deployment
</li><li>The Business Case for Cloud Computing
</li><li>Big Data Analytics
</li></ul>

<p>The course is divided across two source code repositories:
</p>
<ul class="itemize mark-bullet">
<li><a class="uref" href="https://github.com/mickesv/ProvisioningDeployment.git">https://github.com/mickesv/ProvisioningDeployment.git</a> contains the instructions and source code for the Cloud Provisioning and Deployment, and the Business Case for Cloud Computing parts of the course.
</li><li><a class="uref" href="https://github.com/mickesv/BigDataAnalytics.git">https://github.com/mickesv/BigDataAnalytics.git</a> contains the instructions and source code for the Big Data Analytics part of the course.
</li></ul>

<p>This document covers the first two of these themes, i.e. Cloud Provisioning and Deployment, and The Business Case for Cloud Computing. The document is structured as a series of introductions to different topics mixed with hands-on tasks to exercise these topics. 
</p>
<p>The topic introductions and practical exercises are further punctuated by quizzes that (a) serve as checkpoints of important concepts that have been covered to that point, but also (b) introduce further reading material to deepen your understanding of the cloud computing business case. <strong class="strong">These quizzes are not marked</strong>, but serve as a learning aid; for you to summarise what you have learnt so far, and for us to keep track of your progress through the material.
</p>
<p>The two themes are examined through a final assignment (See <a class="ref" href="#assignment_002dbuild_002dsomething">assignment-build-something</a> ), where you put what you have learnt so far into practice.
</p>
<p>This document is available in different formats:
</p>
<ul class="itemize mark-bullet">
<li>as web pages on the course platform
</li><li>as a pdf file
</li><li>as a TeXInfo tutorial
</li></ul>

<p>The TeXInfo tutorial may require a bit more introduction. Access this version e.g. through the command <code class="code">info Provisioning-Deployment</code> or in your favourite editor though <code class="code">C-u C-h i Provisioning-Deployment.info</code> . Basic navigation in the document is done with the following keys (try <code class="code">info info</code> for more details and further key commands):
</p>
<ul class="itemize mark-bullet">
<li>&lt;spc&gt; (space) scroll forward 
</li><li>&rsquo;b&rsquo; Beginning of current node
</li><li>&rsquo;e&rsquo; End of current node
</li><li>&rsquo;n&rsquo; Next node
</li><li>&rsquo;p&rsquo; Previous node
</li><li>&rsquo;u&rsquo; Up (usually (but not always) to the top index page) 
</li><li>&lt;enter&gt; on a cross reference to open it.
</li></ul>

<hr>
</div>
<div class="chapter-level-extent" id="A-Note-on-Reading-Research-Articles">
<div class="nav-panel">
<p>
Next: <a href="#Introduction-to-Orchestration-and-Provisioning" accesskey="n" rel="next">Introduction to Orchestration and Provisioning</a>, Previous: <a href="#Document-Overview" accesskey="p" rel="prev">Document Overview</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="A-Note-on-Reading-Research-Articles-1">2 A Note on Reading Research Articles</h2>

<p>This course may suggest research articles for you to read. This may seem a daunting task for you, but there are some general guidelines that may help you:
</p>
<ul class="itemize mark-bullet">
<li>Start by reading the abstract and the conclusions. These will tell you what problem or area the article is addressing, and what the article contributed to solving the problem.
</li><li>The articles in this course have &ndash; to a large extent &ndash; been chosen because they summarise the topics in various ways. To find these summaries, look for <em class="emph">lists, figures, and tables</em> in the article. Read these. Read the text around them, or where the figures and tables were referenced, in order to get an explanation of how to interpret them.
</li></ul>


<p>Generally, interpret each section of an article as follows:
</p>
<ul class="itemize mark-bullet">
<li>The <em class="emph">introduction</em> section in an article puts the problem into context, and might give you clues as to how other researchers have solved it before. You can use this section to get a generic overview.
</li><li>The <em class="emph">related work</em> section should discuss in further detail what other researchers have done that is similar to, or relates to, the article you are reading. This may give you an idea of how others have addressed the problem, and may give you pointers to other articles that you would wish to read.
</li><li>The <em class="emph">methodology</em> section explains how the study was conducted. Once an article is published (which they naturally are in this course), this is mostly interesting if you distrust some of the results and want to see if anything has been missed when constructing the study.
</li><li>The <em class="emph">execution and results</em> sections describe how the study was executed (in particular discrepancies from the planned methodology), and what the raw results were. Most of the time, you can safely skip these sections.
</li><li>The <em class="emph">analysis</em> section &ldquo;bakes&rdquo; the results and tries to answer the research questions (address the identified problem). This is probably the most interesting section for you to read.
</li><li>The <em class="emph">discussion</em> section should raise the view and try to see what the results actually mean in a bigger context. What can you do with the results? &ldquo;So what?&rdquo;. This is a tricky section to read, since the authors want you to believe that their results are the best thing invented since hot porridge, but at the same time they have to identify threats to the validity of the study. Validity threats are things that could have influenced the results instead of the sought after effect. This may be things that happened at the same time, inadequacies in the researchers skills and abilities, or inadequacies in the research design. Please remember, when (or if) reading this section, that most of the identified validity threats are minor obstacles (or the article would not have been published) that may impact the scientific view of the results more than the practical significance or usefulness of them.
</li><li>The <em class="emph">references</em> may give you ideas for other articles that you would like to read.
</li></ul>

<p>The bottom line is that when being told to read a lot of research articles, the trick is to learn how to not read them while still getting the gist of them. Hopefully, the &ldquo;map&rdquo; described above may provide some help in identifying the parts of an article that are important for you.
</p>
<hr>
</div>
<div class="chapter-level-extent" id="Introduction-to-Orchestration-and-Provisioning">
<div class="nav-panel">
<p>
Next: <a href="#Microservices-and-Lightweight-Containers" accesskey="n" rel="next">Microservices and Lightweight Containers</a>, Previous: <a href="#A-Note-on-Reading-Research-Articles" accesskey="p" rel="prev">A Note on Reading Research Articles</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Introduction-to-Orchestration-and-Provisioning-1">3 Introduction to Orchestration and Provisioning</h2>

<a class="anchor" id="introduction"></a>
<p>A vital part of making the best use of cloud resources is to have a controllable way to set up your cloud environment. Ironically, a large part of this consists of <em class="emph">not</em> using cloud resources but rather configure a transparent way to set up a local development environment, a potentially local test environment, and the production environment. The goal is to be able to do this with the same command(s) and to make sure that all environments are similarly configured.
</p>
<p>You may be used to develop applications in your local development environment. From within this environment you will run and debug your application. You may even have set up automated tests to run as well. There are some challenges with this, however:
</p>
<ul class="itemize mark-bullet">
<li>Your development computer needs to remain very stable. If you install some new software or run some update, you can no longer be sure that the application will actually continue to run. Even if it still works on your machine, there is no guarantee that it will also work on the customers&rsquo; machine.
</li></ul>

<a class="index-entry-id" id="index-Configuration-Management"></a>
<ul class="itemize mark-bullet">
<li>When you start working on a new feature branch, your machine is indeed tainted by everything you have developed and tested before. Partially, this is what you have your configuration management system for: You would go back to the main branch and create your new feature branch from there. Technically, this <em class="emph">should</em> remove everything else you have been doing so that you start from the same page every time. In practice, the settings in your development environment is not affected by what you do with the configuration management tool, your stack of installed software is not affected, and if you use a database it will merrily continue with whatever test data you had in there just before.
</li></ul>

<a class="index-entry-id" id="index-Deployment"></a>
<ul class="itemize mark-bullet">
<li>When you are ready to deploy your application (of course you have already tested it?) , you first need to set this server up and make sure that it is installed and setup in exactly the same way as your development machine. And then you deploy. And say a prayer. And hope that no users try to use your application while you are figuring out what went wrong.
</li></ul>

<a class="index-entry-id" id="index-Redeployment"></a>
<ul class="itemize mark-bullet">
<li>As time goes, you ever so often log in to the server with your running application to install updates, fix minor errors, and upgrade your application. Until things have gone horribly wrong and you need to start from scratch again, and you realise that you have not maintained an updated lab notebook with all the things you have ever done on the server. Things that you have already fixed once re-appear and you have to fix them again. And again.
</li></ul>

<a class="index-entry-id" id="index-Deployment-Environments"></a>
<p>This brings us back to the overall goal. What you want is a controllable and repeatable way to set up your machines. Controllable, so that you can decide whether you want a development-version (Where perhaps your application is running with debug flags turned on), a test-version (that contains a reasonable subset of all the data in the live system and where tests for different environments are launched automatically) , or a running production version of your system (that you really have no business ever editing directly, and maybe never need to edit directly since it is deployed automatically as soon as all tests are run).
</p>
<a class="index-entry-id" id="index-Repeatable-Deployment"></a>
<p>You want the setup to be <em class="emph">repeatable</em> so that you will always start from the same page, no matter what. Basically, you want to banish even the idea that it is ok to log in to a running environment to change things. If you want to introduce changes, you change the repeatable scripts, test them, and then push them to the rest of the project for common use. Now, <em class="emph">anyone</em> in the project can create the exact same environment as you have, and test your code under exactly the same conditions.
</p>
<a class="index-entry-id" id="index-Configuration-Managed-Deployments"></a>
<p>Today, you would not even dream of working in a larger development project without having some form of configuration management support. You create feature development branches, merge features into testing branches, which eventually are merged into a main branch. Your automated tests are treated in the same way; The test code may even be part of the same commits as the application code. By creating scripts for your deployments, you now have the ability to put these too under configuration management. No more guesswork about which version of framework &ldquo;frobnicator&rdquo; that was launched together with version 1.3.42 of your application &ndash; it&rsquo;s in the setup scripts.
</p>
<p><strong class="strong">Summary</strong>
<a class="index-entry-id" id="index-Goal-_002d_002d-a-Controllable-and-Repeatable-Deployment"></a>
<a class="index-entry-id" id="index-Ultimate-Goal-_002d_002d-Deploy-Application-to-a-Cloud-Server"></a>
The <em class="emph">ultimate</em> goal remains to be able to deploy your application to a cloud server somewhere. But the <em class="emph">path to get there</em> require you to spend time and effort to set up a repeatable foundation to develop locally. As always, by laying a proper foundation it is much easier to reach the end goal.
</p>
<p>In this part of the course we are thus going to be looking at different ways of setting up local development in a controllable and repeatable way. We are going to look into different types of deployments (e.g. microservices or infrastructure-as-a-service), and different types of deployment targets (local, test, production).
</p>
<p>We are going to do this through a combination of theoretical knowledge and practical exercises. The practical exercises will allow you to try out different tools for creating different types of deployments.
</p>
<a class="index-entry-id" id="index-Command_002dLine-Interface"></a>
<p><strong class="strong">A word of warning</strong> There are many tools to master, and each of them use their own language. We are going to be working in a console (Command Prompt, terminal, xterm, or whatever your operating system provides) using the command line interfaces of these tools. The reason for this is that we want to create a solution that can be combined into a bigger scripted solution, and this is simply not possible if you are expected to intervene and point-and-click your way to a solution.
</p>
<div class="example">
<pre class="example-preformatted">

     +-----------------------------+
     | WARNING                     |
     |                             |
     |     Unix-commands ahead     |
     |                             |
     +--------------+--------------+       
                    |                      
--------------------+-----------------------
    /    |     \    |
   /            \   |
  /      |       \  |
 /                \ |
</pre></div>


<ul class="mini-toc">
<li><a href="#Learning-Outcomes" accesskey="1">Learning Outcomes</a></li>
</ul>
<hr>
<div class="section-level-extent" id="Learning-Outcomes">
<div class="nav-panel">
<p>
Up: <a href="#Introduction-to-Orchestration-and-Provisioning" accesskey="u" rel="up">Introduction to Orchestration and Provisioning</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Learning-Outcomes-1">3.1 Learning Outcomes</h3>

<a class="index-entry-id" id="index-Learning-Outcomes"></a>
<a class="index-entry-id" id="index-Course-Syllabus"></a>
<p>Relevant learning outcomes from the course syllabus are:
</p>
<p><strong class="strong">Knowledge and understanding</strong> On completion of the course, the student will be able to
</p><ul class="itemize mark-bullet">
<li>In depth be able to describe different types of cloud platforms
</li><li>In depth be able to describe different reasons for adopting a cloud solution, and the challenges with these different reasons.
</li><li>In depth be able to reason about solutions to the common challenges with the cloud solutions.
</li></ul>

<p><strong class="strong">Competence and skills</strong> On completion of the course, the student will be able to:
</p><ul class="itemize mark-bullet">
<li>Independently be able to set up a development environment consisting of local machine configurations and cloud based servers.
</li></ul>

<p><strong class="strong">Judgement and approach</strong> On completion of the course, the student will be able to:
</p><ul class="itemize mark-bullet">
<li>Be able to evaluate different reasons for choosing a cloud solution and select a suitable solution accordingly accordingly.
</li></ul>

<hr>
</div>
</div>
<div class="chapter-level-extent" id="Microservices-and-Lightweight-Containers">
<div class="nav-panel">
<p>
Next: <a href="#Quiz-Hypervisors-and-Lightweight-Virtual-Machines" accesskey="n" rel="next">Quiz: Hypervisors and Lightweight Virtual Machines</a>, Previous: <a href="#Introduction-to-Orchestration-and-Provisioning" accesskey="p" rel="prev">Introduction to Orchestration and Provisioning</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Microservices-and-Lightweight-Containers-1">4 Microservices and Lightweight Containers</h2>

<p>As applications grow, it becomes more and more difficult to understand all of them at once. The programming solution is to divide the application into components, where each component has well defined responsibilities and interfaces. Component-based software engineering and code modularisation (and &ndash; as it is most often used &ndash; object oriented software development) is an answer to the need for smaller, more manageable parts of a larger system. However, ultimately, the main reason for this type of modularisation is <em class="emph">development</em> needs.
</p>
<a class="index-entry-id" id="index-Software-Architecture-Conceptual-View"></a>
<a class="index-entry-id" id="index-Software-Architecture-Module-View"></a>
<a class="index-entry-id" id="index-Software-Architecture-Execution-View"></a>
<p>Going further down the rabbit hole of software architectures, we do see that there are other reasons for modularisation. One often discuss different viewpoints of a software architecture (which &ndash; just like UML &ndash; has its origins in P. Kruchten &ldquo;The 4+ 1 view model of architecture.&rdquo; <em class="emph">IEEE software</em> 12.6 (1995): 42-50. ), with a <em class="emph">conceptual view</em> to understand what to build, a <em class="emph">module view</em> to understand how to structure it while building, and an <em class="emph">execution view</em> to understand the threads, processes, processors, memory, and shared memory required in order to run the system. These are not created in isolation; the module view in particular need to reflect both the conceptual view as well as the execution view in order to build the right execution targets so that the application can be properly deployed.
</p>
<p>Thus: as an application grows in size and complexity, there is a need to structure it into modules for the sake of conceptual understanding and for the sake of scalability.
</p>
<a class="index-entry-id" id="index-Client-Server-Software-Architecture"></a>
<p>Some types of execution modularisation is probably already familiar to you. You have probably heard of <em class="emph">client-server architectures</em>, and you have probably built systems using an external database. If you are unlucky, you may have developed multi-threaded applications.
</p>
<a class="index-entry-id" id="index-Microservice-Architecture"></a>
<p><em class="emph">Microservice architectures</em> is an attempt to simplify development. On an architecture level, it is an attempt to settle on a single type of interface between the different conceptual components (usually a <a class="ref" href="#Communicating-Microservices-and-REST-APIs">REST API</a>), align the execution of an application with its conceptual view, and defer creation of the module view to each individual component/executable. Of course, this works less well in practice because one still wish to re-use components between the different microservices but that&rsquo;s another story.
</p>
<p>One more benefit (some would argue it is the main benefit) is that there is no longer any need for multi-threaded programming. Each microservice can (and perhaps even should be) as single-threaded as possible. If one needs to scale the application this is done as part of the deployment rather than with the help of logic inside the application. This creates a <em class="emph">separation of concern</em> between application logic and deployment logic which is highly sought after.
</p>
<p>Another benefit is that each microservice can be written in the way and language best suited for its particular responsibility. Some may use a particular framework that dictate how to structure the code, others may be written in some high performance language, and others again may consist of a simple stringing together of a couple of Unix commands.
</p>
<a class="index-entry-id" id="index-Governance"></a>
<p>A third benefit is that with the separation between application logic and deployment logic it is easy to attach monitors to each microservice to gauge e.g. whether it is running, healthy, or overloaded. Logs can be created and inspected within each microservice, and temporary or permanent storage may be attached to each microservice.
</p>

<ul class="mini-toc">
<li><a href="#Building-Microservices" accesskey="1">Building Microservices</a></li>
<li><a href="#A-Quick-Rundown-of-Docker-Terminology" accesskey="2">A Quick Rundown of Docker Terminology</a></li>
<li><a href="#Dockerfile" accesskey="3">Dockerfile</a></li>
<li><a href="#Docker-Commands" accesskey="4">Docker Commands</a></li>
<li><a href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service" accesskey="5">Not Building Microservices &ndash; Infrastructure As A Service</a></li>
<li><a href="#Provisioning-your-Virtual-Machine" accesskey="6">Provisioning your Virtual Machine</a></li>
<li><a href="#Communicating-Microservices-and-REST-APIs" accesskey="7">Communicating Microservices and REST APIs</a></li>
<li><a href="#Other-communication-means" accesskey="8">Other communication means</a></li>
</ul>
<hr>
<div class="section-level-extent" id="Building-Microservices">
<div class="nav-panel">
<p>
Next: <a href="#A-Quick-Rundown-of-Docker-Terminology" accesskey="n" rel="next">A Quick Rundown of Docker Terminology</a>, Up: <a href="#Microservices-and-Lightweight-Containers" accesskey="u" rel="up">Microservices and Lightweight Containers</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Building-Microservices-1">4.1 Building Microservices</h3>

<p>What do we then need to do in order to build our application as a collection of collaborating microservices?
</p>
<p>In the most basic level, we simply build our application as a collection of executables. We launch each executable as a separate process, and have some mechanism to communicate between the processes (e.g. sockets, remote procedure calls, pipes, file system, or through the database). Challenges are that we still have to start and connect all the different parts of our system when running, and we need to build the logic ourselves to scale up or down. If we want to scale one part of our application by starting more processes of the same type, we need to manage the logic for this. If we want to &ldquo;scale out&rdquo; to another machine, we need to implement and manage the logic for this. If one process writes to a particular file, all other processes are directly influenced by this, and need to have logic implemented to avoid conflicts.
</p>
<a class="index-entry-id" id="index-chroot"></a>
<p>Next level up, at least on UNIX systems, is through &lsquo;<samp class="samp">chroot</samp>&rsquo;. Through this program we basically &ldquo;sandbox&rdquo; the file system for a particular process so that we can have separate parts of our disk allocated to different processes (called a &ldquo;chroot jail&rdquo; ). Within this new root environment we can install tools only needed for this particular process. We can also have separate sections of our disk for e.g. testing environments and development environments, and we can isolate all dependencies from one process to only that which is available within its particular chroot jail.
</p>
<p>&lsquo;<samp class="samp">chroot</samp>&rsquo; is old, it was created in 1979, and as computers became more powerful it started to be used as a lightweight virtualisation. There are, however, some considerable limitations. For the sake of this course, the most major limitation is that any logic surrounding the use of chroot &ndash; scaling, inter process communication, etc. &ndash; still has to be implemented by the developers of the application. Shirley there&rsquo;s an app to help with that!
</p>
<a class="index-entry-id" id="index-LXC-Linux-Containers"></a>
<a class="index-entry-id" id="index-Docker"></a>
<a class="index-entry-id" id="index-Podman"></a>
<a class="index-entry-id" id="index-Container"></a>
<p>As it happens, there are applications for this. You may have heard about Docker <a class="uref" href="https://www.docker.com/">https://www.docker.com/</a> or its open source cousin Podman <a class="uref" href="https://podman.io/">https://podman.io/</a> . Both of these are examples of Linux Containers (LXC), which are usually described as &ldquo;Lightweight virtual machines&rdquo;. With tools like these you create a <em class="emph">Container</em> with a specific set of programs installed, and then you can manage this container as a whole, rather than having to keep track of each individual part inside. 
</p>
<a class="index-entry-id" id="index-Responsibility_002dDriven-Design"></a>
<p>This container essentially consist of two things: (a) The software needed to run your microservice, and (b) your microservice, and the idea is to keep both of these as small as possible. Do not expect a full user experience from the software stack in a container, be prepared to fight with <code class="code">sh</code> rather than something slightly easier to use like <code class="code">bash</code>. As for the microservice that you deploy in the container, try to maintain a strict responsibility-driven design: If you want to give a container two responsibilities then consider splitting it into two containers.
</p>
<hr>
</div>
<div class="section-level-extent" id="A-Quick-Rundown-of-Docker-Terminology">
<div class="nav-panel">
<p>
Next: <a href="#Dockerfile" accesskey="n" rel="next">Dockerfile</a>, Previous: <a href="#Building-Microservices" accesskey="p" rel="prev">Building Microservices</a>, Up: <a href="#Microservices-and-Lightweight-Containers" accesskey="u" rel="up">Microservices and Lightweight Containers</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="A-Quick-Rundown-of-Docker-Terminology-1">4.2 A Quick Rundown of Docker Terminology</h3>

<a class="index-entry-id" id="index-Dockerfile"></a>
<p>When working with Docker you start with a <code class="code">Dockerfile</code> . Each line in this Dockerfile creates a <code class="code">Layer</code>, and Docker will try to be smart about caching these layers so that if you re-use your Dockerfile it will start from the last layer that is the same as one it has previously built.
</p>
<a class="index-entry-id" id="index-Docker-Hub-1"></a>
<a class="index-entry-id" id="index-Docker-Hub"></a>
<p>Based on this Dockerfile you create an <code class="code">Image</code> . This is a snapshot in time from when all the lines in the Dockerfile have been executed. You can version control and tag this image if you like, and it is this image that you will push to Docker hub <a class="uref" href="https://hub.docker.com/">https://hub.docker.com/</a> . If you are using a ready-made container from Docker hub, e.g. with a database or a web server installed , it is this image that will be downloaded and used as a layer in your own Docker image.
</p>
<p>When you start your Container, it will use the image as a base and execute the <code class="code">ENTRYPOINT</code> in the Dockerfile, which is the command and its parameters that should be used to start your microservice. You now have your running Container.
</p>
<div class="example">
<pre class="example-preformatted">                    (/-/---------\-\)
                     \  Docker hub /
                      -\         /-
                        ---------   
                            ^ 
                            |
                            v 
+--------------+     +--------------+     +--------------+
| Dockerfile   |     | Image        |     | Container    |
|              | --&gt; |              | --&gt; |              |
|              |     |              |     |              |
|              |     |              |     |              |
+--------------+     +--------------+     +--------------+
| ENTRYPOINT   |                                 ^
+------+-------+                                 |
       +-----------------------------------------+

</pre></div>

<hr>
</div>
<div class="section-level-extent" id="Dockerfile">
<div class="nav-panel">
<p>
Next: <a href="#Docker-Commands" accesskey="n" rel="next">Docker Commands</a>, Previous: <a href="#A-Quick-Rundown-of-Docker-Terminology" accesskey="p" rel="prev">A Quick Rundown of Docker Terminology</a>, Up: <a href="#Microservices-and-Lightweight-Containers" accesskey="u" rel="up">Microservices and Lightweight Containers</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Dockerfile-1">4.3 Dockerfile</h3>

<p>Typically, a Dockerfile will contain at least the following commands (Most of which can appear more than once):
</p>
<a class="index-entry-id" id="index-Docker-FROM"></a>
<p><code class="code">FROM</code> to specify which image to use as a base for the container. This can either be an image you have created yourself, or a ready-made image from Docker hub. Example: <code class="code">FROM node:18-alpine</code> says that you want to use an image that has node.js version 18 installed on top of an Alpine Linux install (which is a lightweight Linux distribution, more than which you probably do not need).
</p>
<a class="index-entry-id" id="index-Docker-RUN"></a>
<a class="index-entry-id" id="index-nodemon"></a>
<p><code class="code">RUN</code> , which has a whole range of different parameters ( <a class="uref" href="https://docs.docker.com/engine/reference/builder/#run">https://docs.docker.com/engine/reference/builder/#run</a> ), but you would typically use this to add any programs that you need but which were not part of the original image. Example <code class="code">RUN npm install -g nodemon</code> means that you wish to use npm (one of the package managers available for node.js) to install the program <code class="code">nodemon</code>. Nodemon is used during development to restart a node.js application as soon as any of its files change.
</p>
<a class="index-entry-id" id="index-Docker-EXPOSE"></a>
<p><code class="code">EXPOSE</code> is used to flag network ports that can be of use outside of the container. Example: <code class="code">EXPOSE 3000</code> flags port 3000 as being accessible.
</p>
<p><strong class="strong">Please note</strong>: This only instructs Docker that this port <em class="emph">can</em> be opened. You still have to explicitly tell Docker that you <em class="emph">want</em> it open and mapped to a particular port on your host machine when starting your container.
</p>
<a class="index-entry-id" id="index-Docker-WORKDIR"></a>
<p><code class="code">WORKDIR</code> instructs Docker that when you start the container, this is the directory it should start in. Example <code class="code">WORKDIR /app</code> to start in the <code class="code">/app</code> directory.
</p>
<a class="index-entry-id" id="index-Docker-COPY"></a>
<p><code class="code">COPY</code> is used to move any files from your host machine into the image. You would for example use this to copy the code for your microservice into the container. You can also use it to copy a specific configuration etc. Example: <code class="code">COPY . .</code> copies everything in the current directory on the host machine (probably the directory where your Dockerfile is located) into the current working directory inside the container (which you may have set with a previous <code class="code">WORKDIR</code> command).
</p>
<p>At this point you are in many cases done with what needs to be installed, what remains is perhaps to set a few environment variables, and instruct Docker how you want to start your microservice. If you are creating a node.js application, this is a good point to ensure that all node.js packages you depend on are also installed. Another RUN takes care of this: <code class="code">RUN npm install</code>
</p>
<a class="index-entry-id" id="index-Docker-ENV"></a>
<p>Setting an environment variable so that node.js, when running, knows what debug output to focus on: <code class="code">ENV DEBUG='qfapp:*'</code>.
</p>
<a class="index-entry-id" id="index-Docker-ENTRYPOINT"></a>
<a class="index-entry-id" id="index-Docker-CMD"></a>
<p><code class="code">ENTRYPOINT</code> is typically the last line in your Dockerfile, and it specifies which command to run and which parameters to use for it. You can specify a <code class="code">CMD</code> instead (or together with <code class="code">ENTRYPOINT</code>), but it is generally recommended to try with only an <code class="code">ENTRYPOINT</code> first, since this can be replaced even after the image is created (e.g. if you realise that you want to try out a different start command). The preferred format (which can be used for other command such as <code class="code">RUN</code> too) is to use an array format for the command: <code class="code">ENTRYPOINT [&quot;npm&quot;, &quot;run&quot;, &quot;dev&quot;]</code> .
</p>
<a class="index-entry-id" id="index-Docker-VOLUME"></a>
<a class="index-entry-id" id="index-Docker-USER"></a>
<a class="index-entry-id" id="index-Docker-ADD"></a>
<p>Other commands that you sometimes see are used to mount VOLUMEs, or set the USER. Please see the full reference for the Dockerfile <a class="uref" href="https://docs.docker.com/engine/reference/builder/">https://docs.docker.com/engine/reference/builder/</a>  for more information.
</p>
<div class="example">
<pre class="example-preformatted">FROM node:18-alpine
RUN npm install -g nodemon
EXPOSE 3000
WORKDIR /app
COPY . .
RUN npm install
ENV DEBUG='qfapp:*'
ENTRYPOINT [&quot;npm&quot;, &quot;run&quot;, &quot;dev&quot;]
</pre></div>

<hr>
</div>
<div class="section-level-extent" id="Docker-Commands">
<div class="nav-panel">
<p>
Next: <a href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service" accesskey="n" rel="next">Not Building Microservices &ndash; Infrastructure As A Service</a>, Previous: <a href="#Dockerfile" accesskey="p" rel="prev">Dockerfile</a>, Up: <a href="#Microservices-and-Lightweight-Containers" accesskey="u" rel="up">Microservices and Lightweight Containers</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Docker-Commands-1">4.4 Docker Commands</h3>

<p>Now that you have created your Dockerfile, the next step is to start using it.
</p>
<ol class="enumerate">
<li> <a class="anchor" id="Getting-Help"></a>Getting Help


<a class="index-entry-id" id="index-man"></a>
<a class="index-entry-id" id="index-info"></a>
<p>For almost all commands in Unix, you have a few different ways to get help. Running the command with the parameter &lsquo;<samp class="samp">-h</samp>&rsquo; , or &lsquo;<samp class="samp">--help</samp>&rsquo; (note the two dashes) is a good start. For more detailed information, you use the command &lsquo;<samp class="samp">man</samp>&rsquo; . Sometimes, you can get even more details if you use the command &lsquo;<samp class="samp">info</samp>&rsquo;. Try the following commands:
</p>
<div class="example">
<pre class="example-preformatted">docker -h
docker --help
</pre></div>

<a class="index-entry-id" id="index-more"></a>
<a class="index-entry-id" id="index-less"></a>
<p>Wow, that was a long page. Let&rsquo;s pipe it through something that paginates it for us. We can use either &lsquo;<samp class="samp">more</samp>&rsquo; or its more enabled version &lsquo;<samp class="samp">less</samp>&rsquo; for this.
</p>
<div class="example">
<pre class="example-preformatted">docker -h | more 
docker --help | less
</pre></div>

<p>To see how much more information you can get, try the following commands (you can also learn more about &lsquo;<samp class="samp">man</samp>&rsquo; by looking at <em class="emph">its</em> man-page: &lsquo;<samp class="samp">man man</samp>&rsquo;):
</p>
<div class="example">
<pre class="example-preformatted">man docker
info docker
</pre></div>

<p>Pressing the key &lsquo;<samp class="samp">h</samp>&rsquo; while on a man-page gives you instructions on how to navigate the document.
</p>
</li><li> <a class="anchor" id="Docker-image-and-Image-Management"></a>Docker image and Image Management 


<p>First, we need to use the Dockerfile and create an image. This image downloads everything that should be installed &ndash; provisioned &ndash; in order to run your application later. During this process, all commands in your Dockerfile will be executed, and the image will be stored ready for use. Note that once this step is complete, nothing is actually running. All you have is a chunk of disk space that is <em class="emph">ready</em> to run.
</p>
<a class="index-entry-id" id="index-docker-build"></a>
<a class="index-entry-id" id="index-docker-image-build"></a>
<p>The command is &lsquo;<samp class="samp">docker build</samp>&rsquo; , and we want to look in the current directory for the Dockerfile so we add a period to the command. However, if we do this we get an image which has no name and only an unwieldy image id to work with. So let&rsquo;s tag the image as we create it with the &lsquo;<samp class="samp">-t &lt;tagname&gt;</samp>&rsquo; flag.
</p>
<div class="example">
<pre class="example-preformatted">docker build -t myfirstimage .
</pre></div>

<a class="index-entry-id" id="index-docker-image"></a>
<a class="index-entry-id" id="index-docker-image-ls"></a>
<p>Did it work? Let&rsquo;s view all images:
</p><div class="example">
<pre class="example-preformatted">docker image ls
</pre></div>

<p>The output should be something like:
</p>
<pre class="verbatim">REPOSITORY                    TAG         IMAGE ID       CREATED         SIZE
myfirstimage                  latest      270970b0971b   5 seconds ago   232MB
</pre>
<p>What else can we do? Try &lsquo;<samp class="samp">docker image --help</samp>&rsquo; . Apparently we can (among other things) build, list, inspect, remove, and tag images with this command. &lsquo;<samp class="samp">docker build</samp>&rsquo; is, in fact, an alias for &lsquo;<samp class="samp">docker image build</samp>&rsquo;.
</p>
<a class="index-entry-id" id="index-docker-image-rm"></a>
<p>Once you are done (not yet), you may want to clean up after yourself. Each image has a name listed under REPOSITORY, a tag listed under TAG, and an IMAGE ID. If there is only one image with that name, you can run &lsquo;<samp class="samp">docker image rm myfirstimage</samp>&rsquo; . If you have several images with the same name (try creating one more with &lsquo;<samp class="samp">docker build -t myfirstimage:second .</samp>&rsquo; ) , you will need to qualify the name with the specific TAG you want to remove. If all else fail (e.g. if you forgot to give the image a name in the first place), you can use the IMAGE ID to uniquely identify your image.
</p>
</li><li> <a class="anchor" id="Docker-run-and-Container-Management"></a>Docker run and Container Management


<a class="index-entry-id" id="index-docker-run"></a>
<a class="index-entry-id" id="index-docker-container-run"></a>
<p>So, let&rsquo;s get this image to actually run as a container, using the command &lsquo;<samp class="samp">docker run</samp>&rsquo;. We need a few parameters for this to work as we want it. Some of the more commonly used parameters are listed in Table <a class="ref" href="#tabdocker_002drun_002dparameters">Table 4.1</a>
</p>
<div class="float" id="tabdocker_002drun_002dparameters">
<table class="multitable">
<thead><tr><th>Short</th><th>Long</th><th></th></tr><tr><th>Parameter</th><th>Parameter</th><th>Description</th></tr></thead>
<tbody><tr><td>-d</td><td>&ndash;detach</td><td>Run the container in the background without any console interaction</td></tr>
<tr><td>-p</td><td>&ndash;publish</td><td>List the ports that should be exposed from inside the container to a specific port on the host OS</td></tr>
<tr><td>-e</td><td>&ndash;env</td><td>Set environment variables inside the container</td></tr>
<tr><td>-v</td><td>&ndash;volume</td><td>Mount a volume (or directory) from the host is into the container</td></tr>
<tr><td></td><td>&ndash;name</td><td>Give the running container a specific name</td></tr>
<tr><td></td><td></td><td></td></tr>
<tr><td>-i</td><td>&ndash;interactive</td><td>Run the container as an interactive console application. Usually together with -t</td></tr>
<tr><td>-t</td><td>&ndash;tty</td><td>Allocate a terminal (console). Usually together with -i</td></tr>
</tbody>
</table>

<div class="caption"><p><strong class="strong">Table 4.1: </strong>Some of the more common parameters to docker run.</p></div></div>
<p>The most common ones you will see are the detach and publish flags, and you will often see these together: &lsquo;<samp class="samp">docker run -dp 8080:3000</samp>&rsquo; , which will open port 8080 on your host into port 3000 inside the container.
</p>
<p>When developing your application, it is useful to be able to view any console output it makes (e.g. if you use &lsquo;<samp class="samp">printf()</samp>&rsquo;, &lsquo;<samp class="samp">cout</samp>&rsquo;, &lsquo;<samp class="samp">console.log()</samp>&rsquo; , or &lsquo;<samp class="samp">(print)</samp>&rsquo; inside your application). &lsquo;<samp class="samp">docker run -it</samp>&rsquo; enables this, and also enables you to give commands into your running application if it is reading from standard input.
</p>
<a class="index-entry-id" id="index-docker-container"></a>
<a class="index-entry-id" id="index-docker-container-ps"></a>
<a class="index-entry-id" id="index-docker-container-ls"></a>
<a class="index-entry-id" id="index-docker-ps"></a>
<p>You can view running containers with &lsquo;<samp class="samp">docker container ps</samp>&rsquo;, &lsquo;<samp class="samp">docker container ls</samp>&rsquo;, or just &lsquo;<samp class="samp">docker ps</samp>&rsquo; :
</p>
<pre class="verbatim">CONTAINER ID   IMAGE     COMMAND         CREATED         STATUS         PORTS      NAMES
988c2fa79431   tst       ``npm run dev''   7 seconds ago   Up 6 seconds   3000/tcp   pensive@math{_hugle}
</pre>
<a class="index-entry-id" id="index-docker-container-stop"></a>
<a class="index-entry-id" id="index-docker-container-start"></a>
<a class="index-entry-id" id="index-docker-container-rm"></a>

<p>the CONTAINER ID is used as a handle to do other things with the container. We can, for example, stop the container and later start it again with &lsquo;<samp class="samp">docker container stop &lt;container-id&gt;</samp>&rsquo; and &lsquo;<samp class="samp">docker container start &lt;container-id&gt;</samp>&rsquo; . If we stop the container we can also remove it completely (e.g. in order to update with a newer image): &lsquo;<samp class="samp">docker container rm &lt;container-id&gt;</samp>&rsquo; (adding the &ldquo;force&rdquo;-flag &lsquo;<samp class="samp">-f</samp>&rsquo; to rm will first stop the container if it is running, saving you one command: &lsquo;<samp class="samp">docker rm -f &lt;container-id&gt;</samp>&rsquo;).
</p></li></ol>

<hr>
</div>
<div class="section-level-extent" id="Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service">
<div class="nav-panel">
<p>
Next: <a href="#Provisioning-your-Virtual-Machine" accesskey="n" rel="next">Provisioning your Virtual Machine</a>, Previous: <a href="#Docker-Commands" accesskey="p" rel="prev">Docker Commands</a>, Up: <a href="#Microservices-and-Lightweight-Containers" accesskey="u" rel="up">Microservices and Lightweight Containers</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service-1">4.5 Not Building Microservices &ndash; Infrastructure As A Service</h3>

<a class="index-entry-id" id="index-Virtual-Machine"></a>
<a class="index-entry-id" id="index-IAAS-Infrastructure-As-A-Service"></a>
<p>The alternative to running microservices would be to run a full-fledged virtual machine with its full operating system and everything. Maybe even a graphical user interface. Sometimes this is the better option, especially if an application consists of several collaborating processes that expect to co-exist on the same machine. We <em class="emph">could</em> run these inside a docker container too, but this would sort of break the minimalistic view that one container should essentially only run a single command.
</p>
<a class="index-entry-id" id="index-Hypervisor"></a>
<p>In order to run virtual machines, you need a Hypervisor software that can act as a management layer between your host operating system and the guest operating system that you want to run in your virtual machine (Technically, I suppose that Docker/Podman should also be considered hypervisors). The virtual machine is supposed to emulate the hardware, so you are free to &ndash; in theory &ndash; run any operating system built for any platform. In practice, however, there are limitations to this.
</p>
<div class="example">
<pre class="example-preformatted">        +-----------------+ +-----------------+
        |   Guest OS      | |    Guest OS     |
        +-----------------+ +-----------------+
        +-----------------+ +-----------------+
        | Virtual Machine | | Virtual Machine |
        +-----------------+ +-----------------+
        +-------------------------------------+          
        |  Hypervisor                         |          
        +-------------------------------------+      
+----------------------------------------------------+
|          Host Operating System                     |
+----------------------------------------------------+
+----------------------------------------------------+
|          Computer Hardware                         |
+----------------------------------------------------+
</pre></div>

<a class="index-entry-id" id="index-Virtualbox"></a>
<a class="index-entry-id" id="index-VMWare"></a>
<a class="index-entry-id" id="index-Hyper_002dV"></a>
<a class="index-entry-id" id="index-Parallells"></a>
<p>Some common hypervisors include:
</p><ul class="itemize mark-bullet">
<li>Virtualbox <a class="uref" href="https://www.virtualbox.org/">https://www.virtualbox.org/</a> 
</li><li>VMWare, with VMWare Fusion for Mac <a class="uref" href="https://www.vmware.com/products/fusion.html">https://www.vmware.com/products/fusion.html</a>  , and VMWare Workstation for Windows and Linux <a class="uref" href="https://www.vmware.com/products/workstation-player.html">https://www.vmware.com/products/workstation-player.html</a>
</li><li>Parallells <a class="uref" href="https://www.parallels.com/se/">https://www.parallels.com/se/</a>  if you are using a Mac
</li><li>Hyper-V <a class="uref" href="https://learn.microsoft.com/en-us/virtualization/hyper-v-on-windows/">https://learn.microsoft.com/en-us/virtualization/hyper-v-on-windows/</a> if you are using Windows
</li></ul>

<p>Of these, Virtualbox is free for use and available on most operating systems and mostly works without problems. It is, however, limited to x86 and AMD64/Intel64 hardware architectures so if you are using e.g. a more recent Mac you will not be able to use it. In those cases, you <em class="emph">can</em> make do with VMWare or Parallells, but each of them have their own unique set of error messages and challenges to overcome in order to work seamlessly.
</p>
<a class="index-entry-id" id="index-Qemu"></a>
<p>Qemu <a class="uref" href="https://www.qemu.org/">https://www.qemu.org/</a> is a more powerful and free alternative that actually does emulate the virtual hardware as well. So you can emulate an x86 architecture on top of a mac M1 machine, or vice versa. The installation and setup <em class="emph">looks</em> more daunting than e.g. Virtualbox does, but it is really quite easy &ndash; at least on a Linux machine. In my experience, Qemu is also much faster than a corresponding virtual machine in Virtualbox.
</p>
<hr>
</div>
<div class="section-level-extent" id="Provisioning-your-Virtual-Machine">
<div class="nav-panel">
<p>
Next: <a href="#Communicating-Microservices-and-REST-APIs" accesskey="n" rel="next">Communicating Microservices and REST APIs</a>, Previous: <a href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service" accesskey="p" rel="prev">Not Building Microservices &ndash; Infrastructure As A Service</a>, Up: <a href="#Microservices-and-Lightweight-Containers" accesskey="u" rel="up">Microservices and Lightweight Containers</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Provisioning-your-Virtual-Machine-1">4.6 Provisioning your Virtual Machine</h3>

<a class="index-entry-id" id="index-Provisioning"></a>
<p>With a hypervisor such as above, you get a clean virtual machine, and it is up to you to install whatever operating system you want to run, and whatever software you want installed on top of this operating system. You <em class="emph">can</em> do this manually, but if you remember the goals we set up in the Introduction (See <a class="ref" href="#introduction">introduction</a> ) , we want to do better than this. We wish help from the computer to create a repeatable and configuration managed deployment that can be used over and over again.
</p>
<a class="index-entry-id" id="index-Vagrant"></a>
<a class="index-entry-id" id="index-Vagrantfile"></a>
<p>This is where the software Vagrant <a class="uref" href="https://www.vagrantup.com/">https://www.vagrantup.com/</a> comes into play. With Vagrant we create a file &lsquo;<samp class="samp">Vagrantfile</samp>&rsquo; where we specify the size and type of virtual machines we want, the operating system we want on them, and any other software we want installed &ndash; analogous to the &lsquo;<samp class="samp">Dockerfile</samp>&rsquo; discussed earlier, but with much more details. It is important to note that Vagrant does not create any virtual machines itself, it is not a hypervisor. Instead, it interacts with other hypervisors such as Virtualbox, VMWare, Hyper-V, or Qemu and requests them to do the &ldquo;heavy lifting&rdquo; for it. The beauty of this is that you learn once how to work with Vagrant, and can use the same Vagrantfile to create your same virtual machine using any of the supported hypervisors and indeed even launch your virtual machine on a cloud provider.
</p>
<p>Unlike Docker, a Vagrantfile can also specify several machine configurations in one, so you can Orchestrate your entire application at once instead of having to work separately with each component/microservice in your system setup. But this is another story which we will get to later (see <a class="ref" href="#Deployment">Deployment</a> ).
</p>
<hr>
</div>
<div class="section-level-extent" id="Communicating-Microservices-and-REST-APIs">
<div class="nav-panel">
<p>
Next: <a href="#Other-communication-means" accesskey="n" rel="next">Other communication means</a>, Previous: <a href="#Provisioning-your-Virtual-Machine" accesskey="p" rel="prev">Provisioning your Virtual Machine</a>, Up: <a href="#Microservices-and-Lightweight-Containers" accesskey="u" rel="up">Microservices and Lightweight Containers</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Communicating-Microservices-and-REST-APIs-1">4.7 Communicating Microservices and REST APIs</h3>

<a class="index-entry-id" id="index-Network-Socket"></a>
<a class="index-entry-id" id="index-RPC-Remote-Procedure-Call"></a>
<p>With microservices we are tearing apart our monolith application into several smaller units. Where we previously could use a simple method call inside the same process, we must now reach for other tools. Since these smaller units need not run on the same (virtual) machine, we must also resort to communication means that are network-enabled. If we truly love pain, we may develop our own communication protocol and use simple sockets, and for some applications this may be the best way to establish a fast enough and secure enough communications means. One step up, we may rely on Remote Procedure Calls (which still use sockets but we do not need to see them).
</p>
<a class="index-entry-id" id="index-HTTP-protocol"></a>
<a class="index-entry-id" id="index-JSON-grammar"></a>
<a class="index-entry-id" id="index-XML"></a>
<p>What is more common today, however, is that we make use of ready-made components to turn our microservice in to a small web server. The HTTP protocol is already well established and provide support for most of the tasks we need (i.e., GET, POST, PUT, PATCH, and DELETE). The payload of the communication protocol still need to be defined, of course, but much effort can be saved by sticking to existing grammars such as JSON or XML.
</p>
<a class="index-entry-id" id="index-REST-API"></a>
<p>This leads us to Representational State Transfer, or REST APIs for short. Key principles for a REST API are (source: <a class="uref" href="https://www.ibm.com/topics/rest-apis">https://www.ibm.com/topics/rest-apis</a> ):
</p>
<dl class="table">
<dt>Uniform Interface</dt>
<dd><p>All requests for the same resource should look the same. So we cannot embed state or cookies or user session or whatever in the address of the resource (but we can include such information in the actual request)
</p></dd>
<dt>Client-Server Decoupling</dt>
<dd><p>Clients and Servers are independent from each other, all we need to know is the address of a requested resource. In fact, this is all that is ever available to us.
</p></dd>
<dt>Statelessness</dt>
<dd><p>This one is interesting given the original description of the REST pattern as transitioning a service through a series of states. The key here is that the server does not keep track of the state for every client that is connected, this is instead made part of each client&rsquo;s requests.
</p></dd>
<dt>Cacheability</dt>
<dd><p>Whenever possible, the same request should give the same answer (this may not be desired if, for example, content is being continuously generated, and in those cases the resource should flag itself as being not cacheable).
</p></dd>
</dl>

<p>As already almost stated, over time we have mostly settled on using HTTP (or HTTPS) as the communications protocol and JSON or XML as the data protocol for our REST APIs. Because there are ready-made components for many programming languages today, it is easy to start listening for HTTP calls and to parse JSON data. Creating HTTP calls is equally easy, and so we have an easy mechanism for providing and using a service that works across system borders.
</p>
<a class="index-entry-id" id="index-Layered-Architecture-Style"></a>
<p>The downside is that we break the seamlessness of our application. Ideally (and this was once the sales pitch for remote procedure calls), we want to make all function/method calls in the same way throughout the entire application, no matter the physical distribution of parts of the application to different servers. In fact, the first thing we do when we create a microservice is probably to define a <em class="emph">Layered</em> architecture style where the top layer deals with all the HTTP/JSON complexities, so that the rest of the application can be an as pure representation as possible of the domain concepts. Likewise, when we develop clients that need to make REST calls to another service, we will probably create a layer that marshal regular function calls into JSON/HTTP requests and unmarshall the response into a return value that knows how to behave like a proper object.
</p>
<hr>
</div>
<div class="section-level-extent" id="Other-communication-means">
<div class="nav-panel">
<p>
Previous: <a href="#Communicating-Microservices-and-REST-APIs" accesskey="p" rel="prev">Communicating Microservices and REST APIs</a>, Up: <a href="#Microservices-and-Lightweight-Containers" accesskey="u" rel="up">Microservices and Lightweight Containers</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Other-communication-means-1">4.8 Other communication means</h3>

<p>Do note that the required statelessness of a REST service means that the communication should only ever be one-directional. A well behaved service dutifully waits until someone makes an HTTP call, responds, and then goes back to waiting for the next call. If we expect the service to call back at a later stage (perhaps when a long-running job is done, or when a monitored resource becomes available, or when a specific user comes online, etc.), there should not be any way for the service to even know about the clients. And yet sometimes we need this, which means we sometimes need to break the simpleness of our REST service.
</p>
<a class="index-entry-id" id="index-Dependency-Injection"></a>
<p>First, we may need some mental acrobatics to decide that a request is not done until we have called back to the originator with results. If the initial request contains the return address, we can pretend that we are still working from within the same request and we are still (please click your heels three times and believe very firmly) working within the conceptual model of the REST architecture pattern.
</p>
<p>One challenge is that we may not be able to spawn new threads inside our application, e.g. if the programming language or paradigm does not support threads. Thus, if the client makes a synchronous call, our hands are tied and we must deal with the execution thread we have been given to us, process the request, and return the answer. Ideally, we want something like:
</p>
<ol class="enumerate">
<li> A call is made to our REST service together with a callData object.
</li><li> We store the callData object.
</li><li> We prepare a response to the REST call and write this to the open network socket.
</li><li> We close the network socket but DO NOT return from our method just yet.
</li><li> Now, we can start processing the callData object and figure out what they really wanted us to do.
</li><li> Once we have prepared our more detailed response, we look in the callData object and locate the address we should use for our return call.
</li><li> <em class="emph">We</em> make a REST call to the client and drop off our carefully prepared response.
</li><li> And now, finally, we can return from our method inside the REST service.
</li></ol>

<p>&hellip; Assuming, of course, that the client is accessible through layers and layers of firewalls and NAT:ed networks. I think you get the idea that this is not precisely a neat and tidy way of programming. Nor is it easily supported by common web frameworks, which usually expect steps 3 and 4 to be done by returning from our method, and thus giving back the execution thread.
</p>
<p>Our next option is to coerce the client to make an asynchronous call to us. This is tricky using the standard HTTP api. A message queue is a better alternative, and is something which we can (and will have to) do by introducing a separate microservice in charge of the message queues. The workflow is now:
</p>
<ol class="enumerate">
<li> The client drops off a message in the message queue and returns.
</li><li> The REST service gets notified that there is a message to process, or simply polls at regular time intervals.
</li><li> The REST service collects the next message to process.
</li><li> The REST service process the message and prepares a response.
</li><li> The REST service looks up the return address in the message, and returns the response accordingly.
</li></ol>

<p>We&rsquo;re getting there. Now all we need to do is decide on how the REST service should contact the client. As before, the client can provide a REST api of their own, in order to receive the return call. Or, since we now have a microservice for managing message queues in place, we can use this:
</p>
<ol class="enumerate">
<li> The client opens up a return queue
</li><li> The client drops off a message (containing, among other things, the address to the return queue) in the outgoing message queue and returns.
</li><li> The client checks the return queue until a message arrives.
</li></ol>

<p>Having established that this is indeed possible, the question remains: Is this a good idea? Please discuss this in small groups.
</p>
<a class="index-entry-id" id="index-Redis"></a>
<a class="index-entry-id" id="index-MQTT"></a>
<p>The message queue may be implemented in many ways. We may, for example, use a dedicated table in our database (to which our entire system is connected anyway). We may dedicate a separate microservice running e.g. Redis <a class="uref" href="https://redis.io/">https://redis.io/</a> , and use an implementation of a message queue that connects to this microservice. We may even wish to go formal and pick a service that implements the MQTT protocol (Message Queue Telemetry Transport protocol). But that&rsquo;s a story for another day.
</p>
<hr>
</div>
</div>
<div class="chapter-level-extent" id="Quiz-Hypervisors-and-Lightweight-Virtual-Machines">
<div class="nav-panel">
<p>
Next: <a href="#Let_0027s-get-Practical" accesskey="n" rel="next">Let&rsquo;s get Practical</a>, Previous: <a href="#Microservices-and-Lightweight-Containers" accesskey="p" rel="prev">Microservices and Lightweight Containers</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Quiz_003a-Hypervisors-and-Lightweight-Virtual-Machines">5 Quiz: Hypervisors and Lightweight Virtual Machines</h2>

<p><strong class="strong">TODO</strong> Please read the following articles:
</p>
<ol class="enumerate">
<li> Crosby, Simon, and David Brown. &ldquo;The Virtualization Reality: Are hypervisors the new foundation for system software?.&rdquo; Queue 4.10 (2006): 34-41.
</li><li> Morabito, Roberto, Jimmy Kjällman, and Miika Komu. &ldquo;Hypervisors vs. lightweight virtualization: a performance comparison.&rdquo; 2015 IEEE International Conference on cloud engineering. IEEE, 2015.
</li><li> Jiang, Congfeng, et al. &ldquo;Energy efficiency comparison of hypervisors.&rdquo; Sustainable Computing: Informatics and Systems 22 (2019): 311-321.
</li><li> Riddle, Andrew R., and Soon M. Chung. &ldquo;A survey on the security of hypervisors in cloud computing.&rdquo; 2015 IEEE 35th International Conference on Distributed Computing Systems Workshops. IEEE, 2015.
</li></ol>

<p>We have chosen these articles for you to read because they illustrate first that there are different types and levels of hypervisors, and secondly because they illustrate that there are many different concerns to consider when selecting which hypervisor (and hence, indirectly, which cloud provider) you chose. The articles above measure and discuss performance, energy consumption, and security.
</p>
<p><strong class="strong">TODO</strong> Summarise each article (no more than 1/2 page each) according to the following:
</p>
<ul class="itemize mark-bullet">
<li>Authors and Title of the article
</li><li>Briefly, what is the article about?
</li><li>What have they measured?
</li><li>What are their main findings?
</li><li>What can you learn from this article?
</li></ul>

<p><strong class="strong">TODO</strong> Answer the following questions:
</p>
<ul class="itemize mark-bullet">
<li>What is a hypervisor?
</li><li>What are the main differences between a lightweight virtual machine and a virtual machine?
</li><li>What is a microservice?
</li><li>What is the REST architecture pattern? How is it implemented in modern microservice development?
</li><li>What is &ldquo;Infrastructure-As-A-Service&rdquo; (IAAS)?
</li><li>What are the main differences between microservice development and IAAS?
</li></ul>

<p>There is a Quiz on Canvas where you can submit your article summaries and answers to the questions.
</p>
<p><strong class="strong">NOTICE:</strong> <em class="emph">This quiz does not contribute to the grade in the course. We do, however, require of you to submit the quiz on time.</em> The purpose of this quiz is to serve as a learning aid allowing you to think about these concepts, and for us to keep track of your progress in the course. If you are unable to maintain the study pace required to submit this quiz on time, we want to be made aware of this so that you are able to re-plan your commitment for the remainder of the course.
</p>
<hr>
</div>
<div class="chapter-level-extent" id="Let_0027s-get-Practical">
<div class="nav-panel">
<p>
Next: <a href="#Quiz-Let_0027s-get-Practical" accesskey="n" rel="next">Quiz: Let&rsquo;s get Practical</a>, Previous: <a href="#Quiz-Hypervisors-and-Lightweight-Virtual-Machines" accesskey="p" rel="prev">Quiz: Hypervisors and Lightweight Virtual Machines</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Let_0027s-get-Practical-1">6 Let&rsquo;s get Practical</h2>


<ul class="mini-toc">
<li><a href="#Introducing-the-QuoteFinder-application" accesskey="1">Introducing the QuoteFinder application</a></li>
<li><a href="#Install-relevant-software" accesskey="2">Install relevant software</a></li>
<li><a href="#Installing-and-Running-QFStandalone" accesskey="3">Installing and Running QFStandalone</a></li>
<li><a href="#A-Minimal-Qemu-Vagrantfile" accesskey="4">A Minimal Qemu Vagrantfile</a></li>
</ul>
<hr>
<div class="section-level-extent" id="Introducing-the-QuoteFinder-application">
<div class="nav-panel">
<p>
Next: <a href="#Install-relevant-software" accesskey="n" rel="next">Install relevant software</a>, Up: <a href="#Let_0027s-get-Practical" accesskey="u" rel="up">Let&rsquo;s get Practical</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Introducing-the-QuoteFinder-application-1">6.1 Introducing the QuoteFinder application</h3>

<a class="index-entry-id" id="index-QuoteFinder-Version1"></a>
<a class="index-entry-id" id="index-QFStandalone"></a>

<p><em class="emph">QuoteFinder</em> is the application we are going to use for testing purposes. This application consist of a web site where you can search for quotes in texts. <em class="emph">Version 1</em>, which we are starting with, simply searches for the entire string in its entirety. In <em class="emph">Version 2</em> and <em class="emph">Version 3</em>, this basic search algorithm is replaced by one that allows for a more advanced search where the words may appear near each other if not directly together. We will initially stick to version 1, as it is mostly a <em class="emph">standalone</em> version. We will later come back to version 1 when we explore other concepts. In this part of the tutorial we are going to, step by step, install and run QuoteFinder version 1 in different ways, but first let us explore the application a bit.
</p>

<a class="index-entry-id" id="index-node_002ejs"></a>
<a class="index-entry-id" id="index-Express"></a>
<a class="index-entry-id" id="index-MongoDB"></a>
<a class="index-entry-id" id="index-socket_002eio"></a>
<p>QuoteFinder Version 1 has the following characteristica:
</p><ul class="itemize mark-bullet">
<li>it is written in node.js <a class="uref" href="https://nodejs.org/">https://nodejs.org/</a>
</li><li>it is an Express web app <a class="uref" href="http://expressjs.com/">http://expressjs.com/</a>
</li><li>it also uses socket.io <a class="uref" href="https://socket.io/">https://socket.io/</a> to communicate between the web client and the express server
</li><li>it uses a MongoDB database <a class="uref" href="https://www.mongodb.com/">https://www.mongodb.com/</a>
</li></ul>

<a class="index-entry-id" id="index-Project-Gutenberg"></a>
<p>Once started, there are three landing pages:
</p><ul class="itemize mark-bullet">
<li><code class="code">/</code> This is the start page, where you enter text to search for.
</li><li><code class="code">/add</code> From the <code class="code">/add</code> page you can add new texts to the database. For adding texts, we recommend Project Gutenberg <a class="uref" href="https://www.gutenberg.org/">https://www.gutenberg.org/</a> . Indeed, if you leave the text fields empty, you will add a plaintext copy of Leo Tolstoy&rsquo;s <em class="emph">War and Peace</em> to your database.
</li><li><code class="code">/list</code> Last but not least, <code class="code">/list</code> allows you to view a list of currently added texts.
</li></ul>

<p>Being an Express app, this is all controlled by so called routes, which are set up in the file <code class="code">src/index.js</code>:
</p>
<div class="example">
<pre class="example-preformatted">var router = express.Router();
router.get('/', startPage);
router.get('/add', addTextPage);
router.get('/list', listTextsPage);
app.use('/', router);
</pre></div>

<p>The second argument for each of the <code class="code">router.get()</code> calls is a reference to a function, also found in <code class="code">index.js</code> . These are fairly small, and mostly rely on jade/pug to render a page back to the user. The <code class="code">listTextsPage()</code> is slightly longer since it first creates a new <code class="code">TextManager</code> object (more on this class later) to find all the available texts from the database.
</p>
<div class="example">
<pre class="example-preformatted">function startPage(req, res) {
    console.log('Loading start page from: ' + req.hostname);
    return res.render('index', serverIDMessage);
}

function addTextPage(req, res) {
    console.log('Serving the &quot;Add New Text&quot; page...');
    return res.render('addText');
}

function listTextsPage(req, res) {
    console.log('Listing available texts.');
    let tm = new TextManager();
    return tm.connect()
        .then( tm.listTexts )
        .then(texts =&gt; res.render('index', {textList: texts,
                                                ...serverIDMessage}) );
}
</pre></div>

<a class="index-entry-id" id="index-Jade"></a>
<a class="index-entry-id" id="index-Pug"></a>
<a class="index-entry-id" id="index-JavaScript-Promise"></a>
<p>Jade/Pug is out of scope for this brief walk-through, but the templates used to render the pages can be found in the directory <code class="code">/src/views</code> . One more thing to point out here is the use of <em class="emph">Promises</em> rather than the usual callback hell that you often end up in with JavaScript (the <code class="code">then()</code> - daisy-chain is a clue that Promises are being used).
</p>
<p>The rendered web page connects back to the express server using <em class="emph">socket.io</em> , so when a button is pressed in the web browser, this does not generate a new HTTP call back, but rather just a message on an already open communications socket. This seamlessly extends the event-driven architecture of node.js (with <code class="code">EventEmitter.emit()</code> and <code class="code">EventEmitter.on()</code> ) to also work across system boundaries to the web browser. In the directory <code class="code">/src/public/js</code> you will find the two client-side javascript files that takes care of this.
</p>
<p>This design decision was taken so that the web page could be rendered in pieces. For example, when a search is being executed, partial results can be added to the page while still waiting for more complex calculations. It will, however, cause problems for us down the line, so please remember that you have been forewarned.
</p>
<p>Because the socket object is required in order to send results back to the web client, the methods that require this (i.e. <code class="code">searchTexts()</code> and <code class="code">addText()</code> ) are declared once for each connection. That is also when the server-side socket is connected to pass on messages from the client to these two methods:
</p>
<div class="example">
<pre class="example-preformatted">socket.on('search', searchTexts );
socket.on('addText', addText)    
socket.on('disconnect', () =&gt; { console.log('user disconnected'); });
</pre></div>

<p>&hellip; And that pretty much takes care of <code class="code">index.js</code>, with some excursions into views and client side code. The remainder is mostly Express boilerplate code to deal with simple error handling and to actually start listening for connections.
</p>
<p>The other component needed is the TextManager class, which is responsible for connecting to MongoDB, and searching, adding, and listing texts. The connection can be done in two different ways, but for now we will only be using the second alternative where (optionally) an environment variable <code class="code">TEXTSTORE_HOST</code> decides the IP-address for the MongoDB server. If left unspecified, TextManager assumes localhost (127.0.0.1).
</p>
<p>A conceptual view of the application:
</p>
<div class="example">
<pre class="example-preformatted">+----------------------+                    +--------------------+---------------+
| Web Client           |&lt;------------------&gt;| QuoteFinder        | Jade/Pug      |
+----------------------+   Socket.io        |                    | Page Rendering|
                           and              +--------------------+---------------+
                           HTTP             | TextManager        |         
                                            |                    |
                                            +---------+----------+
                                                      |      
                                            +---------+----------+
                                            | MongoDB Database   |
                                            +--------------------+
</pre></div>

<hr>
</div>
<div class="section-level-extent" id="Install-relevant-software">
<div class="nav-panel">
<p>
Next: <a href="#Installing-and-Running-QFStandalone" accesskey="n" rel="next">Installing and Running QFStandalone</a>, Previous: <a href="#Introducing-the-QuoteFinder-application" accesskey="p" rel="prev">Introducing the QuoteFinder application</a>, Up: <a href="#Let_0027s-get-Practical" accesskey="u" rel="up">Let&rsquo;s get Practical</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Install-relevant-software-1">6.2 Install relevant software</h3>

<p>Before deploying the QuoteFinder app, we need to install and familiarise ourselves with the technology stack we are going to use. Specifically, this includes the different types of hypervisors that we are going to use, and supporting software for these:
</p>
<ul class="itemize mark-bullet">
<li>(Windows and OSX) Docker Desktop
</li><li>(Linux) docker
</li><li>(Linux) docker-compose
</li><li>(Linux) minikube and kubectl
</li><li>Virtualbox or Qemu
</li><li>Vagrant
</li></ul>

<p><strong class="strong">TODO</strong> Install Docker <a class="uref" href="https://docs.docker.com/get-docker/">https://docs.docker.com/get-docker/</a>
<a class="index-entry-id" id="index-Homebrew"></a>
On Windows or OSX, the software to install is <em class="emph">Docker Desktop</em>. This is now available on Linux as well, but I suggest that you nevertheless install the command line version <code class="code">docker</code> via your regular package management tool. (On a mac you can use <code class="code">homebrew</code> for this <a class="uref" href="https://formulae.brew.sh/cask/docker">https://formulae.brew.sh/cask/docker</a> , which enables you to reproducibly script the installation of your software). 
</p>
<p>On Linux, you will want to install <code class="code">docker</code>, <code class="code">docker-compose</code>, and <code class="code">minikube</code>.
</p>
<p><strong class="strong">TODO</strong> Install Vagrant <a class="uref" href="https://developer.hashicorp.com/vagrant/downloads">https://developer.hashicorp.com/vagrant/downloads</a>
</p>
<p><strong class="strong">TODO</strong> Install a Hypervisor
Vagrant provides a script language for  provisioning and orchestrating a solution, but it relies on that you already have a hypervisor installed (see <a class="ref" href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service">Not Building Microservices &ndash; Infrastructure As A Service</a> ). Virtualbox <a class="uref" href="https://www.virtualbox.org/">https://www.virtualbox.org/</a> is free and easy to install if your hardware is supported. Vagrant works more or less straight off with Virtualbox.
</p>
<p>You may wish to try Qemu <a class="uref" href="https://www.qemu.org/download/#linux">https://www.qemu.org/download/#linux</a> , and all its gory details <a class="uref" href="https://wiki.archlinux.org/title/QEMU">https://wiki.archlinux.org/title/QEMU</a>. If you do, you will need the following two vagrant plugins, and config the libvirt provider in the &lsquo;<samp class="samp">Vagrantfile</samp>&rsquo; (see <a class="anchor" id="qemu_002dvagrant"></a>):
</p>
<div class="example">
<pre class="example-preformatted">vagrant plugin install vagrant-mutate # to convert boxes between different hypervisors
vagrant plugin install vagrant-libvirt

# You may also wish to download and convert a box image for use with qemu:
vagrant box add bento/ubuntu-20.04
vagrant mutate bento/ubuntu-20.04 libvirt
</pre></div>

<p><strong class="strong">TODO</strong> Run some Tutorials
To familiarise yourself with Docker and Vagrant, please work through some of the tutorials they provide:
</p>
<ol class="enumerate">
<li> Docker <a class="uref" href="https://docs.docker.com/get-started/">https://docs.docker.com/get-started/</a>
</li><li> Docker with node.js  <a class="uref" href="https://docs.docker.com/language/nodejs/">https://docs.docker.com/language/nodejs/</a>
</li><li> Vagrant <a class="uref" href="https://developer.hashicorp.com/vagrant/tutorials">https://developer.hashicorp.com/vagrant/tutorials</a>
</li></ol>

<hr>
</div>
<div class="section-level-extent" id="Installing-and-Running-QFStandalone">
<div class="nav-panel">
<p>
Next: <a href="#A-Minimal-Qemu-Vagrantfile" accesskey="n" rel="next">A Minimal Qemu Vagrantfile</a>, Previous: <a href="#Install-relevant-software" accesskey="p" rel="prev">Install relevant software</a>, Up: <a href="#Let_0027s-get-Practical" accesskey="u" rel="up">Let&rsquo;s get Practical</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Installing-and-Running-QFStandalone-1">6.3 Installing and Running QFStandalone</h3>

<ol class="enumerate">
<li> <a class="anchor" id="Full-Virtual-Machine"></a>Full Virtual Machine


<p>The first step is to run the QFStandalone app as if you were running it on &ldquo;bare metal&rdquo;, i.e. just as you would do if you install it directly on your machine. The benefit of running it in a separate virtual machine is that you will not litter your own machine with any of the software required for this one app. If you are involved in several different projects, each requiring their own technology stack and (possibly) different versions of some tools, it quickly becomes a nightmare to keep track of on a single machine. If you instead get into the habit of always developing inside a virtual machine, you will avoid much of this pain. Not to mention that you should not trust the software that some random teacher tells you to install, so running things inside a virtual machine is a prudent security measure. Lastly, should you later decide do deploy to a cloud provider, your machine setup is already scripted, configuration managed, and ready to go.
</p>
<p><strong class="strong">Tasks</strong>
</p><ol class="enumerate" start="0">
<li> Open a terminal in whichever way your operating system expects you to.

</li><li> Create an empty directory on your machine, e.g. <code class="code">QuoteFinder/Version1/vagrant</code> , and cd into it.

</li><li> Create a Vagrantfile according to what is required for your particular hypervisor.
<ul class="itemize mark-bullet">
<li>The box to use is &lsquo;<samp class="samp">bento/ubuntu-20.04</samp>&rsquo;
</li><li>Define one VM, e.g. called &lsquo;<samp class="samp">app</samp>&rsquo;
</li><li>Configure this VM so that it forwards the guest port 3000 to the host port 8080
</li></ul>

</li><li> Set up provisioning of the VM to install MongoDB and node.js as follows:
</li></ol>

<div class="example">
<pre class="example-preformatted">config.vm.provision &quot;shell&quot;, inline: &lt;&lt;-SHELL
sudo apt-get update
sudo apt-get install -y git curl wget gnupg

echo &quot;----------&gt; Installing MongoDB-org&quot;
wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo apt-key add -
echo &quot;deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/6.0 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list
sudo apt-get update
sudo apt-get install -y mongodb-org
sudo systemctl start mongod

echo &quot;----------&gt; Installing node.js&quot;
curl -fsSL https://deb.nodesource.com/setup_19.x | sudo -E bash - &amp;&amp;\
sudo apt-get install -y nodejs
npm install -g nodemon
SHELL
</pre></div>

<ol class="enumerate" start="4">
<li> Set up provisioning of the VM to download QuoteFinder and set it up as follows (note that this is run as the user &lsquo;<samp class="samp">vagrant</samp>&rsquo; in order to get file permissions right):
</li></ol>

<div class="example">
<pre class="example-preformatted">config.vm.provision &quot;shell&quot;, privileged: false, inline: &lt;&lt;-SHELL
echo &quot;----------&gt; Downloading QuoteFinder&quot;
cd /home/vagrant
if [ -d &quot;./QuoteFinder&quot; ]; then
   echo &quot;repo already cloned...&quot;   
else
   git clone https://github.com/mickesv/QuoteFinder/
fi
cp -r QuoteFinder/Containers/Version1 .

echo &quot;----------&gt; Setting up QFStandalone&quot;
cd Version1/QFStandalone
npm install
SHELL
</pre></div>

<p>The if-statement here is not strictly necessary but it helps us if we want to re-provision without destroying the VM first, since otherwise git will throw an error at us.
</p>
<ol class="enumerate" start="5">
<li> Start the machine: <code class="code">vagrant up</code> 
</li><li> Log in to the machine with <code class="code">vagrant ssh</code> and double check that everything is installed as it should be:
</li></ol>

<div class="example">
<pre class="example-preformatted">$ node --version
v19.7.0
$ mongosh --version
1.7.1
$ ls -l Version1/QFStandalone/
total 116
-rw-rw-r--   1 vagrant vagrant    150 Feb 23 11:37 Dockerfile
drwxrwxr-x 134 vagrant vagrant   4096 Feb 23 11:38 node_modules
-rw-rw-r--   1 vagrant vagrant    414 Feb 23 11:37 package.json
-rw-rw-r--   1 vagrant vagrant 100895 Feb 23 11:38 package-lock.json
drwxrwxr-x   4 vagrant vagrant   4096 Feb 23 11:37 src
</pre></div>

<p>Your specific version numbers may of course vary, but specific things to look at is that the node version is not something hopelessly outdated such as &lsquo;<samp class="samp">0.10.0</samp>&rsquo;, that the owner of the files is &lsquo;<samp class="samp">vagrant</samp>&rsquo;, that there is a &lsquo;<samp class="samp">package-lock.json</samp>&rsquo; file, and a &lsquo;<samp class="samp">node_modules</samp>&rsquo; directory.
</p>
<ol class="enumerate" start="7">
<li> log out and start the QuoteFinder app with <code class="code">vagrant ssh -c 'cd ~/Version1/QFStandalone &amp;&amp; npm run dev'</code>

</li><li> We can now test the app. Open a web browser to <a class="uref" href="http://localhost:8080/add">http://localhost:8080/add</a> and click the &rsquo;Add&rsquo; button to add a book to your database. Your terminal window where the app is running will print some info, hopefully ending with <em class="emph">Text added.</em> If not, make note of any error messages printed.

</li><li> Go to <a class="uref" href="http://localhost:8080/">http://localhost:8080/</a> and search for something, e.g. &rsquo;prince&rsquo;. This will give a list of hits. Remember to keep an eye on the output in the terminal (ignore the &lsquo;<samp class="samp">TEXTSTORE_HOST</samp>&rsquo; warning for now).

</li><li> We can also test editing the app. In a new terminal, on your <em class="emph">host</em> machine, navigate to the directory where you have your Vagrantfile and amaze at the fact that this directory still contains nothing but the Vagrantfile.

</li><li> Log in to the running virtual machine with <code class="code">vagrant ssh</code>, change directory to &lsquo;<samp class="samp">~/Version1/QFStandalone/src</samp>&rsquo; and open the file &lsquo;<samp class="samp">index.js</samp>&rsquo; in an editor. At least two editors are installed by default, &lsquo;<samp class="samp">vi</samp>&rsquo; and &lsquo;<samp class="samp">nano</samp>&rsquo;.

</li><li> In the function <code class="code">startPage()</code> , instead of directly return a page rendering, let us by default always list the available texts. So replace the return line with &lsquo;<samp class="samp">return listTextsPage(req, res);</samp>&rsquo; and save. Because we are internally using <code class="code">nodemon</code> <a class="uref" href="https://nodemon.io/">https://nodemon.io/</a> to start our app (this is specified in &lsquo;<samp class="samp">package.json</samp>&rsquo; ), the app is restarted whenever we save a file, which you can go back to your first terminal and verify.
</li></ol>

<p>If you think it was cumbersome to edit the file like this, then any modern IDE ought to support opening a file over a network protocol. In Emacs, for example, you open the file as usual but with the search path <code class="code">/vagrant:version1--app:/home/vagrant/Version1/QFStandalone/src/index.js</code> , i.e. using the protocol <code class="code">/vagrant:</code> , open a file on the machine <code class="code">app</code> as specified in the Vagrantfile in the directory <code class="code">version1</code> , and then the full path to the file inside the guest machine.
</p>
<p>Another approach (which is maybe more likely) is that you would develop locally in a sub-directory to where the Vagrantfile is located. By default Vagrant mounts this directory to <code class="code">/vagrant</code> on the guest machine (Please, do log in and check this). This is however not always the case. In some situations Vagrant has troubles keeping the host and the guest in sync, and you will be forced to sync files manually.
</p>
<p><strong class="strong">Summary</strong>
We have now
</p><ol class="enumerate">
<li> Configured a virtual machine using Vagrant and a hypervisor of your choice.
</li><li> Provisioned the machine with the help of some shell scripting so that it has node.js installed and is running a MongoDB database.
</li><li> Installed version 1 of the QuoteFinder app.
</li><li> Started the machine and let it set everything up.
</li><li> Started the QuoteFinder app and tested it to ensure that it is able to connect to the web client and the database.
</li><li> Edited a file in the QuoteFinder app and seen the app restart and the changes immediately go live.
</li></ol>

<p>Not bad for a first try, eh?
</p>
<p><strong class="strong">Cleanup</strong>
Run <code class="code">vagrant destroy -f</code> to take down the machine and scrub it from your computer. All that remains now is the Vagrantfile (Sadly, the edit we made is also lost because we never committed it), but that is also all we need to start the machine and re-provision it again.
</p>
</li><li> <a class="anchor" id="Docker"></a>Docker


<p>The next step is to microservice the app. QFStandalone is still simple enough so that it will be run as a single microservice. However, we want to run the database as a separate microservice. If nothing else, this will mean that any books that we add to the database will remain when we rebuild the QFStandalone image.
</p>
<p>This time, we are going to fetch the QuoteFinder app and pretend to do our development locally, so that we are only <em class="emph">deploying</em> as a microservice.
</p>
<p><strong class="strong">Tasks</strong>
0.[@0] Open up a terminal as before, create a new sub-directory e.g. <code class="code">QuoteFinder/Version1/docker</code> , and cd into it.
</p>
<ol class="enumerate">
<li> Clone the QuoteFinder repository: <code class="code">git clone https://github.com/mickesv/QuoteFinder/</code> ,  extract Version1 by copying it <code class="code">cp -r QuoteFinder/Containers/Version1 .</code>  , and cd into the directory <code class="code">cd Version1/QFStandalone</code>

</li><li> In this directory you will find a <code class="code">Dockerfile</code> , with instructions for docker on how to create a docker image from this directory (see also <a class="ref" href="#Dockerfile">Dockerfile</a> ).
</li></ol>

<div class="example">
<pre class="example-preformatted">FROM node:18-alpine
RUN npm install -g nodemon
EXPOSE 3000
WORKDIR /app
COPY . .
RUN npm install
ENV DEBUG='qfapp:*'
ENTRYPOINT [&quot;npm&quot;, &quot;run&quot;, &quot;dev&quot;]
</pre></div>

<p>Please take a moment to study this file and make sure you understand what each line does. Pay particular notice to the line <code class="code">WORKDIR /app</code> and the <code class="code">COPY . .</code> instructions. With these two instructions we set the working directory inside the image to <code class="code">/app</code> and copy everything from the current working directory on the host into the image&rsquo;s working directory. After these two instructions, everything that the image requires to get going is essentially in place, and all that is needed is to install dependencies from the just now inserted <code class="code">package.json</code>.
</p>
<ol class="enumerate" start="3">
<li> Build the image: <code class="code">docker build -t qfstandalone .</code> 
</li><li> Check that the image is indeed created: <code class="code">docker image ls</code> 
</li><li> For the sake of it, let&rsquo;s tag it as well: <code class="code">docker tag qfstandalone:latest mickesv/qfstandalone:version1</code> (replace &rsquo;mickesv&rsquo; with your username on Docker Hub). If you have an account on Docker Hub, you might also wish to push the image thither. Currently this has little meaning unless you wish to proudly distribute your own copy of QuoteFinder.
</li></ol>

<p>At this stage we can actually start the container, but it will not yet be able to connect to your database (you don&rsquo;t even have a database image installed yet). So we&rsquo;ll continue setting up things a while longer before we actually launch the app:
</p>
<ol class="enumerate" start="6">
<li> Download the &lsquo;<samp class="samp">mongo</samp>&rsquo; image: <code class="code">docker pull mongo</code>
</li><li> Create a virtual network, so that we might connect our two microservices: <code class="code">docker network create qfstandalone-net</code>
</li><li> Start the MongoDB container. This incantation has a few commands built in, so let&rsquo;s break it down first:
</li></ol>

<div class="example">
<pre class="example-preformatted">docker run                  # Start a Container
-d                          # In detached mode (in the background)
--network qfstandalone-net  # Connect to the virtual network we just created
--network-alias textstore   # Make this container accessible on the network using this name
--name textstore            # Use this name when we access the container with docker
mongo                       # Use this image as base for the container
</pre></div>

<p>In one line: <code class="code">docker run -d --network qfstandalone-net --network-alias textstore --name textstore mongo</code>
</p><ol class="enumerate" start="9">
<li> Now we are finally ready to start the QuoteFinder container. Again, let&rsquo;s break down the incantation first:
</li></ol>

<div class="example">
<pre class="example-preformatted">docker run                    # Start a container
-it                           # In interactive mode, and attach a terminal so we can also type into it
--network qfstandalone-net    # Same virtual network
-e TEXTSTORE_HOST=textstore   # Set the environment variable to the network alias of our MongoDB database
-w /app                       # Set the working directory inside the container
-v ./src:/app/src             # Attach the host directory ./src to the guest under /app/src
--name qfstandalone           # Docker name
-p 8080:3000                  # Connect host port 8080 to port 3000 in the container
mickesv/qfstandalone:version1 # Use this image (the tag we previously set)
</pre></div>

<p>One long string: <code class="code">docker run -it --network qfstandalone-net -e TEXTSTORE_HOST=textstore -w /app -v ./src:/app/src --name qfstandalone -p 8080:3000 mickesv/qfstandalone:version1</code> 
</p>
<ol class="enumerate" start="10">
<li> We can now test the app. Open a web browser to <a class="uref" href="http://localhost:8080/add">http://localhost:8080/add</a> and click the &rsquo;Add&rsquo; button to add a book to your database. Your terminal window where the app is running will print some info, hopefully ending with <em class="emph">Text added.</em> If not, make note of any error messages printed.

</li><li> Go to <a class="uref" href="http://localhost:8080/">http://localhost:8080/</a> and search for something, e.g. &rsquo;prince&rsquo;. This will give a list of hits. Remember to keep an eye on the output in the terminal.

</li><li> Let us now test editing the app. On your host machine, open up the file <code class="code">src/index.js</code> , find the function &lsquo;<samp class="samp">startPage()</samp>&rsquo;, replace the return line with &lsquo;<samp class="samp">return listTextsPage(req, res);</samp>&rsquo; and save. Notice that the app is reloaded directly, and when you reload the start page in your web browser you will now see a list of available texts.
</li></ol>

<p>The reason why this works so much more seamlessly compared to the full-virtual-machine approach we tried before is because we are mounting the host directory into the guest with the <code class="code">-v ./src:/app/src</code> flag. In effect, we are replacing the entire &lsquo;<samp class="samp">src</samp>&rsquo; directory inside the container with whatever we have saved locally, thus overloading whatever we put in there when we created the image. If we remove the &lsquo;<samp class="samp">-v</samp>&rsquo; flag, we will revert back to whatever was in there when we created the image. As before, <code class="code">nodemon</code> restarts for us if it detects that a file has been changed.
</p>
<p>If you look in the &lsquo;<samp class="samp">Version1/QFStandalone</samp>&rsquo; directory on your host computer, you will notice that it only contains the code that you yourself have created (or, &lt;ahem!&gt;, yours truly :-) . There is no directory <code class="code">node_modules</code> , and there is no <code class="code">package-lock.json</code>. These are created <em class="emph">inside</em> the container, and actually already inside the image. This is nice, you do not clutter your own disk with lots of node.js cruft (you actually do not even need to have node.js installed locally), but it does mean that you need to rebuild the image when you want to add a package dependency to your <code class="code">package.json</code>. This is a slight hassle, but as a consolation it does not happen very often once you have settled on an architecture for your system.
</p><ol class="enumerate" start="13">
<li> Are we still running? Check with <code class="code">docker ps</code> to see what containers are up and running.
</li></ol>

<p><strong class="strong">Summary</strong>
We have now:
</p><ol class="enumerate">
<li> Cloned the QuoteFinder application to our local machine
</li><li> Created a Dockerfile and a Docker image for Version1/QFStandalone.
</li><li> Downloaded a MongoDB docker image
</li><li> Created a virtual network
</li><li> Started a MongoDB database as a microservice
</li><li> Started Version1/QFStandalone as a microservice
</li><li> Connected Version1/QFStandalone with MongoDB using our virtual network and started the app so that we may test it.
</li><li> Edited a file locally and see the running app inside the container restart to reflect the updated version.
</li></ol>

<p>Not bad for a <em class="emph">second</em> try, eh?
</p>
<p><strong class="strong">Cleanup</strong>
</p><div class="example">
<pre class="example-preformatted">docker rm -f textstore qfstandalone
docker network rm qfstandalone-net
docker network prune -f
</pre></div>

<p><strong class="strong">Remaining Pain Points</strong>
</p><div class="example">
<pre class="example-preformatted"> _______________________________________
( If only there was a way to create the )
( virtual network and connect the       )
( microservices with a single command   )
( rather than having to memorise arcane )
( command line parameters...            )
 ---------------------------------------
        o   ^__^
         o  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||
</pre></div>
</li></ol>

<hr>
</div>
<div class="section-level-extent" id="A-Minimal-Qemu-Vagrantfile">
<div class="nav-panel">
<p>
Previous: <a href="#Installing-and-Running-QFStandalone" accesskey="p" rel="prev">Installing and Running QFStandalone</a>, Up: <a href="#Let_0027s-get-Practical" accesskey="u" rel="up">Let&rsquo;s get Practical</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="A-Minimal-Qemu-Vagrantfile-1">6.4 A Minimal Qemu Vagrantfile</h3>

<p>In case you want to run Qemu, here is a minimal Vagrantfile for you to start from. If you use e.g. Virtualbox, you will not need this.
</p>
<div class="example">
<pre class="example-preformatted">Vagrant.configure(&quot;2&quot;) do |config|
  # Some of these things may not be necessary, but it does yield a smoother setup.
  config.vm.synced_folder &quot;.&quot;, &quot;/vagrant&quot;, type: &quot;rsync&quot;
  config.vm.boot_timeout = 999999
  config.ssh.insert_key = false
  config.vm.box_check_update = false

  # This is the most important section where you define the parameters for qemu/libvirt
  config.vm.provider :libvirt do |libvirt|
    # Don't forget to create your storage pool
    libvirt.storage_pool_name=&quot;default&quot;
    libvirt.driver=&quot;kvm&quot;
    libvirt.uri=&quot;qemu:///system&quot;
    libvirt.memory = 1024
    libvirt.graphics_type = &quot;none&quot;
    libvirt.cpus = 1
  end

  # And this is just your bog standard Vagrantfile to fire up one virtual machine
  # using bento/ubuntu-18.04 and the name &quot;test_machine&quot;
  config.vm.box = &quot;bento/ubuntu-18.04&quot;
  config.vm.define &quot;test_machine&quot; do |node|
  end
end
</pre></div>

<hr>
</div>
</div>
<div class="chapter-level-extent" id="Quiz-Let_0027s-get-Practical">
<div class="nav-panel">
<p>
Next: <a href="#Provisioning-and-Orchestration" accesskey="n" rel="next">Provisioning and Orchestration</a>, Previous: <a href="#Let_0027s-get-Practical" accesskey="p" rel="prev">Let&rsquo;s get Practical</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Quiz_003a-Let_0027s-get-Practical">7 Quiz: Let&rsquo;s get Practical</h2>

<p>Please answer the following questions:
</p>
<ol class="enumerate">
<li> QFStandalone depends on five javascript packages. In what file are these dependencies specified?
</li><li> The dependencies are never installed on your host computer. How do you instruct Docker that they should be installed?
</li><li> How do you instruct Vagrant that they should be installed?
</li><li> Which file/javascript module is responsible for setting up the http routes?
</li><li> What are the responsibilities of the &lsquo;<samp class="samp">SimpleTextManager</samp>&rsquo; class?
</li><li> What are the responsibilities of the file &lsquo;<samp class="samp">textStore.js</samp>&rsquo; ?
</li><li> The function &lsquo;<samp class="samp">index.js::searchTexts()</samp>&rsquo; is mostly built up around promises. Where is the first Promise created?
</li><li> Briefly outline what you would need to do if you wish to add a dependency to a new javascript package in your Vagrant solution.
</li><li> Briefly outline what you would need to do if you wish to add a dependency to a new javascript package in your Docker solution.
</li></ol>

<p>There is a Quiz on Canvas where you can submit your article summaries and answers to the questions.
</p>
<p><strong class="strong">NOTICE:</strong> <em class="emph">This quiz does not contribute to the grade in the course. We do, however, require of you to submit the quiz on time.</em> The purpose of this quiz is to serve as a learning aid allowing you to think about these concepts, and for us to keep track of your progress in the course. If you are unable to maintain the study pace required to submit this quiz on time, we want to be made aware of this so that you are able to re-plan your commitment for the remainder of the course.
</p>
<hr>
</div>
<div class="chapter-level-extent" id="Provisioning-and-Orchestration">
<div class="nav-panel">
<p>
Next: <a href="#Quiz-Provisioning-and-Orchestration" accesskey="n" rel="next">Quiz: Provisioning and Orchestration</a>, Previous: <a href="#Quiz-Let_0027s-get-Practical" accesskey="p" rel="prev">Quiz: Let&rsquo;s get Practical</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Provisioning-and-Orchestration-1">8 Provisioning and Orchestration</h2>


<ul class="mini-toc">
<li><a href="#Provisioning" accesskey="1">Provisioning</a></li>
<li><a href="#Orchestration" accesskey="2">Orchestration</a></li>
<li><a href="#Docker-Compose" accesskey="3">Docker Compose</a></li>
<li><a href="#Cloud-Orchestration" accesskey="4">Cloud Orchestration</a></li>
</ul>
<hr>
<div class="section-level-extent" id="Provisioning">
<div class="nav-panel">
<p>
Next: <a href="#Orchestration" accesskey="n" rel="next">Orchestration</a>, Up: <a href="#Provisioning-and-Orchestration" accesskey="u" rel="up">Provisioning and Orchestration</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Provisioning-1">8.1 Provisioning</h3>

<a class="index-entry-id" id="index-Provisioning-1"></a>
<p>Whether we are setting up a physical computer, a virtual machine, or a microservice, we need to configure it and decide which software should be installed. This process is called <em class="emph">Provisioning</em>. When we are installing a computer or a full virtual machine, it is possible to do this by logging on to the machine and installing software interactively. The downside to this is that we create a fragile system where any particular installation may break the system in new and creative ways. When this happens, our only available solution may be to tear down the entire machine and re-install it from scratch again.
</p>
<p>As good engineers we of course maintain a logbook of everything we do to the machine, in what order, and any errors or warnings that we get during the installation process so that we may go back and analyse what went wrong and try a different approach next time.
</p>
<p>As better engineers, we encode our installation into a <em class="emph">script</em> that the computer can run for us. Eventually we are able to review the log output to see what went wrong and how to modify the installation script.
</p>
<p>We have already seen two forms of provisioning; the one we made with Docker, and the one we made with Vagrant. Let us examine the differences.
</p>
<p>With Docker we started with an almost ready machine (&lsquo;<samp class="samp">FROM node:18-alpine</samp>&rsquo;) , and the focus was to install <em class="emph">anything else</em> that we needed and to further configure the microservice image. We also had to repeat some of this configuration on the command line when we started a container based on this image.
</p>
<p>With Vagrant we started with a relatively clean linux install ( <code class="code">config.vm.box=&quot;bento/ubuntu-20.04&quot;</code> ), and then had to execute a series of shell commands in order to install the rest. We can not compare with the docker install straight off since we also installed a MongoDB database, and we downloaded the entire QuoteFinder repository (not just its dependencies) inside the virtual machine, but if you go back and look, you will notice that there was a bit of <code class="code">sudo apt-get update</code>, <code class="code">sudo apt-get install -y</code>, some <code class="code">echo</code> and <code class="code">cd here/and/there</code> , and some copying of files with &lsquo;<samp class="samp">cp</samp>&rsquo; . All the things you could expect to do interactively, but saved in the Vagrantfile to be able to run and re-run the provisioning at will. Technically, we <em class="emph">can</em> do all of this in our Dockerfile too, but there is generally less need for it.
</p>
<a class="index-entry-id" id="index-Ansible"></a>
<a class="index-entry-id" id="index-Chef"></a>
<a class="index-entry-id" id="index-Puppet"></a>
<a class="index-entry-id" id="index-YAML-Ansible"></a>
<p>If we do not wish to get our hands dirty with shell provisioning, we can use provisioning software instead. For example, Ansible <a class="uref" href="https://docs.ansible.com/ansible/latest/getting_started/index.html">https://docs.ansible.com/ansible/latest/getting_started/index.html</a> specifies the machines we have and their respective desired state in a collection of YAML-files, whereas Chef <a class="uref" href="https://www.chef.io/">https://www.chef.io/</a> and Puppet <a class="uref" href="https://www.puppet.com/">https://www.puppet.com/</a> use their own homegrown language. While there are important differences (e.g. whether new configurations are <em class="emph">pushed</em> to each machine or <em class="emph">pulled</em> from a central repository, and whether the tools are open source or not), the overall idea is to specify a desired state for each machine rather than specific shell instructions (potentially only valid for a specific linux dialect) for how to get to that state.
</p>
<p>An added benefit to provisioning tools like this is that it is possible to update the desired state and let the provisioning tools transfer your deployment to the new state in a controlled manner.
</p>
<hr>
</div>
<div class="section-level-extent" id="Orchestration">
<div class="nav-panel">
<p>
Next: <a href="#Docker-Compose" accesskey="n" rel="next">Docker Compose</a>, Previous: <a href="#Provisioning" accesskey="p" rel="prev">Provisioning</a>, Up: <a href="#Provisioning-and-Orchestration" accesskey="u" rel="up">Provisioning and Orchestration</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Orchestration-1">8.2 Orchestration</h3>

<a class="index-entry-id" id="index-Orchestration"></a>
<p>As the number of services we wish to deploy grows (actually, as soon as it grows to more than one, e.g. an application and a database), there is a need to manage the collection of deployments. An application may, for example, consist of several collaborating virtual machines, each requiring a specific provisioning and configuration of ports to forward, or there may be a desire to create more instances of the database and have some form of load balancing between them. This additional step is called <em class="emph">Orchestration</em>. Vagrant does both; orchestration of which virtual machines to start ( for example, <code class="code">config.vm.define &quot;app&quot;</code> creates one machine named &ldquo;app&rdquo;), and the provisioning of them ( &lsquo;<samp class="samp">config.vm.provision &quot;shell&quot;</samp>&rsquo; ). This is practical for smaller setups, but the desire to <em class="emph">separate concerns</em> means that it is soon desirable to delegate the provisioning to a provisioning tool such as Ansible and leave the Vagrantfile responsible only for the orchestration.
</p>
<p>With Vagrant, adding more machines is as easy as adding additional blocks of &lsquo;<samp class="samp">config.vm.define</samp>&rsquo;. For each defined virtual machine, the network alias, preferred IP address, and forwarded ports can be configured. Additional provisioning can also be added for each machine, but I would advise against this: it is better to rely on your designated provisioning tool for <em class="emph">all</em> provisioning, and only include as little as is necessary to bootstrap this provisioning tool in your Vagrantfile. Separation of Concerns for the win!
</p>
<hr>
</div>
<div class="section-level-extent" id="Docker-Compose">
<div class="nav-panel">
<p>
Next: <a href="#Cloud-Orchestration" accesskey="n" rel="next">Cloud Orchestration</a>, Previous: <a href="#Orchestration" accesskey="p" rel="prev">Orchestration</a>, Up: <a href="#Provisioning-and-Orchestration" accesskey="u" rel="up">Provisioning and Orchestration</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Docker-Compose-1">8.3 Docker Compose</h3>

<a class="index-entry-id" id="index-Docker-Compose"></a>
<p>Docker&rsquo;s focus is on provisioning a single image, which is then used as a template to start one or more containers. As noticed, already with two containers the command line incantations to set up a virtual network and hook up the microservices to this becomes quite a mouthful. The next step up is to define all the infrastructure in a separate file, and use &lsquo;<samp class="samp">docker compose</samp>&rsquo; to compose your application of several microservices, storage volumes, networks, etc.
</p>
<a class="index-entry-id" id="index-YAML-Docker-Compose"></a>
<p>Docker Compose uses a YAML file to define the services, networks, volumes, etc. that should be configured and started. A Docker compose file for the previous Version 1 of the QuoteFinder app can, for example, look as follows:
</p>
<div class="example">
<pre class="example-preformatted">version: &quot;3.8&quot;
services:
  app:
    image: qfstandalone
    ports:
      - 8080:3000
    volumes:
      - ./Containers/Version1/QFStandalone/src:/app/src
    environment:
      TEXTSTORE_HOST: textstore
  textstore:
    image: mongo
    command: --quiet --syslog
    expose:
      - &quot;27017&quot;
</pre></div>

<p>And is started with &lsquo;<samp class="samp">docker compose -f docker-compose-v1.yml up</samp>&rsquo;. I am not a fan of languages where white-space has a semantic meaning, but with YAML we are unfortunately forced to accept this. Going through the example above, we see that we define two services, &lsquo;<samp class="samp">app</samp>&rsquo; and &lsquo;<samp class="samp">textstore</samp>&rsquo;, each based on a separate docker image (qfstandalone and mongo, respectively). Unless otherwise specified, MongoDB is quite chatty so the &lsquo;<samp class="samp">command:</samp>&rsquo; line is basically telling it to shut up and log things using the system logger instead. Do note that the network is implicitly defined, which is a relief.
</p>
<hr>
</div>
<div class="section-level-extent" id="Cloud-Orchestration">
<div class="nav-panel">
<p>
Previous: <a href="#Docker-Compose" accesskey="p" rel="prev">Docker Compose</a>, Up: <a href="#Provisioning-and-Orchestration" accesskey="u" rel="up">Provisioning and Orchestration</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Cloud-Orchestration-1">8.4 Cloud Orchestration</h3>

<p>So now you have your Vagrantfile or your docker compose-file and are able to deploy any number of machines or services locally. The next step up is to deploy to a cloud provider instead. Vagrant has rudimentary support for this since one may define several &lsquo;<samp class="samp">provider</samp>&rsquo; blocks in the Vagrantfile, and determine at startup time whither to deploy: &lsquo;<samp class="samp">vagrant up --provider &lt;some provider&gt;</samp>&rsquo; . Docker compose, on the contrary, does not easily support this. 
</p>
<a class="index-entry-id" id="index-Terraform"></a>
<a class="index-entry-id" id="index-Kubernetes"></a>
<p>What if you want to deploy to several providers in one go? What if you want to first deploy a small set of servers, and then declaratively extend this set as the load increases? Terraform <a class="uref" href="https://developer.hashicorp.com/terraform">https://developer.hashicorp.com/terraform</a> is one example of a tool for this. If your application is constructed only with microservices, then Kubernetes <a class="uref" href="https://kubernetes.io/">https://kubernetes.io/</a> is the docker-equivalent. As far as I can tell, these two tools solve the same problem but for virtual machines versus microservices. Eventually, we will foray into Kubernetes with the QuoteFinder app, but not quite yet.
</p>
<a class="index-entry-id" id="index-SaltStack"></a>
<a class="index-entry-id" id="index-Hadoop"></a>
<p>Yet one more alternative worth mentioning is Salt and its SaltStack <a class="uref" href="http://saltstack.com/">http://saltstack.com/</a> . In many ways, Salt is a combination of a provisioning tool and an orchestration tool. Once a salt infrastructure is set up (with the ever so cool and hip names &lsquo;<samp class="samp">salt-master</samp>&rsquo; and &lsquo;<samp class="samp">salt-minions</samp>&rsquo; ), one distributes jobs across this infrastructure. These jobs may be to query a minion for some state, or to run a specific (UNIX) command on a particular minion. This also means that you can distribute any software to the minions so you can use and re-use your salt infrastructure over and over again with new jobs. In that sense, it is closer to parallel computing platforms such as Hadoop, or even Lambda Functions on e.g Azure or Amazon Web Services.
</p>
<hr>
</div>
</div>
<div class="chapter-level-extent" id="Quiz-Provisioning-and-Orchestration">
<div class="nav-panel">
<p>
Next: <a href="#Application-Design-and-Development" accesskey="n" rel="next">Application Design and Development</a>, Previous: <a href="#Provisioning-and-Orchestration" accesskey="p" rel="prev">Provisioning and Orchestration</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Quiz_003a-Provisioning-and-Orchestration">9 Quiz: Provisioning and Orchestration</h2>

<p><strong class="strong">TODO</strong> Please read the following articles and resources:
</p>
<ol class="enumerate">
<li> Rahman, A., Rahman, M. R., Parnin, C., &amp; Williams, L. (2021). Security smells in ansible and chef scripts: A replication study. ACM Transactions on Software Engineering and Methodology (TOSEM), 30(1), 1-31.
</li><li> Taibi, D., Lenarduzzi, V., &amp; Pahl, C. (2018). Architectural patterns for microservices: a systematic mapping study. In CLOSER 2018: Proceedings of the 8th International Conference on Cloud Computing and Services Science; Funchal, Madeira, Portugal, 19-21 March 2018. SciTePress.
</li><li> Khazaei, H., Barna, C., Beigi-Mohammadi, N., &amp; Litoiu, M. (2016, December). Efficiency analysis of provisioning microservices. In 2016 IEEE International conference on cloud computing technology and science (CloudCom) (pp. 261-268). IEEE.
</li><li> Esteban Elias Romero, Carlos David Camacho, Carlos Enrique Montenegro, Óscar Esneider Acosta, Rubén González Crespo, Elvis Eduardo Gaona, and Marcelo Herrera Martínez. 2022. Integration of DevOps Practices on a Noise Monitor System with CircleCI and Terraform. ACM Trans. Manage. Inf. Syst. 13, 4, Article 36 (December 2022), 24 pages.
</li></ol>

<p>These articles provide different viewpoints with which to start composing your architecture solution. First, the underlying software architecture decisions shape the possible solutions. Second, all the quality requirements (not the least including security) are still important and must be considered both on the architecture level and on the implementation level. Third, fancy principles and lofty software architectures are well and good, but once you start deploying your solution to a particular cloud provider using a particular technology stack, things soon get ugly.
</p>
<p><strong class="strong">TODO</strong> Summarise each article/resource (no more than 1/2 page each) according to the following:
</p>
<ul class="itemize mark-bullet">
<li>Authors (if available/applicable) and Title of the article
</li><li>Briefly, what is the article about?
</li><li>What have they measured?
</li><li>What are their main findings?
</li><li>What can you learn from this article?
</li></ul>

<p><strong class="strong">TODO</strong> Answer the following questions:
</p><ul class="itemize mark-bullet">
<li>What is provisioning?
</li><li>What is orchestration?
</li><li>Why do you want separate tools for provisioning and orchestration?
</li><li>What is Service Oriented Architecture (SOA)?
</li><li>What &ldquo;is Software-As-A-Service&rdquo; (SAAS)?
</li></ul>

<p>There is a Quiz on Canvas where you can submit your article summaries and answers to the questions.
</p>
<p><strong class="strong">NOTICE:</strong> <em class="emph">This quiz does not contribute to the grade in the course. We do, however, require of you to submit the quiz on time.</em> The purpose of this quiz is to serve as a learning aid allowing you to think about these concepts, and for us to keep track of your progress in the course. If you are unable to maintain the study pace required to submit this quiz on time, we want to be made aware of this so that you are able to re-plan your commitment for the remainder of the course.
</p>
<hr>
</div>
<div class="chapter-level-extent" id="Application-Design-and-Development">
<div class="nav-panel">
<p>
Next: <a href="#Let_0027s-get-Practical-Again" accesskey="n" rel="next">Let&rsquo;s get Practical Again</a>, Previous: <a href="#Quiz-Provisioning-and-Orchestration" accesskey="p" rel="prev">Quiz: Provisioning and Orchestration</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Application-Design-and-Development-1">10 Application Design and Development</h2>


<ul class="mini-toc">
<li><a href="#Principles-of-Microservice-Architectures" accesskey="1">Principles of Microservice Architectures</a></li>
<li><a href="#Cloud-Architecture-Patterns" accesskey="2">Cloud Architecture Patterns</a></li>
<li><a href="#Introduction-to-YAML-and-Docker_002dComposeyml" accesskey="3">Introduction to YAML and Docker-Compose.yml</a></li>
</ul>
<hr>
<div class="section-level-extent" id="Principles-of-Microservice-Architectures">
<div class="nav-panel">
<p>
Next: <a href="#Cloud-Architecture-Patterns" accesskey="n" rel="next">Cloud Architecture Patterns</a>, Up: <a href="#Application-Design-and-Development" accesskey="u" rel="up">Application Design and Development</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Principles-of-Microservice-Architectures-1">10.1 Principles of Microservice Architectures</h3>

<a class="index-entry-id" id="index-Scalability"></a>
<a class="index-entry-id" id="index-Maintainability"></a>
<p>The key quality requirement for cloud architecture patterns is <em class="emph">Scalability</em>. This is a bit unusual, since most modularisation efforts rather focus on <em class="emph">Maintainability</em>. Digging deeper, the goal is of course always to create a maintainably scalable solution, i.e. where scalability is built in and therefore any maintainability task that deals with scaling the application should be easy to do.
</p>
<a class="index-entry-id" id="index-Vertical-Scaling"></a>
<a class="index-entry-id" id="index-Horizontal-Scaling"></a>
<p>Trivially, an application can scale in two directions, i.e. <em class="emph">vertically</em> by adding more resources within each node (e.g. faster CPU&rsquo;s, more memory, bigger disks), or <em class="emph">horizontally</em> by adding more nodes. One refers to this as <em class="emph">vertically scaling up</em>, and <em class="emph">horizontally scaling out</em>. The goals of both these types of scalability is to support more concurrent users or jobs, or to decrease response times.
</p>
<a class="index-entry-id" id="index-Reliability"></a>
<a class="index-entry-id" id="index-Extensibility"></a>
<p>Using the same scalability mechanisms, one can also increase <em class="emph">reliability</em> of an application, e.g. by adding redundant nodes and a load balancer. Moreover, and this becomes more prevalent in microservice architectures, we can create an <em class="emph">extensible</em> architecture where it is easy to add new functionality as standalone nodes in a microservice network.
</p>
<p>B Wilder, <em class="emph">Cloud Architecture Patterns</em>, O&rsquo;Reilly, 2012. ISBN: 978-1-449-31977-9, defines some boundaries for cloud applications, that define the types of solutions one is able to imagine. Specifically, they enumerate:
</p>
<a class="index-entry-id" id="index-Elastic-Scaling"></a>
<a class="index-entry-id" id="index-Metered-Billing"></a>
<a class="index-entry-id" id="index-IAC-Infrastructure-As-Code"></a>
<dl class="table">
<dt>(The illusion of) Infinite Resources</dt>
<dd><p>Meaning, horizontal scaling is easy and preferred. It also means that there is no upper limit to how many services you can use to deploy in your application.
</p></dd>
<dt>Elastic Scaling</dt>
<dd><p>When more resources are needed, they are available, but equally important is that you are able to release resources when they are no longer needed.
</p></dd>
<dt>Metered Billing</dt>
<dd><p>This is the term that Rosenberg &amp; Mateos, <em class="emph">The cloud at your service</em>. Manning Publications Co. 2010. uses. You only pay for the resources that are currently being used. Again, the idea is to lull you into thinking that resources are infinite and infinitely cheap.
</p></dd>
<dt>Automation</dt>
<dd><p>This scaling up and down is managed through automated tools, where the currently desired platform is programmatically expressed (Infrastructure as Code). There is no need for manual intervention by a platform engineer e.g. to make new resources available, or for new contracts to be negotiated for every change in the required cloud resources.
</p></dd>
</dl>

<p>As a developer of a cloud-native application, these principles are in fact more or less sufficient. The knowledge that new resources are always available and under the control of the application itself, as and when needed means that an application can be developed as a collection of standalone units. For the <em class="emph">cloud provider</em>, however, a few more principles are desirable to make this an economically viable business model:
</p>
<a class="index-entry-id" id="index-Pooled-Resources"></a>
<a class="index-entry-id" id="index-Multitenancy"></a>
<a class="index-entry-id" id="index-Virtualisation"></a>
<a class="index-entry-id" id="index-Commodity-Hardware"></a>
<dl class="table">
<dt>Multitenancy, or Pooled Resources</dt>
<dd><p>There may be any number of virtual resources running on each physical hardware unit, and any single user of a cloud service or of cloud infrastructure is not aware of who else may be sharing the physical platform at any given point. Each resource has its own CPU, memory, and disk, and is not aware of what else may be running next to it (or what they are paying for).
</p></dd>
<dt>Virtualisation</dt>
<dd><p>In order to support the above, virtualisation of resources is a required technical solution. Without virtualisation, neither multitenancy, automation, nor elastic scaling, would be possible.
</p></dd>
<dt>Commodity Hardware</dt>
<dd><p>To further keep the costs down for the cloud provider, it is desirable to avoid any specialised hardware. For example the CPUs, memory units, and hard drives should be as close to off-the-shelf units as possible, that could just as well be installed in a desktop computer.
</p></dd>
</dl>

<p>Where the first group of principles <em class="emph">enabled</em> cloud native applications, these additional principles <em class="emph">restrict</em> the solutions. Critically, a cloud application can never be sure that a specific resource is available at a specific point in time. It might, for example, be in the process of migrating to a new hardware unit to make room for another customer&rsquo;s request for a bigger resource, or the hard disk may fail. As usual (to use a Swedish expression), what you gain on the carousel, you loose on the swings. The cost per time unit for a specific cloud resource may be low, but this is somewhat balanced by the cost of the development time to create a fault-tolerant application.
</p>
<a class="index-entry-id" id="index-Platform-Service-Ecosystem"></a>
<dl class="table">
<dt>Platform Service Ecosystem</dt>
<dd><p>This is one last piece of the puzzle for a cloud native application. A cloud solution requires more than just virtual CPU power. For example, data storage, a message bus, network facilities, monitoring facilities, the ability to move the application closer to its users, etc., may also be required for a complete cloud application. Different cloud providers may provide a more or less rich ecosystem of platform services. When selecting between different cloud providers, these extra services may and should factor in the decision.
</p></dd>
</dl>

<hr>
</div>
<div class="section-level-extent" id="Cloud-Architecture-Patterns">
<div class="nav-panel">
<p>
Next: <a href="#Introduction-to-YAML-and-Docker_002dComposeyml" accesskey="n" rel="next">Introduction to YAML and Docker-Compose.yml</a>, Previous: <a href="#Principles-of-Microservice-Architectures" accesskey="p" rel="prev">Principles of Microservice Architectures</a>, Up: <a href="#Application-Design-and-Development" accesskey="u" rel="up">Application Design and Development</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Cloud-Architecture-Patterns-1">10.2 Cloud Architecture Patterns</h3>

<p>B Wilder, <em class="emph">Cloud Architecture Patterns</em>, O&rsquo;Reilly, 2012 is a good starting point for the basic structures available to create scalable software architecture solutions for cloud native applications. Below is a brief summary of some of the patterns in this book; for details I encourage you to read the book yourself.
</p>

<p><strong class="strong">Horizontally Scaling Compute Pattern</strong> and the <strong class="strong">Auto-Scaling Pattern</strong>
Together, these two patterns suggest to prefer horizontal scaling and to use automated tools to request this scaling. When using horizontal scaling, each component in the application can more or less be single-threaded and should be kept as simple as possible. As I&rsquo;m sure have been hammered into you by now, any time you are forced to write multi-threaded code an angel loses their wings.
</p>
<div class="example">
<pre class="example-preformatted">             ,        ,
            /(        )`
            \ \___   / |
            /- _  `-/  '
           (/\/ \ \   /\
           / /   | `    \
           O O   ) /    |
           `-^--'`&lt;     '
          (_.)  _  )   /
           `.___/`    /
             `-----' /
&lt;----.     __ / __   \
&lt;----|====O)))==) \) /====
&lt;----'    `--' `.__,' \
             |        |
              \       /
         ______( (_  / \______
       ,'  ,-----'   |        \
       `--{__________)        \/
</pre></div>

<p>Challenges with horizontal scaling includes the need to be absolutely sure about the billing model the cloud provider uses, how to deal with session state, and how to update the nodes with a minimum of application downtime.
</p>

<p><strong class="strong">Queue-Centric Workflow Pattern</strong>
This pattern is used to make the nodes more loosely connected. Without this pattern, when one node wishes to communicate something to another node (For example, a control message or a job request), it first needs to find the right instance of the other node, and then wait for it to become available to receive the message. Meanwhile, the first node is also unavailable for new requests.
</p>
<p>With the queue pattern in place, rather than going directly to the other node, the message is placed in a queue, and the first node can go back to being available. When one instance of the receiving node type becomes available, it will collect the messages in turn from the message queue and act upon them. This pattern is usually not relevant for read-only requests, since it is desirable to keep these synchronous. Rather, it is used when a job can be launched asynchronously and the calling node need not wait for the job to finish.
</p>
<p>The actual queue can be implemented in many ways, either through a message bus provided by the cloud platform, a dedicated MQTT <a class="uref" href="https://mqtt.org/">https://mqtt.org/</a> solution running on a separate node, or using some storage resource already available to all nodes (e.g. a shared filesystem or a database).
</p>
<p>The queue should be more reliable than the nodes acting on the data so that no messages are lost, and it should be possible to re-process the same message multiple times with the same business result.
</p>

<a class="index-entry-id" id="index-MapReduce"></a>
<p><strong class="strong">MapReduce Pattern</strong>
This gives me a chance to write about my favourite programming language, <em class="emph">lisp</em>, where this pattern is an intrinsic part of any data processing. Surprisingly, it reappears in more modern programming languages as well, such as JavaScript and Java (with the introduction of the Streams API). The underlying principle of this programming pattern is to transform a list into another list by applying a function to each element in the list, i.e. a <em class="emph">map</em> from one domain to another. Multiple transformations can be daisy-chained through a series of <em class="emph">maps</em>, and often this is sufficient to process the data as required. Sometimes, something needs to be computed across an entire list, i.e. <em class="emph">reduce</em> the list down to for example a scalar. This is done by applying a function together with an accumulator variable to each element in the list.
</p>
<div class="example">
<pre class="example-preformatted">           map                 reduce
(a b c)  -------&gt; (a' b' c') ----------&gt; X
</pre></div>

<p>As it happens, this programming pattern is eminently suitable for scaling. In the extreme case, each application of the map function can be distributed to a separate node. Since each element in the list and the application of the map function on that element is independent from all other elements, they can be executed asynchronously, and the results collected and collated into the modified list. The reduce function can be trickier to distribute since there may be a dependency on that elements are reduced in a specific order. However, with some clever use of the right data structures (in particular the <em class="emph">dictionary</em> data structure), it is possible to create parallelisable versions of reduce functions as well.
</p>
<p>When parallelising this programming pattern e.g. in a cloud native application, important aspects to consider is to ensure that each element is truly independent of all other elements, and that the map function can operate on each element individually. Additional map/reduce steps may be necessary in order to preprocess the data to ensure this. Scalability-wise, there is an overhead cost for a new computing node, since data need to be pre-processed and distributed to the node and the results need to be collected and collated, so it is important to fine-tune the number of jobs assigned to each computing node for optimal performance.
</p>

<p><strong class="strong">Node Failure</strong> and <strong class="strong">Busy Signal</strong> patterns
The fundamental programming principle in a cloud native application is that <em class="emph">All application compute nodes should be ready to fail at any time.</em> As a corollary to this, all application compute nodes must be prepared that any other node is about to fail at any time.
</p>
<p>Protecting from sudden and unplanned node failures, data that should be persistent should be kept in a persistent storage, jobs that have not been completed should remain in the job queue, and one might consider to have a certain number of redundant nodes that can pick up the slack when a node fails.
</p>
<p>Nodes subjected to a planned failure (either planned by the cloud provider or by the application itself) have the luxury of both being able to complete what they are currently working on, gracefully removing themselves from accepting new jobs, and to alert e.g. load balancers that they are about to become unavailable.
</p>
<p>From the calling side (be it the end user or another node inside your application), it is important to maintain an updated list of available nodes, or delegate this to a load balancer or a worker queue. Calls between nodes should be programmed with a timeout to enable switching to an alternative strategy, should a node fail to reply. When a call times out, the options are to retry, wait a while and then retry, or switch to a backup node and retry. The &rsquo;retry&rsquo; strategy is often sufficient if there is a load balancer in place, since the new call is likely to end up on a new node anyway.
</p>
<p>When and whether to alert the load balancer that a node might be unavailable is another discussion.
</p>
<p>Sometimes, a node is not completely down, it is just unable to process the request right now. For example, it did not get all of the message, some other component it relies on was temporarily unavailable, or it was busy doing some maintenance work. In that case, the node should return a &ldquo;busy signal&rdquo;, for example a &lsquo;<samp class="samp">503 service unavailable</samp>&rsquo; return on a http request. Good clients recognise this busy signal and have strategies for dealing with this. Usually, a retry is sufficient, or maybe first wait a while and then retry.
</p>

<p><strong class="strong">Colocate Pattern</strong> and <strong class="strong">Multisite Deployment Pattern</strong>
Nodes that work closely together should also be located as close to each other as is possible. Later on, you will learn how tools such as Kubernetes have built this into their microservices deployment architecture.
</p>
<p>This principle extends to the end users. By deploying an application to many data centers across the world, users can be routed to the instance running closest to them, thereby reducing network latency. As it happens, this also enables redundancy in that if one data center fails, the work can be handed over to one of the application instances running on a different data center.
</p>
<p>There is an overhead and a cost in running multiple instances of an application &ndash; even when using the cloud provider&rsquo;s tools for moving the application around the world. Unless there is a tangible improvement in user experience, it may not be worth it to implement the multisite deployment pattern.
</p>
<p>Another consideration is whether your deployments across the globe should shrink and grow over the course of a single day, to accommodate for the fact that users in a particular region are more or less active during a day (e.g. more activity in the early evenings and less at night).
</p>

<p><strong class="strong">Content Delivery Network (CDN)</strong> and <strong class="strong">Valet Key</strong> patterns
Building a RESTful microservice usually means starting with some web framework in your programming environment (e.g. an express application in node.js). This means that you have an adequate or possibly decent web server that is good at executing the application code, but may not be great as a web server. If your application is serving a lot of static contents, then it may not be able to keep up with the dynamic requests that will execute your application code.
</p>
<p>The solution is to include a dedicated web server in your solution that is really good and optimised for serving static content. Either access this web server directly, or through dedicated nodes across the globe whose purpose is to cache oft-requested contents closer to the end-user. This network is solely focused on delivering contents and not bothered with anything else in your application. Specifically, the CDN does not deal with dynamic contents.
</p>
<p>Sometimes (oftentimes) the delivered content should only be available to the one user that requested it (or at least a limited list of users), or it should only be available for a specific period of time. That&rsquo;s where the Valet Key pattern comes in. When a user requests access to some content through your application, a unique URL is generated for this particular user, and the CDN server is instructed to make the requested resource available on that URL. This URL may also be set up to only work for a limited time. Moreover, the URL may be used to also upload contents instead of just downloading or streaming.
</p>
<p>If a really secure solution is desired, the URL should only be valid for a limited time and from a specific IP address. Furthermore, the contents can be encrypted so that the user must also have access to the decryption key.
</p>

<p><strong class="strong">Summary</strong>
The architecture patterns for cloud native applications are centered around the ability to scale up and down as needed (This is perhaps not very surprising), but the preference is to scale horizontally. Since the current state of the application (e.g. the number of available nodes of any particular type) can change at a moments notice, robust communication pathways using e.g. message queues are required. To some extent, this defines the execution view of the system&rsquo;s architecture, but with this definition comes a few limitations. Accepting that nodes can fail or be taken offline at any time means that applications need to be built with this in mind. Limitations in network speeds and a desire to make the best use of available computing resources influence where and how an application&rsquo;s services are deployed (e.g., which parts of an application that are co-located or distributed closer to the customers) and indeed what constitutes a service in the first place (e.g. inserting a content delivery network in the application). In a more conceptual focus, the desire to enable scaling implies restructuring algorithms into more scaling-friendly forms, for example the MapReduce pattern. Finally, an open architecture across multiple nodes and servers requires that security and access control is considered throughout the application, for example using temporary and time-limited access keys.
</p>
<hr>
</div>
<div class="section-level-extent" id="Introduction-to-YAML-and-Docker_002dComposeyml">
<div class="nav-panel">
<p>
Previous: <a href="#Cloud-Architecture-Patterns" accesskey="p" rel="prev">Cloud Architecture Patterns</a>, Up: <a href="#Application-Design-and-Development" accesskey="u" rel="up">Application Design and Development</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Introduction-to-YAML-and-Docker_002dCompose_002eyml">10.3 Introduction to YAML and Docker-Compose.yml</h3>

<a class="index-entry-id" id="index-YAML"></a>
<p>An increasing range of tools use YAML <a class="uref" href="https://yaml.org/spec/">https://yaml.org/spec/</a> to describe configurations. As mentioned before, this includes provisioning tools such as Ansible, and orchestration tools such as Docker Compose and Kubernetes (which we will eventually get to). There are of course other choices too, but it is a rather neat idea to be able to use a single grammar for all types of configurations. It is claimed that YAML is more readable than JSON (which I doubt) and XML (which I agree with). Below is a quick rundown of relevant YAML syntax (there is more, but this covers 90% of the cloud configuration use cases).
</p>
<div class="example">
<pre class="example-preformatted">---                          # Every new YAML node starts with three hyphens. You can often include many nodes in the same file.
Name: &quot;Arthur Dent&quot;          # Something with the key &quot;Name&quot; has the (string) value &quot;Arthur Dent&quot;
Age: 42                      # Integers and floats are also supported.
Active: true                 # ... as are booleans (true or false)
Friends: null                # ... and null values.
Inventory:                   # The value of the inventory key is a list.
  - Tea
  - No Tea
  - Towel
  - Babelfish
Desires: [ House, Clothes ]   # Lists can also be inlined
Address:                      # A Mapping (or a dictionary) is a set of key/value pairs, where each key is unique.
  Street: &quot;Vogon Intergalactic Bypass #47111&quot;
  City: &quot;What do you mean city? We work with the whole Universe!&quot;
  HouseNumber: 0
Contacts:                     # A list of mappings
  - Name: &quot;Ford Prefect&quot;
    Address: &quot;Anywhere, really. Just wave!&quot;
  - Name: &quot;Trillian&quot;
    Address: &quot;Heart of Gold&quot;
  - Name: &quot;Marvin&quot;
    Address: &quot;Everywhere, eventually.&quot;
Appearances:                  # Inlined mappings
  - {Title: &quot;The Hitchhiker's Guide to the Galaxy&quot;, Year: 1979}
  - {Title: &quot;The Restaurant at the End of the Universe&quot;, Year: 1980}
  - {Title: &quot;Life, the Universe and Everything&quot;, Year: 1982}
  - {Title: &quot;So Long, and thanks for All the Fish&quot;, Year: 1984}
  - {Title: &quot;Mostly Harmless&quot;, Year: 1992}
FavouritePoem: |             # Multi-line contents.
  Oh freddled gruntbuggly,
  Thy micturations are to me, (with big yawning)
  As plurdled gabbleblotchits, in midsummer morning
  On a lurgid bee,
  That mordiously hath blurted out,
  Its earted jurtles, grumbling
  Into a rancid festering confectious organ squealer. [drowned out by moaning and screaming]
...                          # Formally, a YAML ends with three dots. Can often be left out.
</pre></div>

<p>Do note that indentation matters. Apparently this is a popular design decision these days. I personally dislike this since I claim that whitespace should not carry semantic meaning. In my not so humble opinion, this choice decreases maintainability and readability.
</p>
<p>On to Docker Compose, then, the configuration of which is specified in a yaml file (Please see <a class="uref" href="https://docs.docker.com/compose/compose-file/">https://docs.docker.com/compose/compose-file/</a> for a full reference). In summary, the following can be specified:
</p>
<ul class="itemize mark-bullet">
<li>&lsquo;<samp class="samp">Services</samp>&rsquo; (required) correspond to your different microservices, i.e. the components with which you will build your system, and for each service you specify its configuration, and how to scale it etc.
</li><li>&lsquo;<samp class="samp">Networks</samp>&rsquo; Can be used to separate parts of your application into smaller networks. Usually, there is not much configuration to do per network.
</li><li>&lsquo;<samp class="samp">Volumes</samp>&rsquo; define persistent storage volumes. Persistent is key here; if you are only using a temporary storage inside a container, you do not need a volume, but if you want to store data that survives restarts of the container (or scaling of it), then you define a volume for this data. Typically, you will at least want volumes for use by your database service.
</li><li>&lsquo;<samp class="samp">Configs</samp>&rsquo; are used to modify the configuration inside a container without having to rebuild the image. For example, this can be done by superimposing a new configuration file over the one in the image.
</li><li>&lsquo;<samp class="samp">Secrets</samp>&rsquo; a special type of configs for sensitive data. It is good practice to keep configs and secrets separate to avoid accidentally exposing them (e.g. by committing a secret in the configuration management tool).
</li></ul>

<p>A brief example:
</p>
<div class="example">
<pre class="example-preformatted">services:
  name-of-some-service:
    image:            # docker image to base this service on
    ports:            # should match what you wrote in your Dockerfile
      - &quot;host:container&quot;
      - &quot;8080:3000&quot;
    volumes:
      - &quot;volume:container-path&quot;
      - db-data:/etc/data  # Mount the volume db-data inside the container on the path /etc/data.
  some-other-service:
    image:           # the image of some other service you want to run

volumes:
  db-data:
</pre></div>

<p>&hellip; And at this level, there really isn&rsquo;t much more to say about the yaml syntax.
</p>
<hr>
</div>
</div>
<div class="chapter-level-extent" id="Let_0027s-get-Practical-Again">
<div class="nav-panel">
<p>
Next: <a href="#Quiz-Design-Decisions-and-Development-Setup" accesskey="n" rel="next">Quiz: Design Decisions and Development Setup</a>, Previous: <a href="#Application-Design-and-Development" accesskey="p" rel="prev">Application Design and Development</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Let_0027s-get-Practical-Again-1">11 Let&rsquo;s get Practical Again</h2>


<ul class="mini-toc">
<li><a href="#Introducing-Version-2-of-the-QuoteFinder-app" accesskey="1">Introducing Version 2 of the QuoteFinder app</a></li>
<li><a href="#Installing-and-Running-Version-2-of-QuoteFinder" accesskey="2">Installing and Running Version 2 of QuoteFinder</a></li>
<li><a href="#Editing-the-Running-Application" accesskey="3">Editing the Running Application</a></li>
<li><a href="#Scaling-the-Deployment" accesskey="4">Scaling the Deployment</a></li>
<li><a href="#Cleanup-and-Summary" accesskey="5">Cleanup and Summary</a></li>
<li><a href="#Introducing-Version-3-of-the-QuoteFinder-app" accesskey="6">Introducing Version 3 of the QuoteFinder app</a></li>
</ul>
<hr>
<div class="section-level-extent" id="Introducing-Version-2-of-the-QuoteFinder-app">
<div class="nav-panel">
<p>
Next: <a href="#Installing-and-Running-Version-2-of-QuoteFinder" accesskey="n" rel="next">Installing and Running Version 2 of QuoteFinder</a>, Up: <a href="#Let_0027s-get-Practical-Again" accesskey="u" rel="up">Let&rsquo;s get Practical Again</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Introducing-Version-2-of-the-QuoteFinder-app-1">11.1 Introducing Version 2 of the QuoteFinder app</h3>

<a class="index-entry-id" id="index-QuoteFinder-Version-2"></a>
<p>Version 2 of the QuoteFinder app replaces the rudimentary search algorithm in the first version with something more complex that is able to look for the words <em class="emph">near</em> each other and not just directly adjacent to each other, and instead of returning just a certain number of characters around where the words were found, this version returns the full sentences where the words were found.
</p>
<p>I know. This is still not very complex and we could just as well continue to run this new search algorithm in a single service, but let us <em class="emph">imagine</em> that this is super-complex and require a not insignificant amount of time to go through a single text. Let us imagine that as the number of books in our database grows, a single user request to look for a quote will require the help of several worker nodes sifting through the database.
</p>
<p>The first and most obvious thing to do is to define an architecture that enables horizontal scaling, and that makes use of a message queue to dispatch jobs to the worker nodes.
</p>
<p><strong class="strong">QFApp Frontend</strong>
The first microservice, QFApp, is similar to the previous QFStandalone, in that it is an express app. Much of the code is similar, including the use of a MongoDB database to store the texts in. The main difference lies in what happens in the &lsquo;<samp class="samp">searchTexts()</samp>&rsquo; function. Rather than actually performing the search and format the resulting output, we are now invoking a &lsquo;<samp class="samp">Dispatcher</samp>&rsquo; to distribute the search jobs onto a message queue to be consumed elsewhere by a number of &lsquo;<samp class="samp">QFWorkers</samp>&rsquo;.
</p>
<a class="index-entry-id" id="index-Redis-1"></a>
<a class="index-entry-id" id="index-RSMQ"></a>
<p>The message queue used by the Dispatcher is really the first good hit I found on NPM, called the Real Simple Message Queue, or &lsquo;<samp class="samp">RSMQ</samp>&rsquo;. To be precise, I prefer the promise-enabled version of this queue &lsquo;<samp class="samp">RSMQPromise</samp>&rsquo;. This queue makes use of a Redis key-value store to enqueue and dequeue messages to and from, so we need to remember to add this to our deployment architecture.
</p>
<p>A challenge here, which should be a warning flag that this app is not really a good candidate for the queue centric architecture pattern, is that once the worker nodes are done they need a way to return what they find so that this can be returned to the web user. In this implementation the Dispatcher sets up a return queue, sends the jobs, waits for messages on the return queue, and then sends these on to the web interface using &lsquo;<samp class="samp">socket.io</samp>&rsquo; emit-calls.
</p>
<p><strong class="strong">QFWorker Backend</strong>
In contrast, the backend is much simpler. It connects to the job queue and listens for messages. The first one to pick a message gets it, and will go to town trying to find all the quotes. Once found, these are sent on the return queue, and eventually the QFWorker will either pick the next message if there is one, or go to sleep waiting for a new job.
</p>
<p>To make things more interesting and to continue imagining that this is a complex and resource intensive application, I have added a bit of vertical scaling in here as well: Every job consists of a single title in the database, and this title is split up into chunks (of &lsquo;<samp class="samp">CHUNKSIZE=1000</samp>&rsquo; lines), and a number of chunks ( &lsquo;<samp class="samp">MAXTHREADS=10</samp>&rsquo; ) are searched in parallel.
</p>
<p><strong class="strong">Data Format</strong>
One reason for this decision is that I want you to get used to thinking about your data architecture as well as your application and deployment architectures.
</p>
<p>Consider this: Each text is added to the database once, but is searched multiple times. If we keep the text as a single block in the database but still want to parallelise the search algorithm, then for every query we need to (a) fetch each entire text at once, and (b) split it into the desired chunk size. If we instead do this when we first add the text to the database, each search is made simpler because it only needs to fetch as many pre-split chunks as it currently need from the database, and then work on these. Less work for each search and less data to fetch before starting to analyse implies that we can start returning results sooner.
</p>
<p><strong class="strong">Summary</strong>
A conceptual view of QuoteFinder Version 2:
</p><div class="example">
<pre class="example-preformatted">+--------------+       +----------------+--------------+            +---------------+
| Web Client   +-------+ QFApp(Express) | Dispatch     |            | QFWorker      |
+--------------+       +----------+-----+------^-------+            +-----^--+------+
                                  |            |                          |  |
                                  |            |        +-----------+     |  |
                                  |            |        | Message   |     |  |
                                  |            +--------&gt; Queue     &lt;-----+  |
                                  |                     +-----+-----+        |
                                  |                           |              |
                              +---+--------+            +-----+-----+        |
                              | MongoDB    |            | Redis     |        |
                              +---+--------+            +-----------+        |
                                  |                                          |
                                  +------------------------------------------+
</pre></div>

<p>The overall process for a search:
</p><table class="multitable">
<thead><tr><th>Web Client</th><th>QFApp</th><th>QFWorker</th></tr></thead>
<tbody><tr><td></td><td></td><td>0. Listen on &rsquo;searchJob&rsquo; queue</td></tr>
<tr><td>1. search(words)</td><td></td><td></td></tr>
<tr><td>2. Listen on &lsquo;<samp class="samp">socket</samp>&rsquo; for results</td><td></td><td></td></tr>
<tr><td></td><td>3. List all texts in TextStore database</td><td></td></tr>
<tr><td></td><td>4. Create a job for each text</td><td></td></tr>
<tr><td></td><td>5. Create a return queue</td><td></td></tr>
<tr><td></td><td>6. Send all jobs to the &rsquo;searchJob&rsquo; queue</td><td></td></tr>
<tr><td></td><td>7. Listen on the return queue.</td><td></td></tr>
<tr><td></td><td></td><td>8. Pick first message in queue</td></tr>
<tr><td></td><td></td><td>9. Create N threads</td></tr>
<tr><td></td><td></td><td>10. [each thread] fetch chunk from TextStore database</td></tr>
<tr><td></td><td></td><td>11. [each thread] look for quote, compile results.</td></tr>
<tr><td></td><td></td><td>12. Collate and send results on return queue.</td></tr>
<tr><td></td><td></td><td>13. Goto 9 until no more chunks available</td></tr>
<tr><td></td><td></td><td>then goto 8 until no more messages</td></tr>
<tr><td></td><td></td><td>then goto 0.</td></tr>
<tr><td></td><td>14. Receive results on return queue.</td><td></td></tr>
<tr><td></td><td>15. send to web client&rsquo;s &lsquo;<samp class="samp">socket</samp>&rsquo;</td><td></td></tr>
<tr><td></td><td>16. Goto 7.</td><td></td></tr>
<tr><td>17. Display results.</td><td></td><td></td></tr>
<tr><td>18. Goto 2.</td><td></td><td></td></tr>
</tbody>
</table>

<p>Simple, isn&rsquo;t it?
</p>
<div class="example">
<pre class="example-preformatted">     ..
    (  |
 ... \  \ 
(...()   `-,
(....()    |
(...()     |
(..()...---'
</pre></div>

<hr>
</div>
<div class="section-level-extent" id="Installing-and-Running-Version-2-of-QuoteFinder">
<div class="nav-panel">
<p>
Next: <a href="#Editing-the-Running-Application" accesskey="n" rel="next">Editing the Running Application</a>, Previous: <a href="#Introducing-Version-2-of-the-QuoteFinder-app" accesskey="p" rel="prev">Introducing Version 2 of the QuoteFinder app</a>, Up: <a href="#Let_0027s-get-Practical-Again" accesskey="u" rel="up">Let&rsquo;s get Practical Again</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Installing-and-Running-Version-2-of-QuoteFinder-1">11.2 Installing and Running Version 2 of QuoteFinder</h3>

<p>You have already installed the required software stack (<code class="code">docker</code> and <code class="code">docker-compose</code>), so this time we can get started directly with defining the deployment architecture.
</p>
<p><strong class="strong">Tasks</strong>
</p><ol class="enumerate" start="0">
<li> Open up a terminal and enter your <code class="code">QuoteFinder</code> directory.

</li><li> Clone the QuoteFinder repository: <code class="code">git clone https://github.com/mickesv/QuoteFinder/</code>  (If you did this in the previous practice round, git will throw an error but that&rsquo;s ok)  extract Version 2 by copying it <code class="code">cp -r QuoteFinder/Containers/Version2 .</code>  , and cd into the directory <code class="code">cd Version2</code>

</li><li> This time you will find two sub-directories here, one for &lsquo;<samp class="samp">QFApp</samp>&rsquo; and one for &lsquo;<samp class="samp">QFWorker</samp>&rsquo;. As before, inside these directories you will find a Dockerfile. Please take a moment to study these two files. You will notice that they are almost the same. In fact, the only differences are that QFApp will expose port 3000, and that the &lsquo;<samp class="samp">DEBUG</samp>&rsquo; environment variable is different.

</li><li> Build the two images with the tag-names &lsquo;<samp class="samp">qfapp</samp>&rsquo; and &lsquo;<samp class="samp">qfworker</samp>&rsquo;, respectively.

</li><li> MongoDB is already downloaded, but you need to pull &lsquo;<samp class="samp">redis:alpine</samp>&rsquo; as well.

</li><li> Back up to the directory <code class="code">QuoteFinder/Version2/</code> and Create a file &lsquo;<samp class="samp">docker-compose-v2.yml</samp>&rsquo;.
</li></ol>

<p>In this file, you want to define the following &lsquo;<samp class="samp">services</samp>&rsquo;:
</p>
<ul class="itemize mark-bullet">
<li>&lsquo;<samp class="samp">app</samp>&rsquo; is based on the &lsquo;<samp class="samp">qfapp</samp>&rsquo; image
<ul class="itemize mark-bullet">
<li>make sure &lsquo;<samp class="samp">ports</samp>&rsquo; 8080:3000 are forwarded (port 3000 on the guest is forwarded to port 8080 on the host)
</li><li>the following &lsquo;<samp class="samp">environment</samp>&rsquo; variables are set:
&lsquo;<samp class="samp">REDIS_HOST: messagequeue</samp>&rsquo;
&lsquo;<samp class="samp">TEXTSTORE_HOST: textstore</samp>&rsquo;
</li></ul>
</li><li>&lsquo;<samp class="samp">worker</samp>&rsquo; is based on the &lsquo;<samp class="samp">qfworker</samp>&rsquo; image
<ul class="itemize mark-bullet">
<li>the following &lsquo;<samp class="samp">environment</samp>&rsquo; variables are set:
&lsquo;<samp class="samp">REDIS_HOST: messagequeue</samp>&rsquo;
&lsquo;<samp class="samp">TEXTSTORE_HOST: textstore</samp>&rsquo;
</li></ul>
</li><li>&lsquo;<samp class="samp">messagequeue</samp>&rsquo; is based on the image &lsquo;<samp class="samp">redis:alpine</samp>&rsquo;
<ul class="itemize mark-bullet">
<li>its starting &lsquo;<samp class="samp">command</samp>&rsquo; is &lsquo;<samp class="samp">redis-server</samp>&rsquo;
</li><li>it &lsquo;<samp class="samp">expose</samp>&rsquo; the port &ldquo;6379&rdquo;
</li><li>it mounts the following &lsquo;<samp class="samp">volumes</samp>&rsquo;
<ul class="itemize mark-bullet">
<li>&lsquo;<samp class="samp">redis-data:/data</samp>&rsquo;
</li><li>&lsquo;<samp class="samp">redis-conf:/usr/local/etc/redis/redis.conf</samp>&rsquo;
</li></ul>
</li></ul>
</li><li>&lsquo;<samp class="samp">textstore</samp>&rsquo; is based on the image &lsquo;<samp class="samp">mongo</samp>&rsquo;
<ul class="itemize mark-bullet">
<li>its &lsquo;<samp class="samp">command</samp>&rsquo; is &lsquo;<samp class="samp">--quiet --syslog</samp>&rsquo;
</li><li>it &lsquo;<samp class="samp">expose</samp>&rsquo; the port &ldquo;27017&rdquo;
</li><li>it mounts the following &lsquo;<samp class="samp">volumes</samp>&rsquo;
<ul class="itemize mark-bullet">
<li>&lsquo;<samp class="samp">textstore-data:/data/db</samp>&rsquo;
</li><li>&lsquo;<samp class="samp">mongo-config:/data/configdb</samp>&rsquo;
</li></ul>
</li></ul>
</li></ul>

<p>The volumes used need to be defined (it is, however, enough to mention them, no further configuration is necessary):
</p>
<div class="example">
<pre class="example-preformatted">volumes:
  redis-data:
  redis-conf:
  textstore-data:
  mongo-config:
</pre></div>

<p>Note that you are intentionally left to explore the docker-compose syntax on your own here. Play around and give it a try before cheating. And no, I&rsquo;m not going to tell you how to cheat.
</p>
<ol class="enumerate" start="7">
<li> Run <code class="code">docker compose -f docker-compose-v2.yml up</code>  to start your setup.

</li><li> Open a web browser to <a class="uref" href="http://localhost:8080/add">http://localhost:8080/add</a> and click the &rsquo;Add&rsquo; button to add a book to your database. Your terminal window where the app is running will print some info, hopefully ending with <em class="emph">Text added.</em> If not, make note of any error messages printed.

</li><li> Go to <a class="uref" href="http://localhost:8080/">http://localhost:8080/</a> and search for something, e.g. &rsquo;prince&rsquo;. This will give a list of hits. Remember to keep an eye on the output in the terminal.
</li></ol>

<hr>
</div>
<div class="section-level-extent" id="Editing-the-Running-Application">
<div class="nav-panel">
<p>
Next: <a href="#Scaling-the-Deployment" accesskey="n" rel="next">Scaling the Deployment</a>, Previous: <a href="#Installing-and-Running-Version-2-of-QuoteFinder" accesskey="p" rel="prev">Installing and Running Version 2 of QuoteFinder</a>, Up: <a href="#Let_0027s-get-Practical-Again" accesskey="u" rel="up">Let&rsquo;s get Practical Again</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Editing-the-Running-Application-1">11.3 Editing the Running Application</h3>

<p>In case you happened to skip directly to the search step, you will notice that the search fails on a timeout and the worker node does not seem to be functioning at all. Let us see if we can recreate this bug. In the console, press &lsquo;<samp class="samp">Ctrl-C</samp>&rsquo; to stop the running deployment, then re-run the same command as before but go directly to the search page <a class="uref" href="http://localhost:8080/">http://localhost:8080/</a> and repeat the previous search. If you had already added something, it is still there and you can not reproduce the bug. Please take a moment to consider why this is the case.
</p>
<p><strong class="strong">Tasks</strong> 
</p><ol class="enumerate">
<li> Inspect the running deployment. Open another terminal and run <code class="code">docker ps</code>. You should see four containers running. You might also wish to see what volumes are available: <code class="code">docker volume ls</code>. Among other volumes you should see the four volumes defined in your yml-file. We can not remove them directly because they are in use by running containers (try! The command is <code class="code">docker volume rm &lt;volume-name&gt;</code> ). Stopping the deployment doesn&rsquo;t help either, the volumes are apparently still in use. 

</li><li> Stop the deployment with &lsquo;<samp class="samp">Ctrl-C</samp>&rsquo; and run <code class="code">docker ps</code>. As you notice, the list is empty. You need to look for <em class="emph">all</em>, even exited containers, with the command <code class="code">docker ps -a</code> to see them. Let us remove all the containers running or not. I will do this in a lazy way with the command <code class="code">docker rm -f $(docker ps -a -q) dummy</code>  (the nested command lists only the IDs of the containers, and the outer command removes them. &rsquo;dummy&rsquo; is appended just to ensure that there is something &ndash; anything &ndash; there to look for so the outer command knows to behave nicely).

</li><li> It should now be possible to remove the volumes. Please do, and then restart the deployment again. Visit the search page <a class="uref" href="http://localhost:8080/">http://localhost:8080/</a> , search for something, and see it timeout and fail.
</li></ol>

<a class="index-entry-id" id="index-Docker-Bind-Mount"></a>
<ol class="enumerate">
<li> Assume that we now want to edit the application, as we did before. With its current deployment, this will not work; each container is only based on the initial image (except redis and mongo that use the defined volumes). In order to enable editing we must &ndash; as before &ndash; mount a directory on the host computer to a directory inside the container (this is referred to as a <em class="emph">bind mount</em> in docker vernacular). Edit the <code class="code">docker-compose-v2.yml</code> file and add <code class="code">volumes</code> to the services <code class="code">app</code> ( <code class="code">./QFApp/src:/app/src</code> ) and <code class="code">worker</code> ( <code class="code">./QFWorker/src:/app/src</code> ).

</li><li> Restart the deployment (technically, you only need to re-read the configuration, but for now it is easy enough to just &lsquo;<samp class="samp">Ctrl-C Up Enter</samp>&rsquo; to restart).

</li><li> On your host machine, open up the file <code class="code">QFApp/src/dispatcher.js</code> and familiarise yourself with the code. In the method <code class="code">formatJobs()</code> we want to add the following at the start of the function:
</li></ol>

<div class="example">
<pre class="example-preformatted">if (0 == texts.length) {
    console.log('WARNING: No texts are available, no jobs will be created.');
}
</pre></div>

<p>As before, you should see the app reload directly (in the console output), and if you search for something in the web browser before adding any texts this new warning will be printed in the console.
</p>
<hr>
</div>
<div class="section-level-extent" id="Scaling-the-Deployment">
<div class="nav-panel">
<p>
Next: <a href="#Cleanup-and-Summary" accesskey="n" rel="next">Cleanup and Summary</a>, Previous: <a href="#Editing-the-Running-Application" accesskey="p" rel="prev">Editing the Running Application</a>, Up: <a href="#Let_0027s-get-Practical-Again" accesskey="u" rel="up">Let&rsquo;s get Practical Again</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Scaling-the-Deployment-1">11.4 Scaling the Deployment</h3>

<p>There is one last thing we wish to do with the running deployment: Scale it. With <code class="code">docker compose</code> this is in fact quite easy:
</p>
<p><strong class="strong">Tasks</strong>
</p><ol class="enumerate">
<li> Edit the file <code class="code">docker-compose-v2.yml</code> and add the following instruction to the <code class="code">worker</code> service:
</li></ol>

<a class="index-entry-id" id="index-Docker-Compose-deploy"></a>
<a class="index-entry-id" id="index-Docker-Compose-replicas"></a>
<div class="example">
<pre class="example-preformatted">deploy:
  replicas: 3
</pre></div>

<ol class="enumerate" start="2">
<li> in a terminal where you are not running the <code class="code">docker compose ... up</code> command, enter the directory where the file  <code class="code">docker-compose-v2.yml</code> is located, and run the command <code class="code">docker compose -f docker-compose-v2.yml up -d</code> (Note the &rsquo;detach&rsquo; flag <code class="code">-d</code>, this is what does all the magic in this case). Look at the output in the first terminal, you should see that there are now three replicas of the worker node running.

</li><li> Edit the number of replicas down to 1 again, re-run the <code class="code">docker compose .. up -d</code> command and see what happens with the running deployment.
</li></ol>

<a class="index-entry-id" id="index-Load-Balancer"></a>
<p>In theory, it is possible to scale the <code class="code">app</code> service in the same way. In practice, however, this will not work. The reason for this is that the web client uses <code class="code">socket.io</code> for communication, which essentially ties one web client to one running app container. The built-in load balancer in docker compose employs a simple round-robin algorithm, passing each new call to localhost:8080 to port 3000 in the next <code class="code">app</code> container.
</p>
<hr>
</div>
<div class="section-level-extent" id="Cleanup-and-Summary">
<div class="nav-panel">
<p>
Next: <a href="#Introducing-Version-3-of-the-QuoteFinder-app" accesskey="n" rel="next">Introducing Version 3 of the QuoteFinder app</a>, Previous: <a href="#Scaling-the-Deployment" accesskey="p" rel="prev">Scaling the Deployment</a>, Up: <a href="#Let_0027s-get-Practical-Again" accesskey="u" rel="up">Let&rsquo;s get Practical Again</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Cleanup-and-Summary-1">11.5 Cleanup and Summary</h3>

<p>Stop and clean up after the running deployment by running the following commands:
</p>
<div class="example">
<pre class="example-preformatted">docker compose -f docker-compose-v2.yml stop
docker rm -f $(docker ps -a -q) dummy
docker volume rm version2_mongo-config version2_redis-conf version2_redis-data version2_textstore-data
docker network prune -f
</pre></div>

<p>The last command may need a clarification: Even if we have not manually created any virtual networks, docker compose have still created them in the background. <code class="code">docker network ls</code> will show you any remaining virtual networks.
</p>
<p><strong class="strong">Summary</strong>
We have now:
</p><ol class="enumerate">
<li> Built two Docker images, corresponding to the frontend <code class="code">qfapp</code> and the backend <code class="code">qfworker</code> of the QuoteFinder version 2 app.
</li><li> Downloaded a &lsquo;<samp class="samp">redis:alpine</samp>&rsquo; image.
</li><li> Constructed a docker-compose configuration that defines the four services and the volumes needed for this version to run.
</li><li> Launched this deployment
</li><li> Modified the configuration to use <em class="emph">build mounts</em> to superimpose the host&rsquo;s version of the application code over the default code inside the images.
</li><li> Edited a file locally and see the app in the running deployment restart to reflect the updated version.
</li><li> Modified the configuration to add more <em class="emph">replicas</em> of the <code class="code">worker</code> service.
</li><li> Re-deployed the configuration to the running deployment, without a restart.
</li></ol>

<p>Please take a moment to compare these achievements with the manual deployment of QuoteFinder Version 1.
</p>
<p><strong class="strong">Remaining Pain Points</strong>
Using RSMQ for passing messages between the frontend and the backend turned out to be a bad idea for a number of reasons:
</p>
<ol class="enumerate">
<li> The implementation of RMSQWorker is in fact <em class="emph">polling</em> the Redis store, so there is an inevitable delay before jobs are picked up.
</li><li> That we create a unique return queue and pass that along in the job is a dependency injection, meaning that the containers are no longer independent of each other.
</li><li> The workers need to pass their output back to a waiting web client. This means that the queue centric workflow is not the most suitable design pattern.
</li></ol>

<p>A more apt design pattern is to use a REST-API to access the QFWorkers; this is explored in Version 3 of the QuoteFinder app.
</p>
<p>Application design aside, the use of docker compose poses a bigger problem: Docker Compose deploys locally and not to a cloud provider. Moreover, there is no easy mechanism to distribute containers across several hosts.
</p>
<p>We can scale the QFWorker by adding more replicas, but we cannot easily scale the frontend QFApp. Making the frontend simpler, acting as a gateway to the QFWorkers who do the heavy lifting, is one approach to deal with this.
</p>
<div class="example">
<pre class="example-preformatted"> ____________________________
&lt; Can we scale the database? &gt;
 ----------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||
</pre></div>

<hr>
</div>
<div class="section-level-extent" id="Introducing-Version-3-of-the-QuoteFinder-app">
<div class="nav-panel">
<p>
Previous: <a href="#Cleanup-and-Summary" accesskey="p" rel="prev">Cleanup and Summary</a>, Up: <a href="#Let_0027s-get-Practical-Again" accesskey="u" rel="up">Let&rsquo;s get Practical Again</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Introducing-Version-3-of-the-QuoteFinder-app-1">11.6 Introducing Version 3 of the QuoteFinder app</h3>

<p>A few issues continue to itch with QuoteFinder Version 2. Specifically, the use of a queue centric workflow for an application where this is not the most suitable choice, and the resulting bad performance due to the chosen queue implementation. Even more concerning is that the wrong choice of architecture pattern broke one of the fundamental principles of microservice design: <em class="emph">Services should be independent</em>! Before continuing, let us take a moment to correct this.
</p>
<p>In <a class="uref" href="https://github.com/mickesv/QuoteFinder/">https://github.com/mickesv/QuoteFinder/</a> , that you have previously cloned, there is also a Version 3 of the QuoteFinder app. Please copy this version to a separate directory:
</p>
<div class="example">
<pre class="example-preformatted">cp -r QuoteFinder/Containers/Version3 .
cp QuoteFinder/docker-compose-v3.yml Version3/
cd Version3
ls
</pre></div>

<p>As before, you should see two directories, one each for <code class="code">QFApp</code> and one for <code class="code">QFWorker</code>. You also copied a file <code class="code">docker-compose-v3.yml</code>, so let&rsquo;s start by inspecting this file:
</p>
<div class="example">
<pre class="example-preformatted">version: &quot;3.8&quot;
services:
  app:
    image: qfappv3
    ports:
      - 8080:3000
    volumes:
      - ./Containers/Version3/QFApp/src:/app/src
    environment:
      TEXTSTORE_HOST: textstore
      WORKER: worker
      TIMEOUT: 10

  worker:
    image: qfworkerv3
    volumes:
      - ./Containers/Version3/QFWorker/src:/app/src
    deploy:
      replicas: 5
    environment:
      TEXTSTORE_HOST: textstore

  textstore:
    image: mongo
    restart: always
    command: --quiet --syslog
    expose:
      - &quot;27017&quot;
    volumes:
      - textstore-data:/data/db
      - mongo-config:/data/configdb

volumes:
  textstore-data:
  mongo-config:
</pre></div>

<p>There are only three services this time since the Redis store is no longer needed. The images are tagged <code class="code">v3</code> to keep them separate from the previous version (They could probably have been named <code class="code">qfapp:v3</code> and <code class="code">qfworker:v3</code> according to Docker&rsquo;s tag-numbering scheme, but they are not really versions of the same app since they use a different architecture, and I like to live on the wild side). The <code class="code">app</code> service has one additional environment variable set, but otherwise there are no major differences.
</p>
<a class="index-entry-id" id="index-diff"></a>
<p>Inspecting the QFAapp frontend, the only part we expect to differ is the <code class="code">Dispatch</code> class (This can be confirmed with the help of the command <code class="code">diff</code>, for example using <code class="code">diff --brief QFApp/src/ ../Version2/QFApp/src/</code> to get a summary of which files that differ). In the same way, we find that the only file that differs for the QFWorker is the <code class="code">index.js</code> file.
</p>
<p>The <code class="code">Dispatch</code> class is now much simpler, since there is no need to meddle with any queues in any direction. Since it is now so small, let us inspect the class in its entirety:
</p>
<div class="example">
<pre class="example-preformatted">class Dispatcher {
    constructor() {
        this.TIMEOUT = 1000 * (process.env.TIMEOUT || DEFAULTTIMEOUT);
        this.WORKER = process.env.WORKER || DEFAULTWORKER;
    }

    formatJobs(searchString, texts) {
        return texts.map( t =&gt; { return {searchString: searchString, textTitle: t};});
    }

    dispatchSearch(searchString, jobs, socket) {
        console.log('Searching for : ' + searchString);
        let baseurl = 'http://' + this.WORKER + ':3000';

        if (0 &gt;= jobs.length) {
            socket.emit('done', {msg: 'no texts available' }); 
            return 'DONE'
        };        

        setTimeout( () =&gt; socket.emit('done', {msg: 'timeout'}), this.TIMEOUT);

        return Promise.all(jobs.map( j =&gt; {
            let title = j.textTitle.replaceAll(' ','+');
            let search = j.searchString.replaceAll(' ','+');
            let url = baseurl + '/' + title + '/' +search;
            console.log('Using url:', url);
            return fetch(url)
                .then(res =&gt; res.json())
                .then(res =&gt; res.forEach( t =&gt; socket.emit('answer', JSON.stringify(t))));
        }))
        .then( () =&gt; socket.emit('done', {msg: 'done'}));
    }
}
</pre></div>

<p>As before, <code class="code">formatJobs()</code> generates one job for each text in the database (and could be improved with the same modification we did for Version 2). The new magic start with the line <code class="code">return Promise.all(jobs.map( j =&gt; {</code> , where each job is used to generate a Promise to dispatch the search of that specific title to one worker. Each title will generate an asynchronous call to the REST API in a QFWorker (the load balancer in Docker Compose decides which one), and when an answer is received it will use <code class="code">socket.emit()</code> to send this answer to the web client.
</p>
<p>The <code class="code">index.js</code> in QFWorker is now slightly longer since it is now using the same &lsquo;<samp class="samp">express.js</samp>&rsquo; framework as QFApp to serve up a tiny web server. However, most of the new code is boilerplate code for &lsquo;<samp class="samp">express.js</samp>&rsquo;, and there is really only one method which takes care of the search requests. Please take a moment to study <code class="code">index.js</code> and make sure you understand how the REST API is constructed.
</p>
<p>Feel free to build the necessary images for Version 3, start the deployment and play around with it. It should be prepared for you so that you can live-edit the files and the deployment as you did with Version 2.
</p>
<hr>
</div>
</div>
<div class="chapter-level-extent" id="Quiz-Design-Decisions-and-Development-Setup">
<div class="nav-panel">
<p>
Next: <a href="#Deployment-with-Kubernetes" accesskey="n" rel="next">Deployment with Kubernetes</a>, Previous: <a href="#Let_0027s-get-Practical-Again" accesskey="p" rel="prev">Let&rsquo;s get Practical Again</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Quiz_003a-Design-Decisions-and-Development-Setup">12 Quiz: Design Decisions and Development Setup</h2>

<p><strong class="strong">TODO</strong> Please read the following article:
</p>
<ul class="itemize mark-bullet">
<li>Taibi, D., Lenarduzzi, V., &amp; Pahl, C. (2018). Architectural patterns for microservices: a systematic mapping study. In CLOSER 2018: Proceedings of the 8th International Conference on Cloud Computing and Services Science, SciTePress, Setúbal, 2018.
</li></ul>

<p><strong class="strong">TODO</strong> Answer the following questions on Taibi et al.:
</p><ul class="itemize mark-bullet">
<li>Briefly list and describe the microservice architectural patterns identified in Taibi et al.?
</li><li>How do these patterns differ from the architecture patterns described by Bill Wilder, <em class="emph">Cloud Architecture Patterns</em>, O&rsquo;Reilly, 2012 (You can find a summary in <a class="ref" href="#Cloud-Architecture-Patterns">Cloud Architecture Patterns</a>)? Are there any similarities?
</li><li>Taibi et al. describe a number of guiding principles for microservice architecture styles. Please list and briefly describe each of these.
</li></ul>

<p><strong class="strong">TODO</strong> Answer the following questions:
</p><ul class="itemize mark-bullet">
<li>What patterns (from Taibi et al. as well as from Wilder) are currently used in QuoteFinder Version 2?
</li><li>What are the bottlenecks in the current architecture? What can we do about them?
</li><li>What can be done to scale QuoteFinder Version 2? Think in &ldquo;both ends&rdquo;, i.e. scaling the front-end as well as the back-end.
</li></ul>

<p>There is a Quiz on Canvas where you can submit your article summaries and answers to the questions.
</p>
<p><strong class="strong">NOTICE:</strong> <em class="emph">This quiz does not contribute to the grade in the course. We do, however, require of you to submit the quiz on time.</em> The purpose of this quiz is to serve as a learning aid allowing you to think about these concepts, and for us to keep track of your progress in the course. If you are unable to maintain the study pace required to submit this quiz on time, we want to be made aware of this so that you are able to re-plan your commitment for the remainder of the course.
</p>
<hr>
</div>
<div class="chapter-level-extent" id="Deployment-with-Kubernetes">
<div class="nav-panel">
<p>
Next: <a href="#Quiz-Deployment-with-Kubernetes" accesskey="n" rel="next">Quiz: Deployment with Kubernetes</a>, Previous: <a href="#Quiz-Design-Decisions-and-Development-Setup" accesskey="p" rel="prev">Quiz: Design Decisions and Development Setup</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Deployment-with-Kubernetes-1">13 Deployment with Kubernetes</h2>

<a class="anchor" id="Deployment"></a>

<ul class="mini-toc">
<li><a href="#Introduction-to-Kubernetes" accesskey="1">Introduction to Kubernetes</a></li>
<li><a href="#Get-Started-with-Kubernetes" accesskey="2">Get Started with Kubernetes</a></li>
<li><a href="#Attach-the-Database" accesskey="3">Attach the Database</a></li>
</ul>
<hr>
<div class="section-level-extent" id="Introduction-to-Kubernetes">
<div class="nav-panel">
<p>
Next: <a href="#Get-Started-with-Kubernetes" accesskey="n" rel="next">Get Started with Kubernetes</a>, Up: <a href="#Deployment-with-Kubernetes" accesskey="u" rel="up">Deployment with Kubernetes</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Introduction-to-Kubernetes-1">13.1 Introduction to Kubernetes</h3>

<p>With the introduction of Docker Compose, it is now possible to provision and orchestrate docker microservices in the same way as has previously been introduced for full virtual machines e.g. with the use of Vagrant. Some differences are nevertheless worth mentioning:
</p>
<p>With Vagrant and a hypervisor, provisioning and deployment is done in one step. While a separate provisioning tool such as Ansible or Puppet may be used, the idea is still to start with an empty virtual machine and then install and configure everything from the operating system and required tool stack all the way up to the software that is supposed to run on the VM.
</p>
<p>With Docker the provisioning is done in a separate step, where an initial docker image is created. Up to a point, the software in this image is ready to start running, requiring only a small set of additional run-time configuration. Docker compose is responsible for the next step, which is to orchestrate and deploy the specified services.
</p>
<p>There is, however, one more trick up Vagrant&rsquo;s sleeve, and that is the ability to deploy to different providers. Adding a small configuration block in the Vagrantfile makes it possible to use the same configuration to deploy to many different cloud providers (or, should you so desire, different hypervisors locally).
</p>
<a class="index-entry-id" id="index-Kubernetes-1"></a>
<p>This is not supported by Docker Compose. To this end, it is time to introduce the next tool in the tool chain, i.e. Kubernetes <a class="uref" href="https://kubernetes.io/">https://kubernetes.io/</a> . Somewhat simplified, one can say that Kubernetes is used to set up the deployment infrastructure within which the application microservices are run.
</p>
<p><strong class="strong">Some Kubernetes Terminology</strong>
From the inside out:
</p>
<a class="index-entry-id" id="index-Kubernetes-Container"></a>
<a class="index-entry-id" id="index-Kubernetes-Pod"></a>
<a class="index-entry-id" id="index-Kubernetes-Deployment"></a>
<a class="index-entry-id" id="index-Kubernetes-Service"></a>
<a class="index-entry-id" id="index-Kubernetes-Volume"></a>
<a class="index-entry-id" id="index-Kubernetes-Label"></a>
<a class="index-entry-id" id="index-Kubernetes-Persistent-Storage"></a>
<a class="index-entry-id" id="index-Kubernetes-Persistent-Volume"></a>
<a class="index-entry-id" id="index-Kubernetes-Persistent-Volume-Claim"></a>

<ol class="enumerate">
<li> <em class="emph">Containers</em> are still the core concept, and they are no different to the microservice containers used previously. They are, in fact, based on the same docker images as before.
</li><li> Containers are collected into <em class="emph">pods</em>, that gathers containers working closely together, possibly with some shared storage.
</li><li> A container can mount <em class="emph">Volumes</em> inside the same pod.
</li><li> If the container need <em class="emph">Persistent Storage</em> this is split into two parts. The developer of container makes a <em class="emph">PersistentVolumeClaim</em> describing what type of persistent storage they need, and the administrator of the Kubernetes cluster provides one or more <em class="emph">PersistentVolume</em> to match the desired claims.
</li><li> A <em class="emph">Deployment</em> describes the contents in a Pod on a slightly higher level, enabling Kubernetes to take more responsibility for e.g. scaling the deployment or to move the pods to other nodes if necessary.
</li><li> <em class="emph">Labels</em> are used to identify which parts of the application are affected by different configuration directives.
</li><li> <em class="emph">Services</em> are set up to access your application. They act as the glue between the pods/containers and the outside world.
</li></ol>

<p>The best way to come to terms with this is to walk through a practical example, which is what we&rsquo;ll do next.
</p>
<hr>
</div>
<div class="section-level-extent" id="Get-Started-with-Kubernetes">
<div class="nav-panel">
<p>
Next: <a href="#Attach-the-Database" accesskey="n" rel="next">Attach the Database</a>, Previous: <a href="#Introduction-to-Kubernetes" accesskey="p" rel="prev">Introduction to Kubernetes</a>, Up: <a href="#Deployment-with-Kubernetes" accesskey="u" rel="up">Deployment with Kubernetes</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Get-Started-with-Kubernetes-1">13.2 Get Started with Kubernetes</h3>

<a class="index-entry-id" id="index-kubectl"></a>
<p>You have already installed the necessary software to set up a very small Kubernetes cluster (consisting of a single machine). For Windows/Mac, this is included in <code class="code">Docker Desktop</code> , although you may need to go into the settings and enable Kubernetes. For Linux, you will use the standalone <code class="code">minikube</code>, started with a simple <code class="code">minikube start</code> . Check the status of your cluster with <code class="code">kubectl cluster-info</code> .
</p>
<p>It is possible to set up your deployment well and good using only the command line tool <code class="code">kubectl</code> but I would not recommend it. By now, the mantra <em class="emph">Infrastructure as Code</em> should be ingrained into you, so let&rsquo;s write some YAML code to set up a deployment.
</p>
<div class="example">
<pre class="example-preformatted"># QFStandalone
# --------------------
# - Deployment to launch one container of mickesv/qfstandalone in a pod.
# - Service (type: LoadBalancer) to open up the app to the world (localhost, at least).
# 
---
apiVersion: v1
kind: Service
metadata:
  name: qfapp-service
  labels:
    app: qfapp
spec:
  type: LoadBalancer
  ports:
  - name: http
    port: 3000
    nodePort: 30001
    protocol: TCP
  selector:
    app: qfapp
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: qfstandalone
  labels:
    app: qfapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: qfapp
  template:
    metadata:
      labels:
        app: qfapp
    spec:
      containers:
      - name: qfstandalone
        image: mickesv/qfstandalone:version1
        ports:
        - containerPort: 3000
---
</pre></div>

<a class="index-entry-id" id="index-Kubernetes-ReplicaSet"></a>
<p>A quick summary of what can be seen:
</p><ul class="itemize mark-bullet">
<li>This consist of two yaml blocks (separated by three hyphens &lsquo;<samp class="samp">---</samp>&rsquo; ), where the first define a deployment and the second exposes this deployment through the use of a LoadBalancer Service.
</li><li>We still have the same issue as before with the use of socket.io and the load balancer, so for now we keep the number of replicas to 1. Giving this instructions means that Kubernetes will create a &lsquo;<samp class="samp">ReplicaSet</samp>&rsquo; to keep track of the pods in this deployment.
</li><li>The Deployment named &lsquo;<samp class="samp">qfstandalone</samp>&rsquo; has a one template for a pod, with the label &lsquo;<samp class="samp">qfapp</samp>&rsquo;. As it happens, the selector instructs the ReplicaSet to manage pods matching this same label.
</li><li>The pod template says that there should be one container in there, with the name &lsquo;<samp class="samp">qfstandalone</samp>&rsquo; and based on the image &lsquo;<samp class="samp">mickesv/qfstandalone:version1</samp>&rsquo;.
</li><li>Notice that the &lsquo;<samp class="samp">containers</samp>&rsquo; is a list, so it is possible to add other containers into the same pod.
</li><li>The Service is created to act as a LoadBalancer against the ReplicaSet Deployment. Internally, it will access port 3000, but outside of the cluster (or from other pods inside the cluster), this will be accessed via port 30001.
</li></ul>

<p><strong class="strong">Cave!</strong> Kubernetes will fetch the images from Docker hub, so you either need to push your own qfstandalone image thither or you can trust me (!) and use the &lsquo;<samp class="samp">mickesv</samp>&rsquo; version.
</p>
<p><strong class="strong">Tasks</strong>
</p><ol class="enumerate" start="0">
<li> Open up a terminal and enter your <code class="code">QuoteFinder</code> directory. Create a new sub-directory, e.g. <code class="code">QuoteFinder/Kubernetes</code> , and cd into it.

</li><li> Create the file <code class="code">qfstandalone-v1-1.yaml</code> and copy the configuration from above into it.

</li><li> Apply the configuration: <code class="code">kubectl apply -f qfstandalone-v1-1.yaml</code>

</li><li> Check what was created: <code class="code">kubectl get all</code>
</li></ol>

<a class="index-entry-id" id="index-Kubernetes-Cluster-IP"></a>
<a class="index-entry-id" id="index-Kubernetes-External-IP"></a>
<ol class="enumerate">
<li> It is time to test if the web page is available. In order to access the web page, we first need to find the external ip of the qfapp-service (Remember that the service is required to bridge from the outside world to inside the Kubernetes cluster). Get the list of services through <code class="code">kubectl get services</code> , and you will notice that each service has both a &lsquo;<samp class="samp">CLUSTER-IP</samp>&rsquo; and an &lsquo;<samp class="samp">EXTERNAL-IP</samp>&rsquo;. Right now, the service only has a Cluster-ip, which is internal to Kubernetes. Other containers inside the same Kubernetes cluster may use this to access the qfapp-service, but we cannot use this address from the outside. For this, we need the external IP, and this may still be listed as &lsquo;<samp class="samp">&lt;pending&gt;</samp>&rsquo;.
</li></ol>

<a class="index-entry-id" id="index-Kubernetes-NodePort"></a>
<p>On Windows or Mac with Docker Desktop you may have better luck. Since the LoadBalancer service was created with just a <code class="code">nodePort</code> specified, Kubernetes will open this port on the node (Right now, you only have one node; your host computer). Thus, the QuoteFinder app may be available as <a class="uref" href="http://localhost:30001/">http://localhost:30001/</a> . 
</p>
<p>On Linux with Minikube, the service is exposed with <code class="code">minikube service qfapp-service</code> . As a courtesy to you, minikube will open this web page for you.
</p>
<ol class="enumerate" start="5">
<li> Previously we were able to see the containers print out all sorts of debug info as it was running. Let&rsquo;s try recreating that. First, list all running pods (just the names): <code class="code">kubectl get pods</code> . Notice that the name you specified has been appended with some sort of hash key. All of this is the name of the pod.
</li></ol>

<p>The command to access the logs in a pod is <code class="code">kubectl logs -f &lt;podname&gt;</code>, where the <code class="code">-f</code> flag means that we want to <em class="emph">follow</em> the logs and continue to print anything that is added to them. With a bit of Unix elbow-grease, the following incantation should both find the name of the pod and attach itself to the log: <code class="code">kubectl get pods -o name | grep qfstandalone | xargs kubectl logs -f</code> . 
</p>
<a class="index-entry-id" id="index-grep"></a>
<a class="index-entry-id" id="index-xargs"></a>
<a class="index-entry-id" id="index-Unix-pipe-_007c"></a>
<p>Breaking down the command, we see the following:
</p><ul class="itemize mark-bullet">
<li>The three parts are combined with Unix pipes (the <code class="code">|</code> symbol). The output (standard output, to be precise) of the command to the left of the pipe will be the input (standard input) for the command to the right of the pipe. This is how simple Unix commands are daisy-chained to each other to produce ever more complex tasks.
</li><li><code class="code">kubectl get pods -o name</code> prints the names (only the names) of all running pods.
</li><li><code class="code">grep qfstandalone</code> filters the output to only those containing the string &ldquo;qfstandalone&rdquo;
</li><li><code class="code">xargs</code> converts whatever it receives on standard input into arguments at the end of whatever command is given to it.
</li><li><code class="code">kubectl logs -f</code> is the start of this command, to which xargs add the names of all pods containing the string &ldquo;qfstandalone&rdquo; in their names.
</li></ul>

<p>The end result is that we are now attached to the logs and can see the same type of output in the console as we were able to do previously. Incidentally, you may notice that users seem to connect from some strange IP address; while this <em class="emph">should</em> be the address of your host computer, it clearly is not. Take a moment to consider the deployment and see if you can&rsquo;t figure out whose IP address this is.
</p>
<ol class="enumerate" start="6">
<li> While you are attached to the logs try searching for something on the web page. This will not work since we have not yet connected our database or told the qfapp container where to find it, but the log output is interesting. (you will, for example, get a warning that &lsquo;<samp class="samp">TEXTSTORE_HOST</samp>&rsquo; is not set).
</li></ol>


<p><strong class="strong">Summary</strong>
At this point we have:
</p><ol class="enumerate">
<li> Started a local Kubernetes Cluster consisting of a single Node.
</li><li> Defined a Kubernetes ReplicaSet Deployment where containers matching the label &lsquo;<samp class="samp">app: qfapp</samp>&rsquo; is deployed.
</li><li> Re-used the same QuoteFinder v1 (qfstandalone) docker image as before and deployed it on this cluster.
</li><li> Started a Kubernetes LoadBalancer Service to enable access from outside the Kubernetes cluster to the ReplicaSet deployment.
</li></ol>


<p><strong class="strong">Cleanup</strong>
Clean up your deployment: <code class="code">kubectl delete --cascade='foreground' -f qfstandalone-v1-1.yaml</code> .
</p>
<hr>
</div>
<div class="section-level-extent" id="Attach-the-Database">
<div class="nav-panel">
<p>
Previous: <a href="#Get-Started-with-Kubernetes" accesskey="p" rel="prev">Get Started with Kubernetes</a>, Up: <a href="#Deployment-with-Kubernetes" accesskey="u" rel="up">Deployment with Kubernetes</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Attach-the-Database-1">13.3 Attach the Database</h3>

<p>Attaching a database should in theory be easy, but let&rsquo;s take a moment and do this &ldquo;right&rdquo;, so that we get a configurable and by the books deployment.
</p>
<a class="index-entry-id" id="index-Kubernetes-StatefulSet"></a>
<p>First, of course, the database need to be started. Since we want data to survive restarts, we will do this as a <code class="code">StatefulSet</code> . This StatefulSet will launch an image of MongoDB (as before). It will also make two persistent VolumeClaims (as before); one for MongoDB&rsquo;s configuration and one for the data.
</p>
<a class="index-entry-id" id="index-Kubernetes-Access-Roles"></a>
<p>These Persistent Volume Claims are then matched to Persistent Volumes by Kubernetes, and the recommendation is that these are specified in a separate file, so that they can be deployed by someone with the right access privileges. App developers make claims, and node administrators provide resources. A Persistent Volume is a resource, and thus need a node administrator to configure.
</p>
<p>For now, however, there is no need to specify these Persistent Volumes; at least <code class="code">minikube</code> will create them as needed. Other tools may not, and once you deploy to a cloud provider, you most certainly will need to define the Persistent Volumes somewhere and somehow. For now, however, we can leave this.
</p>
<a class="index-entry-id" id="index-Kubernetes-Persistent-VolumeClaim-Templates"></a>
<p>What we <em class="emph">do</em> need to take care of, however, is a little snag in how Persistent Volume Claims work. Let&rsquo;s say we decide that we want more replicas of our database container in the StatefulSet. Unless otherwise specified, Kubernetes will map all of these replicas <em class="emph">to the same</em> volume claim, and MongoDB will most certainly not like this. The first replica will lock the database files, and no other replicas will be allowed to access them.
</p>
<a class="index-entry-id" id="index-Kubernetes-volumeClaimTemplates"></a>
<p>To avoid this, we will not make concrete claims to a particular persistent volume; we will specify a <em class="emph">template</em> for the claims, called a <code class="code">volumeClaimTemplate</code>. This template specifies the <em class="emph">type</em> of volume required, but as little else as possible. Especially avoid specifying any storageClassName, or any StorageClasses or PersistentVolumes at all.
</p>
<p>Almost finally, in order to access the replicas of the database, we need a Service, and any access (even from within the Kubernetes cluster) will be done with the help of this service.
</p>
<a class="index-entry-id" id="index-Kubernetes-ConfigMap"></a>
<p>We still need to configure the QuoteFinder app so that it can find and connect to the database. One Kubernetes way to do this is via a <code class="code">ConfigMap</code>. This is a simple key-value map that can be referenced from the container templates.
</p>
<p>Enough talking! Time to get busy.
</p>
<p><strong class="strong">Tasks</strong>
</p><ol class="enumerate" start="0">
<li> Copy the previous yaml file to a new file, to keep a record of the different steps: <code class="code">cp qfstandalone-v1-1.yaml qfstandalone-v1-2.yaml</code>

</li><li> Add the following to the end of this new copy:
</li></ol>

<div class="example">
<pre class="example-preformatted"># TextStore
# --------------------
# - one container per pod running the image mongodb
# - one headless service to access them.
# - Two persistentVolumeClaims/mounts: textstore-data, and mongo-config
---
apiVersion: v1
kind: Service
metadata:
  name: textstore-service
  labels:
    app: textstore
spec:
  ports:
  - port: 27017
    targetPort: mongodb-port
  selector:
    app: textstore
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: textstore
  labels:
    app: textstore
spec:
  serviceName: mongodb
  replicas: 1
  selector:
    matchLabels:
      app: textstore
  template:
    metadata:
      labels:
        app: textstore
    spec:
      containers:
      - name: textstore
        image: mongo
        ports:
        - containerPort: 27017
          name: mongodb-port
        volumeMounts:
        - name: textstore-data
          mountPath: /data/db
        - name: mongo-config
          mountPath: /data/configdb
  volumeClaimTemplates:
    - metadata:
        name: textstore-data
      spec:
        accessModes: [&quot;ReadWriteOnce&quot;]
        resources:
          requests: 
            storage: 10Mi
    - metadata:
        name: mongo-config
      spec:
        accessModes: [&quot;ReadWriteOnce&quot;]
        resources:
          requests: 
            storage: 5Mi          
---
</pre></div>

<p>Especially interesting here is the <code class="code">volumeClaimTemplates</code> . As you notice, the claims are made in terms of how we are going to access them (&ldquo;ReadWriteOnce&rdquo;), and their desired size. The <code class="code">metadata.name</code> match the <code class="code">volumeMounts</code> in the container spec above.
</p>
<ol class="enumerate" start="2">
<li> Also append the following:
</li></ol>

<div class="example">
<pre class="example-preformatted"># ConfigMap to store TEXTSTORE_HOST variable in
# --------------------
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: qfapp-config
  labels:
    data: config
data:
  textstore_host: &quot;NOTSET&quot;
---
</pre></div>

<p>Caution, <code class="code">textstore_host</code> MUST be &ldquo;NOTSET&rdquo; (case sensitive). This will be replaced with the right IP during startup.
</p>
<ol class="enumerate" start="3">
<li> Some edits are required for the qfapp container template to make use of this ConfigMap to set an environment variable (using the  <code class="code">env</code> specification):
</li></ol>

<div class="example">
<pre class="example-preformatted">spec:
  containers:
  - name: qfstandalone
    image: mickesv/qfstandalone:version1
    ports:
    - containerPort: 3000
    env:
    - name: TEXTSTORE_HOST
      valueFrom:
        configMapKeyRef: 
          name: qfapp-config
          key: textstore_host
</pre></div>

<ol class="enumerate" start="4">
<li> Time to deploy all of this. This needs to be done in stages. First, the ConfigMap and the textstore database are created. Then, the Cluster-IP address for the database is extracted so that the ConfigMap can be updated accordingly. Finally, the qfapp deployment can be launched:
</li></ol>

<div class="example">
<pre class="example-preformatted"># Apply only the parts matching the label for the configmap and the textStore
kubectl apply -f qfstandalone-v1-2.yaml -l data=config
kubectl apply -f qfstandalone-v1-2.yaml -l app=textstore

# Extract the clusterIP
export textstoreip=$( kubectl get services/textstore-service --template='{{.spec.clusterIP}}' )

# Retrieve the ConfigMap, replace &quot;NOTSET&quot; with the clusterIP, and re-apply.
kubectl get configmap/qfapp-config -o yaml | sed -r &quot;s/NOTSET/$textstoreip/&quot; | kubectl apply -f -

# Finally, start the qfapp
kubectl apply -f qfstandalone-v1-2.yaml -l app=qfapp
</pre></div>

<p>&hellip;  If I were you I would seriously considering making a script for this, since it is only going to get worse.
</p>
<ol class="enumerate" start="5">
<li> Attach a log to the running instance of qfstandalone: <code class="code">kubectl get pods -o name | grep qfstandalone | head -1 | xargs kubectl logs -f</code>

</li><li> Using a separate terminal, open a web browser to your service: <code class="code">minikube service qfapp-service</code> (or equivalent command for your version of Kubernetes)  and search for something. Note in the log that the connection to the database is established and the search is executed as it should. Do try to add some texts and re-do the search if you like.
</li></ol>

<p><strong class="strong">Summary</strong>
We have now:
</p><ol class="enumerate">
<li> Added a database container and a service to access it.
</li><li> Added a ConfigMap where we can keep the internal IP-address to this service.
</li><li> Updated the qfstandalone deployment to make use of this ConfigMap.
</li><li> Deployed in three stages; start ConfigMap and textstore, extract the Cluster-IP for the textStore and update the ConfigMap, and started the qfstandalone app and its corresponding service.
</li></ol>

<p><strong class="strong">Cleanup</strong>
As before, clean up your deployment: <code class="code">kubectl delete --cascade='foreground' -f qfstandalone-v1-2.yaml</code> .
</p>
<hr>
</div>
</div>
<div class="chapter-level-extent" id="Quiz-Deployment-with-Kubernetes">
<div class="nav-panel">
<p>
Next: <a href="#Scaling-the-Database" accesskey="n" rel="next">Scaling the Database</a>, Previous: <a href="#Deployment-with-Kubernetes" accesskey="p" rel="prev">Deployment with Kubernetes</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Quiz_003a-Deployment-with-Kubernetes">14 Quiz: Deployment with Kubernetes</h2>

<p><strong class="strong">TODO</strong> Please read the following articles and resources:
</p>
<ul class="itemize mark-bullet">
<li>Andersson, J., &amp; Norrman, F. (2020). Container Orchestration: the Migration Path to Kubernetes. (Bachelor Thesis)
</li><li><a class="uref" href="https://k8s.af/">Kubernetes Failure Stories</a> (last checked 2023-03-30). This is not to dishearten you from using Kubernetes, but there is a lot to learn by looking at mistakes others have made. Also, in the midst of all this failure there are some examples of really good deployment practices in there too.
</li><li>J. Tigani <a class="uref" href="https://motherduck.com/blog/big-data-is-dead/">Big Data is Dead</a> (last checked 2023-03-30). An interesting discussion piece about whether we in fact have moved beyond big data already. Not strictly related to Kubernetes and microservice development, but still a relevant read.
</li><li>D. Glasser, <a class="uref" href="https://blog.meteor.com/mongodb-queries-dont-always-return-all-matching-documents-654b6594a827#.59pxgubtq">MongoDB queries don&rsquo;t always return all matching documents.</a> (last checked 2023-03-30) This is just one example of an article that explains challenges with nosql databases and their &ldquo;eventually consistent&rdquo; philosophy.
</li></ul>

<p><strong class="strong">TODO</strong> Summarise each article/resource (no more than 1/2 page each) according to the following:
</p>
<ul class="itemize mark-bullet">
<li>Authors (if available/applicable) and Title of the article
</li><li>Briefly, what is the article about?
</li><li>What have they measured?
</li><li>What are their main findings?
</li><li>What can you learn from this article?
</li></ul>

<p><strong class="strong">TODO</strong> Please answer the following questions:
</p><ol class="enumerate">
<li> What types of Kubernetes &lsquo;<samp class="samp">Services</samp>&rsquo; are there?
</li><li> It is recommended to start Services before the Containers they refer to. Why?
</li><li> What is a &lsquo;<samp class="samp">NodePort</samp>&rsquo;? How does it differ from a &lsquo;<samp class="samp">LoadBalancer</samp>&rsquo;?
</li><li> What is a &lsquo;<samp class="samp">StatefulSet</samp>&rsquo;? When is this used?
</li><li> What are the differences between a &lsquo;<samp class="samp">Pod</samp>&rsquo;, a &lsquo;<samp class="samp">Deployment</samp>&rsquo;, a &lsquo;<samp class="samp">ReplicaSet</samp>&rsquo;, and a &lsquo;<samp class="samp">StatefulSet</samp>&rsquo;?
</li><li> When do you use a &lsquo;<samp class="samp">ConfigMap</samp>&rsquo;? How does it differ from a &lsquo;<samp class="samp">Secret</samp>&rsquo;?
</li><li> What are the different ways in which you can use a &lsquo;<samp class="samp">ConfigMap</samp>&rsquo; to configure a Container? When would you use each of them?
</li><li> Do you have a better solution than the multi-stage startup in order to get the IP address of the textstore-service into the ConfigMap before starting qfstandalone?
</li></ol>

<p>There is a Quiz on Canvas where you can submit your article summaries and answers to the questions.
</p>
<p><strong class="strong">NOTICE:</strong> <em class="emph">This quiz does not contribute to the grade in the course. We do, however, require of you to submit the quiz on time.</em> The purpose of this quiz is to serve as a learning aid allowing you to think about these concepts, and for us to keep track of your progress in the course. If you are unable to maintain the study pace required to submit this quiz on time, we want to be made aware of this so that you are able to re-plan your commitment for the remainder of the course.
</p>
<hr>
</div>
<div class="chapter-level-extent" id="Scaling-the-Database">
<div class="nav-panel">
<p>
Next: <a href="#Edit-a-Container-in-a-Pod-in-a-Node-in-a-Cluster" accesskey="n" rel="next">Edit a Container in a Pod in a Node in a Cluster</a>, Previous: <a href="#Quiz-Deployment-with-Kubernetes" accesskey="p" rel="prev">Quiz: Deployment with Kubernetes</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Scaling-the-Database-1">15 Scaling the Database</h2>


<ul class="mini-toc">
<li><a href="#Database-Scaling" accesskey="1">Database Scaling</a></li>
<li><a href="#MongoDB-ReplicaSet" accesskey="2">MongoDB ReplicaSet</a></li>
<li><a href="#Setting-up-a-MongoDB-ReplicaSet-in-Kubernetes" accesskey="3">Setting up a MongoDB ReplicaSet in Kubernetes</a></li>
</ul>
<hr>
<div class="section-level-extent" id="Database-Scaling">
<div class="nav-panel">
<p>
Next: <a href="#MongoDB-ReplicaSet" accesskey="n" rel="next">MongoDB ReplicaSet</a>, Up: <a href="#Scaling-the-Database" accesskey="u" rel="up">Scaling the Database</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Database-Scaling-1">15.1 Database Scaling</h3>

<div class="example">
<pre class="example-preformatted"> ____________________________
&lt; Can we scale the database? &gt;
 ----------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||
</pre></div>

<p>Yes. Yes, we can. The first and easiest way to scale is by scaling the node it runs on, i.e. <em class="emph">vertical scaling</em>. This implies increasing the number of CPUs, the amount of RAM, and/or increase the storage capacity.
</p>
<a class="index-entry-id" id="index-Database-Replication"></a>
<a class="index-entry-id" id="index-NoSQL"></a>
<a class="index-entry-id" id="index-Eventual-Consistency"></a>
<p>The second way to scale is by <em class="emph">replication</em>. This creates duplicate copies of the entire database, each replica requiring as much resources as a single instance of it. Typically, this is combined with a load balancer to even out the load between the replicas. This is typically good if the application <em class="emph">reads</em> data more often than it <em class="emph">writes</em>. Writing data will be slower since the edit will need to propagate across all replicas before it becomes available, but reading can be done by any single replica. In contrast to the classic relational databases, most NoSQL databases (such as MongoDB), only promise <em class="emph">eventual consistency</em>, and this is put to good use for read-intensive applications with database replication.
</p>
<a class="index-entry-id" id="index-Database-Sharding"></a>
<a class="index-entry-id" id="index-Sharding-Architectures"></a>
<p>The <em class="emph">third</em> way of scaling is to split the database across multiple nodes. This, in turn, can be done in some different ways. First, one may divvy up the tables across the available nodes. For simple queries it may be sufficient to just hit a single node, but for more complex joins it may be necessary to perform several queries to get data from tables distributed to other nodes as well. Simplifying a little (ok; a lot) one may see this as <em class="emph">splitting the database across columns</em>.
</p>
<p>When, instead, the database is split across rows so that some <em class="emph">rows</em> are available on one node and other rows are available on another node, this is called <em class="emph">Sharding</em>. The simplest way to do this is to specify ranges for one key and assign a shard ID for each range. Stepping up, one may have an arbitrarily complex algorithm to compute the shard ID for each database record.
</p>
<p>Abandoning all hopes of being able to apply Boyce-Codd Normal Form, it is of course desirable to keep related data together on the same node. Rather than splitting data across tables and use joins when querying, each record can be designed to contain all the necessary data. These records can then be distributed based on some geographical key, for example to comply with laws governing where citizens&rsquo; data must be located.
</p>
<a class="index-entry-id" id="index-Madness"></a>
<p>Of course, one can split across columns as well through sharding. One may even use different sharding architectures for each table. Madness only ever lies a single design decision away.
</p>
<hr>
</div>
<div class="section-level-extent" id="MongoDB-ReplicaSet">
<div class="nav-panel">
<p>
Next: <a href="#Setting-up-a-MongoDB-ReplicaSet-in-Kubernetes" accesskey="n" rel="next">Setting up a MongoDB ReplicaSet in Kubernetes</a>, Previous: <a href="#Database-Scaling" accesskey="p" rel="prev">Database Scaling</a>, Up: <a href="#Scaling-the-Database" accesskey="u" rel="up">Scaling the Database</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="MongoDB-ReplicaSet-1">15.2 MongoDB ReplicaSet</h3>

<p>For the sake of selling access to various tools, everyone agrees that Database Sharding is complex and painful. So in this course we will focus on the next best step, which is to set up a <em class="emph">replicated</em> database. We will get some help from Kubernetes, but since each NoSQL database implements this in their very own creative way this is also going to involve a certain amount of tool specific (MongoDB) incantation.
</p>
<a class="index-entry-id" id="index-MongoDB-ReplicaSet"></a>
<p>Conceptually, replication ought to work as illustrated below:
</p>
<div class="example">
<pre class="example-preformatted"> _O_          +----------------------+        +--------------------+
  |     ------+ Service/LoadBalancer \--------+ MongoDB Replica    |
 / \          +----------------------+\\-     +--------------------+
Client                                 \ \-
                                        \  \- +--------------------+
                                         \-  \+ MongoDB Replica    |
                                           \  +--------------------+
                                            \
                                             \+--------------------+
                                              \ MongoDB Replica    |
                                              +--------------------+
</pre></div>

<p>In practice, however, it doesn&rsquo;t. MongoDB does not know that there is such a thing as external Load-Balancers (and in any case it can not rely on that the user knows). The MongoDB replica do also not want to assume this role, and if they did they would still need to decide which IP should be broadcast to the outside. Instead, the design solution that MongoDB has opted for is to push load balancing onto the database clients.
</p>
<p>By now you know that I have plenty of opinions about software and design decisions so I will leave it as an exercise to the reader to define, list, and sort a suitable array of invectives.
</p>
<hr>
</div>
<div class="section-level-extent" id="Setting-up-a-MongoDB-ReplicaSet-in-Kubernetes">
<div class="nav-panel">
<p>
Previous: <a href="#MongoDB-ReplicaSet" accesskey="p" rel="prev">MongoDB ReplicaSet</a>, Up: <a href="#Scaling-the-Database" accesskey="u" rel="up">Scaling the Database</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Setting-up-a-MongoDB-ReplicaSet-in-Kubernetes-1">15.3 Setting up a MongoDB ReplicaSet in Kubernetes</h3>

<p>The following items from the previous setup are generic enough that they do not require any modification at this stage:
</p>
<dl class="table">
<dt>The qfapp-service</dt>
<dd><p>this service only enables access from the outside of the Kubernetes cluster, so there is no need to change it.
</p></dd>
<dt>The textstore-service</dt>
<dd><p>this too will remain unchanged. To be honest, I&rsquo;m not sure whether it is actually used, but it may need to be there anyway.
</p></dd>
<dt>The volumeClaimTemplates for the textstore containers</dt>
<dd><p>These are the same as before and will remain unchanged.
</p></dd>
</dl>

<ol class="enumerate">
<li> <a class="anchor" id="TextStore-StatefulSet"></a>TextStore StatefulSet


<p>The &lsquo;<samp class="samp">textstore StatefulSet</samp>&rsquo;, does require some changes:
</p>
<a class="index-entry-id" id="index-Kubernetes-Readiness-Probe"></a>
<ul class="itemize mark-bullet">
<li>For cosmetic reasons, we replace the &lsquo;<samp class="samp">serviceName</samp>&rsquo; to &ldquo;textstore-service&rdquo;. This becomes part of the hostname (e.g. <code class="code">textstore-0.textstore-service.default.svc.cluster.local</code>)
</li><li>The number of &lsquo;<samp class="samp">replicas</samp>&rsquo; starts out with the value &lsquo;<samp class="samp">3</samp>&rsquo;.
</li><li>The startup &lsquo;<samp class="samp">command</samp>&rsquo; needs to be edited to start MongoDB in ReplicaSet mode: &lsquo;<samp class="samp">[&quot;mongod&quot;, &quot;--bind_ip&quot;, &quot;0.0.0.0&quot;, &quot;--replSet&quot;, &quot;MainRepSet&quot;</samp>&rsquo; . Breaking this down:
<ul class="itemize mark-bullet">
<li>listen to all network interfaces &lsquo;<samp class="samp">--bind_ip 0.0.0.0</samp>&rsquo;
</li><li>use the specified name for the ReplicaSet &lsquo;<samp class="samp">--replSet MainRepSet</samp>&rsquo;
</li></ul>
</li><li>A <em class="emph">Readiness Probe</em> is defined. This will be used by Kubernetes to check whether the startup of a replica is ready and it can be added to the list of running replicas. Running a &ldquo;ping&rdquo; command inside the database is usually a good start for this.
</li></ul>

<p>In summary, the following yaml defines the textstore StatefulSet:
</p>
<div class="example">
<pre class="example-preformatted">---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: textstore
  labels:
    app: textstore
spec:
  serviceName: textstore-service
  replicas: 3
  selector:
    matchLabels:
      app: textstore
  template:
    metadata:
      labels:
        app: textstore
    spec:
      containers:
      - name: textstore
        image: mongo
        command: [&quot;mongod&quot;, &quot;--bind_ip&quot;, &quot;0.0.0.0&quot;, &quot;--replSet&quot;, &quot;MainRepSet&quot;]
        readinessProbe:
          exec:
            command: [&quot;mongosh&quot;, &quot;--eval&quot;, &quot;db.adminCommand({ping: 1})&quot;]
        ports:
        - containerPort: 27017
          name: mongodb-port
        volumeMounts:
        - name: textstore-data
          mountPath: /data/db
        - name: mongo-config
          mountPath: /data/configdb
  volumeClaimTemplates:
    - metadata:
        name: textstore-data
      spec:
        accessModes: [&quot;ReadWriteOnce&quot;]
        resources:
          requests: 
            storage: 10Mi
    - metadata:
        name: mongo-config
      spec:
        accessModes: [&quot;ReadWriteOnce&quot;]
        resources:
          requests: 
            storage: 5Mi
---
</pre></div>

</li><li> <a class="anchor" id="Qfapp-ConfigMap"></a>Qfapp ConfigMap


<p>Accessing the database, will require a new access string:
</p>
<div class="example">
<pre class="example-preformatted">---
apiVersion: v1
kind: ConfigMap
metadata:
  name: qfapp-config
  labels:
    data: config
data:
  textstore_host: &quot;NOTSET&quot;
  textstore_replicaset: &quot;mongodb://textstore-0.textstore-service.default.svc.cluster.local:27017,textstore-1.textstore-service.default.svc.cluster.local:27017,textstore-2.textstore-service.default.svc.cluster.local:27017/textStore?replicaSet=MainRepSet&quot;
---
</pre></div>

<p>I am not a fan of that the URLs to each member in the cluster has to be hard-coded like this ( &lsquo;<samp class="samp">textstore_replicaset</samp>&rsquo; ), since this limits the ability to scale up or down the number of replicas. Ideally, it should be as easy to change the &lsquo;<samp class="samp">spec.replicas</samp>&rsquo; for the StatefulSet and let Kubernetes re-apply. In practice, this is now made much more difficult.
</p>
</li><li> <a class="anchor" id="QFStandalone-Deployment"></a>QFStandalone Deployment


<p>As a start, the only edit to the qfstandalone deployment we make is to include the newly defined element from the ConfigMap. Specifically, the environment variable &lsquo;<samp class="samp">TEXTSTORE_HOST</samp>&rsquo; need to get its value from &lsquo;<samp class="samp">textstore_replicaset</samp>&rsquo; in the configmap.
</p>
<div class="example">
<pre class="example-preformatted">---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: qfstandalone
  labels:
    app: qfapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: qfapp
  template:
    metadata:
      labels:
        app: qfapp
    spec:
      containers:
      - name: qfstandalone
        image: mickesv/qfstandalone:version1
        ports:
        - containerPort: 3000
        env:
        - name: TEXTSTORE_HOST
          valueFrom:
            configMapKeyRef: 
              name: qfapp-config
              key: textstore_replicaset
---
</pre></div>

<p>Do note that this will not be quite sufficient to create a workable solution. Can you already now figure out why this will not be sufficient?
</p>
</li><li> <a class="anchor" id="Tasks"></a>Tasks


<ol class="enumerate" start="0">
<li> Copy the previous yaml file to a new file, to keep a record of the different steps: <code class="code">cp qfstandalone-v1-2.yaml qfstandalone-v1-3.yaml</code>

</li><li> Locate the &lsquo;<samp class="samp">textstore StatefulSet</samp>&rsquo; and replace it with the version above.

</li><li> Locate the &lsquo;<samp class="samp">QFApp ConfigMap</samp>&rsquo; and replace it with the version above.

</li><li> Locate the &lsquo;<samp class="samp">QFStandalone Deployment</samp>&rsquo; and replace it with the version above.

</li><li> Start everything: <code class="code">kubectl apply -f qfstandalone-v1-3.yaml</code>

</li><li> Wait for the replicas to come online: <code class="code">kubectl rollout status statefulset textstore --timeout=30s</code>
This may take longer than 30 seconds, so you may need to run the command a couple of times. If it <em class="emph">does</em> take longer, it is an excellent opportunity to open up Kubernetes&rsquo; dashboard and see what is going on: &lsquo;<samp class="samp">minikube dashboard &amp;</samp>&rsquo; 

</li><li> Once all three replicas are running (but not before!), it is time to initiate the replicaset in MongoDB. Run the following: <code class="code">kubectl exec -it textstore-0 -- mongosh --quiet --eval &quot;rs.initiate()&quot;</code>
This will log in to <em class="emph">one</em> of the members in the replicaset and initiate it. Sometimes, MongoDB has already figured this out, and you will receive a message &ldquo;already initialized&rdquo;. This is ok.

</li><li> Double check the status: <code class="code">kubectl exec -it textstore-0 -- mongosh --quiet --eval &quot;rs.status()&quot;</code>
One particular thing to look out for is to make sure that one of the servers has the <code class="code">stateStr: 'PRIMARY'</code> . You may have to wait a while and check again for this.

</li><li> Connect to the logs in qfstandalone (as before): <code class="code">kubectl get pods -o name | grep qfstandalone | head -1 | xargs kubectl logs -f</code>

</li><li> Connect to the web interface (e.g. with <code class="code">minikube service qfapp-service</code> ) and search for something. Keep an eye on the logs to see why it fails.
</li></ol>

<p>It appears that the current implementation of the database connection in &lsquo;<samp class="samp">simpleTextManager.js</samp>&rsquo; is trying to add too much to the environment variable. It would be nice if we were able to enter the container and edit the running application as we did before, but for reasons this is not easily done (see <a class="ref" href="#kube_002dedit">kube-edit</a> ). With a bit of elbow-grease we can at least get things to work decently (don&rsquo;t even bother trying to do some fancy development in this way).
</p>
<ol class="enumerate" start="10">
<li> Find the name of the qfstandalone pod: <code class="code">kubectl get pods -o name | grep qfstandalone</code>

</li><li> Enter into this pod: <code class="code">kubectl exec -it &lt;podname&gt; -- sh</code> (where &ldquo;podname&rdquo; is the name of the pod as found in the previous step.
Feel free to poke around at your own leisure here and see what you can find and what works. Note that in order to keep the container image small we used a very limited linux distribution as base, so there isn&rsquo;t much installed at all.

</li><li> Edit the file <code class="code">/app/src/simpleTextManager.js</code> (I&rsquo;m afraid the only editor you&rsquo;ve got is &lsquo;<samp class="samp">vi</samp>&rsquo;) . Replace line 20 with <code class="code">let connection=process.env.TEXTSTORE_HOST;</code> and save.
You should see the app restarting in the log output you attached to earlier, and if you try searching for something you should no longer get any errors.
</li></ol>

<p><strong class="strong">Summary</strong>
We have now:
</p><ol class="enumerate">
<li> Configured the simplest and unsafest possible MongoDB replicaset without any form of authentication whatsoever.
</li><li> Created a single-phase startup where everything can be deployed with a single &lsquo;<samp class="samp">kubectl apply</samp>&rsquo; command.
</li><li> Waited for parts of a deployment to come online in an orderly fashion with <code class="code">kubectl rollout status</code> and a ReadinessProbe.
</li><li> Ugly-hacked our way into a container to edit the running application code.
</li></ol>

<p><strong class="strong">Cleanup</strong>
As before, clean up your deployment: <code class="code">kubectl delete --cascade='foreground' -f qfstandalone-v1-3.yaml</code> .
</p></li></ol>

<hr>
</div>
</div>
<div class="chapter-level-extent" id="Edit-a-Container-in-a-Pod-in-a-Node-in-a-Cluster">
<div class="nav-panel">
<p>
Next: <a href="#Additional-Concepts" accesskey="n" rel="next">Additional Concepts</a>, Previous: <a href="#Scaling-the-Database" accesskey="p" rel="prev">Scaling the Database</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Edit-a-Container-in-a-Pod-in-a-Node-in-a-Cluster-1">16 Edit a Container in a Pod in a Node in a Cluster</h2>

<a class="anchor" id="kube_002dedit"></a>
<div class="example">
<pre class="example-preformatted"> _______________________________________
( So why were we not able to use a Bind )
( Mount to access the innards of the    )
( container as before?                  )
 ---------------------------------------
        o   ^__^
         o  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||
</pre></div>

<a class="index-entry-id" id="index-Bind-Mount"></a>
<p>Technically, we <em class="emph">are</em> able to do this. The problem is that Kubernetes adds an extra layer. Remember that Containers run inside Pods. So while it is relatively easy and similar to what we have done before to set up a bind mount, this will only allow files to be shared between the insides of a container and the pod it is running on. The next necessary step is to somehow create a bridge from the pod&rsquo;s file system to the host&rsquo;s file system.
</p>
<p>The first bit is similar to what we have done before: setup the container template to mount <code class="code">/app/src</code>.
</p>
<div class="example">
<pre class="example-preformatted">containers:
- name: qfstandalone
  image: mickesv/qfstandalone:version1
  volumeMounts:
  - mountPath: /app/src
    name: source-dir
</pre></div>

<a class="index-entry-id" id="index-Kubernetes-EmptyDir"></a>
<p>This is coupled with a matching <code class="code">volumes</code> statement for the pod. In the most basic, just create an empty directory inside the pod to match this volume:
</p>
<div class="example">
<pre class="example-preformatted">volumes:
- name: source-dir
  emptyDir: {}
</pre></div>

<a class="index-entry-id" id="index-Kubernetes-HostPath"></a>
<p>However, since the goal was to be able to reach the directory from the outside, we can go for the moonshot with a HostPath instead:
</p>
<div class="example">
<pre class="example-preformatted">volumes:
- name: source-dir
  hostPath:
    path: /app/src
    type: Directory
</pre></div>

<p>(The path can of course be anywhere here, it does not have to be <code class="code">/app/src</code> since that only really makes sense inside the container. However, it is good to keep it short for the next step. In fact, it would not be a bad idea to keep it under <code class="code">/tmp</code>.)
</p>
<a class="index-entry-id" id="index-Kubernetes-Node"></a>
<p>Unfortunately, this <em class="emph">still</em> does not mean that we are able to access the files. The reason for this is a Kubernetes concept which we have not discussed yet, namely that of a <em class="emph">Node</em>. A Kubernetes node can be seen as the unit that would be run on one piece of (virtual) hardware. On this node pods, volumes, etc. are deployed. <code class="code">minikube</code> is a single-node implementation of Kubernetes so there is not much more configuring to do, but if you deploy to a cloud provider you would get to decide how many nodes you want to run your application across, as well as how many volumes, pods, services, etc. that you desire.
</p>
<p>You can access the inside of the single node with <code class="code">minikube ssh</code> ; please take a moment to convince yourself that the minikube node is essentially a complete virtual machine.
</p>
<p>The bottom line is that while we are able to access the inside of the running container with a hostPath volume, <em class="emph">we are only able to do so from within the Kubernetes node</em>. Not quite what we were after, to put it mildly. It is actually worse than that, since when pods get deleted or moved over to another node, whatever was written to the hostPath directory gets left behind (hence why it would make sense to keep the mount point in <code class="code">/tmp</code> ).
</p>
<div class="example">
<pre class="example-preformatted">+------------------------------------------+
| Node                                     |
|                                          |
|  +----------------+ +----------------+   |
|  | Pod            | | Pod            |   |
|  | +------------+ | |                |   |
|  | | Container  | | |                |   |
|  | +------------+ | |                |   |
|  | +------------+ | |                |   |
|  | | Container  | | |                |   |
|  | +------------+ | |                |   |
|  +----------------+ +----------------+   |
|                                          |
+------------------------------------------+
</pre></div>

<a class="index-entry-id" id="index-Network-File-System-NFS"></a>
<p>Despite all warnings about why this is a bad idea, if we still want to access the container&rsquo;s inside, there are two options available to us. One is to define a proper volume with a PersistentVolumeClaim for the container. Of course, there is a non-trivial amount of work to set this up in Kubernetes to ensure that an already existing directory on the host computer is made available as a PersistentVolume. A middle ground is perhaps to export the directory as an NFS share (or any other type of network filesystem if you are concerned with the security issues of NFS), and mount this as the container volume.
</p>
<p>The other option is to go the other direction and mount a local directory onto the Kubernetes node, and then use a hostPath setup to propagate this mount into the container. <code class="code">minikube mount</code> is able to do this, but due to bugs this is not working at the time of writing.
</p>
<p><strong class="strong">Summary</strong>
Accessing the running code of a container in Kubernetes is difficult and there are plenty of reasons to advice against it. The recommendation is to do the development using e.g. Docker Compose and only deploy to Kubernetes as a last step when everything is tested and ship-shape. This includes subsequent debugging: There should be nothing in the containers that wasn&rsquo;t there already when the image was created, and so all debugging can and should be done locally outside of the Kubernetes deployment.
</p>
<hr>
</div>
<div class="chapter-level-extent" id="Additional-Concepts">
<div class="nav-panel">
<p>
Next: <a href="#Summary" accesskey="n" rel="next">Summary</a>, Previous: <a href="#Edit-a-Container-in-a-Pod-in-a-Node-in-a-Cluster" accesskey="p" rel="prev">Edit a Container in a Pod in a Node in a Cluster</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Additional-Concepts-1">17 Additional Concepts</h2>

<a class="index-entry-id" id="index-Kubernetes-SessionAffinity"></a>
<p>A few loose ends need to be tied up to complete this introduction to Kubernetes. First, we are finally able to solve the previous problems that we had with scaling the frontend. If you remember, the use of <code class="code">socket.io</code> meant that it was difficult to use a simple load-balancer to scale the frontend since each client-server connection relied on a socket to be kept alive for the duration. Well, one of the flags that can be given to a load-balancer service is <code class="code">spec.sessionAffinity: ClientIP</code> , which means that Kubernetes will stick all sessions originating from the same client IP to the same deployment instance. This is all that is required in order to be able to scale the number of replicas of the qfstandalone deployment.
</p>
<a class="index-entry-id" id="index-Kubernetes-Scaling"></a>
<p>One simple way to scale is to edit the <code class="code">spec.replicas</code> in the yaml file and simply re-apply it. Go ahead; start the dashboard <code class="code">minikube dashboard &amp;</code> , edit the yaml file (add the <code class="code">sessionAffinity</code> flag above while you&rsquo;re at it), and re-run <code class="code">kubectl apply -f qfstandalone-v-1-3.yaml</code> . You should see the number of deployed pods change as a consequence.
</p>
<p>You can of course also scale directly via the command line: <code class="code">kubectl scale --replicas=3 deployment/qfstandalone</code> .
</p>
<a class="index-entry-id" id="index-Kubernetes-Rollout"></a>
<a class="index-entry-id" id="index-Kubernetes-Liveness-Probes"></a>
<p>Keeping an eye on a running deployment is done with the dashboard &ndash; you can often find clues in here about what is currently going on &ndash; especially if some deployment is not rolling out as it should. If you want to programmatically keep track of the rollout status, there is the <code class="code">kubectl rollout status</code> command. Especially when you have configured Readiness Probes (as we did before) or Liveness Probes, this is a useful way to keep tabs on how the scaling operation is going. Readiness Probes should be defined to ensure that new pods are well and truly booted and ready to start working <em class="emph">before</em> Kubernetes adds them to the set of running deployments. If no Readiness Probes are defined, the pod may be expected to start serving requests before it is actually finished booting.
</p>
<p>Liveness Probes are another useful addition, since they allow Kubernetes to automatically keep track of the health of the running deployment, and you may define rules about what should happen when a pod continues to report that it is not alive (or, to be precise, continuously fails to report that it is alive).
</p>
<p>The <code class="code">kubectl rollout</code> command can also be used to manage the deployment in some more detail. Most notably, it can be used to <code class="code">pause</code> and <code class="code">resume</code> parts of the deployment.
</p>
<a class="index-entry-id" id="index-MongoDB-Authentication"></a>
<p>When we set up the MongoDB ReplicaSet we dodged the bullet of authentication. Technically, there are a number of steps involved in this that you really ought to try your hand at just because. First, the internal cluster should be told to use a specific key to communicate inside the cluster. Second, once the replicaset is up and running (or before? This used to work in one way and in a recent update it no longer works the same way), you should setup users; One admin user to manage the databases and the database cluster, and at least one regular user that clients can use e.g. when querying the database.
</p>
<a class="index-entry-id" id="index-Kubernetes-Secrets"></a>
<p>The shared key should of course not be bandied around like so much trash: If this key gets out then your database can become compromised by someone adding their own MongoDB instance to your ReplicaSet. As soon as the key is created, we should thus create a Kubernetes <em class="emph">Secret</em> out of it, and then access this secret from within the containers. This is similar to how you can use data from ConfigMaps in your containers.
</p>
<p>To summarise:
</p>
<div class="example">
<pre class="example-preformatted"># Generate and store the key as a Kubernetes Secret
openssl rand -base64 200 &gt; ./replica-set-key.txt
kubectl create secret generic mongodb-bootstrap-data --from-file=mongodb-keyfile=./replica-set-key.txt

# Add some users to the database
kubectl exec -i textstore-0 -- mongosh --quiet --eval 'db.getSiblingDB(&quot;admin&quot;).createUser({ user: &quot;main_admin&quot;, pwd: &quot;hunter2&quot;, roles: [ { role: &quot;root&quot;, db: &quot;admin&quot; } ]});'
kubectl exec -i textstore-0 -- mongosh --quiet --eval 'db.getSiblingDB(&quot;admin&quot;).auth(&quot;main_admin&quot;, &quot;hunter2&quot;); db.getSiblingDB(&quot;admin&quot;).createUser({ user: &quot;kube&quot;, pwd: &quot;kubeuser&quot;, roles: [&quot;readWriteAnyDatabase&quot;]});'
</pre></div>


<p>&hellip; and the configuration of the MongoDB StatefulSet:
</p>
<div class="example">
<pre class="example-preformatted">---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: textstore
  labels:
    app: textstore
spec:
  serviceName: textstore-service  # This becomes part of the hostname (e.g. textstore-0.textstore-service.default.svc.cluster.local)
  replicas: 3
  selector:
    matchLabels:
      app: textstore
  template:
    metadata:
      labels:
        app: textstore
        startup: textstore-wait
    spec:
      containers:
      - name: textstore
        image: mongo
        command: [&quot;mongod&quot;, &quot;--bind_ip&quot;, &quot;0.0.0.0&quot;, &quot;--replSet&quot;, &quot;MainRepSet&quot;, &quot;--auth&quot;, &quot;--clusterAuthMode&quot;, &quot;keyFile&quot;, &quot;--keyFile&quot;, &quot;/etc/secrets-volume/mongodb-keyfile&quot;, &quot;--setParameter&quot;, &quot;authenticationMechanisms=SCRAM-SHA-1&quot;]
        readinessProbe:
          exec:
            command: [&quot;mongosh&quot;, &quot;--eval&quot;, &quot;db.adminCommand({ping: 1})&quot;]
        ports:
        - containerPort: 27017
          name: mongodb-port
        volumeMounts:
        - name: textstore-data
          mountPath: /data/db
        - name: mongo-config
          mountPath: /data/configdb
        - name: secrets-volume
          readOnly: true
          mountPath: /etc/secrets-volume
      volumes:
      - name: secrets-volume
        secret:
          secretName: mongodb-bootstrap-data
          defaultMode: 256
  volumeClaimTemplates:
    - metadata:
        name: textstore-data
      spec:
        accessModes: [&quot;ReadWriteOnce&quot;]
        resources:
          requests: 
            storage: 10Mi
    - metadata:
        name: mongo-config
      spec:
        accessModes: [&quot;ReadWriteOnce&quot;]
        resources:
          requests: 
            storage: 5Mi          
---
</pre></div>

<a class="index-entry-id" id="index-Lambda-Functions"></a>
<a class="index-entry-id" id="index-Azure-Functions"></a>
<a class="index-entry-id" id="index-Azure-Durable-Functions"></a>
<p>One final trend to keep an eye on is that of <em class="emph">lambda functions</em>. They are not always called that, e.g. Microsoft refers to them as Azure Functions or Azure Durable Functions, but the gist is the same. In some ways, this is a natural extension of the microservice architecture, when even a REST API can be considered too much, and all that is needed is a way to replicate and run a function in a distributed way. Typically, the desire is to develop locally and then seamlessly decide whether to run functions within in the same process, perhaps run them on a high-performance computing unit in the same host computer (for example a graphics card), or to scale out and run an arbitrary number of replicas of the function at the cloud provider. This pattern is not always applicable, but for <em class="emph">some</em> computing tasks it really lends itself to creating a transparent and yet scalable solution.
</p>
<hr>
</div>
<div class="chapter-level-extent" id="Summary">
<div class="nav-panel">
<p>
Next: <a href="#Assignment-Build-Something" accesskey="n" rel="next">Assignment: Build Something</a>, Previous: <a href="#Additional-Concepts" accesskey="p" rel="prev">Additional Concepts</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Summary-1">18 Summary</h2>

<p>This is it! We have reached the end of the road for what I wanted to cover in this part of the course. (See <a class="ref" href="#Learning-Outcomes">Learning Outcomes</a> for a list of the relevant Learning Outcomes)  To begin with, the following concepts have been explored:
</p>
<ul class="itemize mark-bullet">
<li>Microservices as a Software Architecture Design Decision
</li><li>Principles of Microservice Architectures
</li><li>Cloud Application Architecture Patterns
</li><li>Microservices and REST APIs
</li></ul>

<p>A software architecture consists of the design decisions that underpin it. Once the decision has been taken to build the application as a collection of microservices (and the rationale for this has been captured and documented), there are a number of design decisions that follow, including how separate components in the architecture should collaborate to solve the overall task, and some design principles and business decisions are given as a consequence. To some extent, much of the remaining work is simply to instantiate these already given design decisions in the best possible way, to leverage as much business use as possible out of them.
</p>
<p>From these overall design decisions we dive deeper into more specific technologies, i.e.:
</p>
<ul class="itemize mark-bullet">
<li>Hypervisors and Lightweight Virtual Machines
</li><li>Provisioning using shell scripting
</li><li>Provisioning using dedicated provisioning tools
</li><li>Orchestration and Deployment of a complete microservice solution
</li></ul>

<p>Specifically, we use some specific tools:
</p>
<ul class="itemize mark-bullet">
<li>Docker, as a means to define a single microservice
</li><li>Vagrant and a Hypervisor, as an alternative to set up a full fledged virtual machine
</li><li>Docker Compose, to orchestrate a complete local solution
</li><li>Kubernetes, to orchestrate and deploy a solution possibly to a cloud provider
</li></ul>

<p>These technologies and tools are typical representatives of contemporary software microservice development. They are by no means alone on the market, there are plenty of other competing technologies, but with this stack and an understanding of the concepts behind the tools you are well equipped to face the future and any tool <em class="emph">du jour</em> life may throw at you.
</p>
<p>While exploring these tools, there is one key principle that have permeated every step along the way: <em class="emph">Infrastructure as Code</em> . Only by treating the infrastructure, the deployment, in the same way as the rest of an applications code-base, are we able to maintain repeatable orchestrations, where each individual part of a deployment is configuration managed and tested.
</p>
<p>In fact, this is important so let me repeat myself:
</p>
<p><em class="emph">Infrastructure is Code</em>
</p>
<p>Here&rsquo;s a bunny to help you remember:
</p>
<div class="example">
<pre class="example-preformatted">

 ________________________
( Infrastructure is Code )
 ------------------------
      o
(\/) o
(..)
c(&quot;)(&quot;)

</pre></div>

<p>The &ldquo;only&rdquo; thing remaining for You to do now is to prove that you too have learnt all this. Read on to figure out how.
</p>
<hr>
</div>
<div class="chapter-level-extent" id="Assignment-Build-Something">
<div class="nav-panel">
<p>
Next: <a href="#Concept-Index" accesskey="n" rel="next">Concept Index</a>, Previous: <a href="#Summary" accesskey="p" rel="prev">Summary</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="chapter" id="Assignment_003a-Build-Something">19 Assignment: Build Something</h2>

<a class="anchor" id="assignment_002dbuild_002dsomething"></a>
<p>It is time to put everything you have learnt so far into practice. The goal of this assignment is for you to create a microservice-based application according to the following principles:
</p>
<ol class="enumerate">
<li> The application must be deployable using Kubernetes.
</li><li> The application must consist of at least two different types of microservices
</li><li> Each microservice must implement a REST API for access
</li><li> The application must be accessible from &ldquo;the outside&rdquo; (e.g. via a web browser)
</li><li> All microservices in the application must be horizontally scalable independently from each other.
</li><li> Any microservice images required to run your application must have been pushed to docker hub so that Kubernetes may find them.
</li><li> The application must make use of some form of database running as a separate microservice.
</li><li> The database must use storage which is persistent across restarts of the deployment infrastructure.
</li><li> The database does not have to be scalable.
</li></ol>

<p>The following items shall be delivered:
</p>
<ol class="enumerate">
<li> A description of the software you have built and what it does.
</li><li> A software architecture design of your application, describing the role of each component in your system, their responsibilities, and the architecture principles (e.g. cloud architecture patterns) that are used to connect them to a functioning system. This also includes a mapping between software components and the microservices designed and built to implement the components.
</li><li> A discussion of the benefits and challenges with your architecture design. This must include a discussion about security. It must also include a discussion of what you have done or what can be done to mitigate the identified challenges.
</li><li> A link to a configuration management repository (e.g. git) where the source code of the application can be viewed. This must also include the code for your Kubernetes deployment.
</li></ol>

<p>Once delivered, <em class="emph">a meeting will be scheduled</em> where you are expected to run and explain your application and its deployment. Be prepared to answer questions about:
</p>
<ul class="itemize mark-bullet">
<li>Your software application idea
</li><li>The architecture design decisions in your application
</li><li>The business implications of these architecture decisions
</li><li>Interaction between different microservices
</li><li>Details of your deployment
</li><li>Security issues identified and/or mitigated
</li></ul>


<p>Your application:
</p><ul class="itemize mark-bullet">
<li>may implement any software idea; it may also be a copy of an already existing software.
</li><li>may be too small or trivial to actually warrant scaling; please acknowledge this and provide instructions for what needs to be pretended for the application to make sense.
</li><li>may use any programming language.
</li><li>may use a different access interface than a web browser, as long as no additional tools need to be installed on my computer.
</li><li>may use any type of database (e.g. NoSQL, SQL, Graph, etc.).
</li><li>may be deployed to a cloud provider already.
</li></ul>

<p>There is a Quiz on Canvas where you can submit your article summaries and answers to the questions.
</p>
<p><strong class="strong">NOTICE:</strong> This is a <em class="emph">marked</em> assignment that contributes to the grade on the course. Specifically, the assignment contribute to your grade on the following parts of the course:
</p><ul class="itemize mark-bullet">
<li>Cloud Provisioning and Deployment
</li><li>The Business Case for Cloud Computing
</li></ul>

<hr>
</div>
<div class="unnumbered-level-extent" id="Concept-Index">
<div class="nav-panel">
<p>
Next: <a href="#Program-Index" accesskey="n" rel="next">Program Index</a>, Previous: <a href="#Assignment-Build-Something" accesskey="p" rel="prev">Assignment: Build Something</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="unnumbered" id="Concept-Index-1">Concept Index</h2>

<div class="printindex cp-printindex">
<table class="cp-letters-header-printindex"><tr><th>Jump to: &nbsp; </th><td><a class="summary-letter-printindex" href="#Concept-Index_cp_letter-A"><b>A</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-B"><b>B</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-C"><b>C</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-D"><b>D</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-E"><b>E</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-G"><b>G</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-H"><b>H</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-I"><b>I</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-J"><b>J</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-K"><b>K</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-L"><b>L</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-M"><b>M</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-N"><b>N</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-O"><b>O</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-P"><b>P</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-R"><b>R</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-S"><b>S</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-U"><b>U</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-V"><b>V</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-X"><b>X</b></a>
 &nbsp; 
</td></tr></table>
<table class="cp-entries-printindex" border="0">
<tr><td></td><th class="entries-header-printindex">Index Entry</th><td>&nbsp;</td><th class="sections-header-printindex"> Section</th></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-A">A</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Azure-Durable-Functions">Azure Durable Functions</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Additional-Concepts">Additional Concepts</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Azure-Functions">Azure Functions</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Additional-Concepts">Additional Concepts</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-B">B</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Bind-Mount">Bind Mount</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Edit-a-Container-in-a-Pod-in-a-Node-in-a-Cluster">Edit a Container in a Pod in a Node in a Cluster</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-C">C</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Client-Server-Software-Architecture">Client Server Software Architecture</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Microservices-and-Lightweight-Containers">Microservices and Lightweight Containers</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Command_002dLine-Interface">Command-Line Interface</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Orchestration-and-Provisioning">Introduction to Orchestration and Provisioning</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Commodity-Hardware">Commodity Hardware</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Configuration-Managed-Deployments">Configuration Managed Deployments</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Orchestration-and-Provisioning">Introduction to Orchestration and Provisioning</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Configuration-Management">Configuration Management</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Orchestration-and-Provisioning">Introduction to Orchestration and Provisioning</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Container">Container</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Building-Microservices">Building Microservices</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Course-Syllabus">Course Syllabus</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Learning-Outcomes">Learning Outcomes</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-D">D</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Database-Replication">Database Replication</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Database-Scaling">Database Scaling</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Database-Sharding">Database Sharding</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Database-Scaling">Database Scaling</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Dependency-Injection">Dependency Injection</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Other-communication-means">Other communication means</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Deployment">Deployment</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Orchestration-and-Provisioning">Introduction to Orchestration and Provisioning</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Deployment-Environments">Deployment Environments</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Orchestration-and-Provisioning">Introduction to Orchestration and Provisioning</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-Bind-Mount">Docker Bind Mount</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Editing-the-Running-Application">Editing the Running Application</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-Hub">Docker Hub</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#A-Quick-Rundown-of-Docker-Terminology">A Quick Rundown of Docker Terminology</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-E">E</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Elastic-Scaling">Elastic Scaling</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Eventual-Consistency">Eventual Consistency</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Database-Scaling">Database Scaling</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Extensibility">Extensibility</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-G">G</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Goal-_002d_002d-a-Controllable-and-Repeatable-Deployment">Goal &ndash; a Controllable and Repeatable Deployment</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Orchestration-and-Provisioning">Introduction to Orchestration and Provisioning</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Governance">Governance</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Microservices-and-Lightweight-Containers">Microservices and Lightweight Containers</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-H">H</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Horizontal-Scaling">Horizontal Scaling</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-HTTP-protocol">HTTP protocol</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Communicating-Microservices-and-REST-APIs">Communicating Microservices and REST APIs</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Hypervisor">Hypervisor</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service">Not Building Microservices -- Infrastructure As A Service</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-I">I</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-IAAS-Infrastructure-As-A-Service">IAAS Infrastructure As A Service</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service">Not Building Microservices -- Infrastructure As A Service</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-IAC-Infrastructure-As-Code">IAC Infrastructure As Code</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-J">J</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-JSON-grammar">JSON grammar</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Communicating-Microservices-and-REST-APIs">Communicating Microservices and REST APIs</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-K">K</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Access-Roles">Kubernetes Access Roles</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Attach-the-Database">Attach the Database</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-ConfigMap">Kubernetes ConfigMap</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Attach-the-Database">Attach the Database</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Container">Kubernetes Container</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Kubernetes">Introduction to Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Deployment">Kubernetes Deployment</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Kubernetes">Introduction to Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-EmptyDir">Kubernetes EmptyDir</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Edit-a-Container-in-a-Pod-in-a-Node-in-a-Cluster">Edit a Container in a Pod in a Node in a Cluster</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-HostPath">Kubernetes HostPath</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Edit-a-Container-in-a-Pod-in-a-Node-in-a-Cluster">Edit a Container in a Pod in a Node in a Cluster</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Label">Kubernetes Label</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Kubernetes">Introduction to Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Liveness-Probes">Kubernetes Liveness Probes</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Additional-Concepts">Additional Concepts</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Node">Kubernetes Node</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Edit-a-Container-in-a-Pod-in-a-Node-in-a-Cluster">Edit a Container in a Pod in a Node in a Cluster</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-NodePort">Kubernetes NodePort</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Get-Started-with-Kubernetes">Get Started with Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Persistent-Storage">Kubernetes Persistent Storage</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Kubernetes">Introduction to Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Persistent-Volume">Kubernetes Persistent Volume</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Kubernetes">Introduction to Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Persistent-Volume-Claim">Kubernetes Persistent Volume Claim</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Kubernetes">Introduction to Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Persistent-VolumeClaim-Templates">Kubernetes Persistent VolumeClaim Templates</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Attach-the-Database">Attach the Database</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Pod">Kubernetes Pod</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Kubernetes">Introduction to Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Readiness-Probe">Kubernetes Readiness Probe</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Setting-up-a-MongoDB-ReplicaSet-in-Kubernetes">Setting up a MongoDB ReplicaSet in Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-ReplicaSet">Kubernetes ReplicaSet</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Get-Started-with-Kubernetes">Get Started with Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Rollout">Kubernetes Rollout</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Additional-Concepts">Additional Concepts</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Scaling">Kubernetes Scaling</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Additional-Concepts">Additional Concepts</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Secrets">Kubernetes Secrets</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Additional-Concepts">Additional Concepts</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Service">Kubernetes Service</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Kubernetes">Introduction to Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-SessionAffinity">Kubernetes SessionAffinity</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Additional-Concepts">Additional Concepts</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-StatefulSet">Kubernetes StatefulSet</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Attach-the-Database">Attach the Database</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Volume">Kubernetes Volume</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Kubernetes">Introduction to Kubernetes</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-L">L</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Lambda-Functions">Lambda Functions</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Additional-Concepts">Additional Concepts</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Layered-Architecture-Style">Layered Architecture Style</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Communicating-Microservices-and-REST-APIs">Communicating Microservices and REST APIs</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Learning-Outcomes">Learning Outcomes</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Learning-Outcomes">Learning Outcomes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Load-Balancer">Load Balancer</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Scaling-the-Deployment">Scaling the Deployment</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-M">M</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Madness">Madness</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Database-Scaling">Database Scaling</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Maintainability">Maintainability</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-MapReduce">MapReduce</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Cloud-Architecture-Patterns">Cloud Architecture Patterns</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Metered-Billing">Metered Billing</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Microservice-Architecture">Microservice Architecture</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Microservices-and-Lightweight-Containers">Microservices and Lightweight Containers</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-MongoDB-Authentication">MongoDB Authentication</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Additional-Concepts">Additional Concepts</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-MongoDB-ReplicaSet">MongoDB ReplicaSet</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#MongoDB-ReplicaSet">MongoDB ReplicaSet</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Multitenancy">Multitenancy</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-N">N</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Network-File-System-NFS">Network File System NFS</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Edit-a-Container-in-a-Pod-in-a-Node-in-a-Cluster">Edit a Container in a Pod in a Node in a Cluster</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Network-Socket">Network Socket</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Communicating-Microservices-and-REST-APIs">Communicating Microservices and REST APIs</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-NoSQL">NoSQL</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Database-Scaling">Database Scaling</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-O">O</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Orchestration">Orchestration</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Orchestration">Orchestration</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-P">P</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Platform-Service-Ecosystem">Platform Service Ecosystem</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Pooled-Resources">Pooled Resources</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Project-Gutenberg">Project Gutenberg</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-the-QuoteFinder-application">Introducing the QuoteFinder application</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Provisioning">Provisioning</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Provisioning-your-Virtual-Machine">Provisioning your Virtual Machine</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Provisioning-1">Provisioning</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Provisioning">Provisioning</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-R">R</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Redeployment">Redeployment</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Orchestration-and-Provisioning">Introduction to Orchestration and Provisioning</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Reliability">Reliability</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Repeatable-Deployment">Repeatable Deployment</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Orchestration-and-Provisioning">Introduction to Orchestration and Provisioning</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Responsibility_002dDriven-Design">Responsibility-Driven Design</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Building-Microservices">Building Microservices</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-REST-API">REST API</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Communicating-Microservices-and-REST-APIs">Communicating Microservices and REST APIs</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-RPC-Remote-Procedure-Call">RPC Remote Procedure Call</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Communicating-Microservices-and-REST-APIs">Communicating Microservices and REST APIs</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-S">S</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Scalability">Scalability</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Sharding-Architectures">Sharding Architectures</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Database-Scaling">Database Scaling</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Software-Architecture-Conceptual-View">Software Architecture Conceptual View</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Microservices-and-Lightweight-Containers">Microservices and Lightweight Containers</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Software-Architecture-Execution-View">Software Architecture Execution View</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Microservices-and-Lightweight-Containers">Microservices and Lightweight Containers</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Software-Architecture-Module-View">Software Architecture Module View</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Microservices-and-Lightweight-Containers">Microservices and Lightweight Containers</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-U">U</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Ultimate-Goal-_002d_002d-Deploy-Application-to-a-Cloud-Server">Ultimate Goal &ndash; Deploy Application to a Cloud Server</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Orchestration-and-Provisioning">Introduction to Orchestration and Provisioning</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-V">V</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Vertical-Scaling">Vertical Scaling</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Virtual-Machine">Virtual Machine</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service">Not Building Microservices -- Infrastructure As A Service</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Virtualisation">Virtualisation</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Principles-of-Microservice-Architectures">Principles of Microservice Architectures</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Concept-Index_cp_letter-X">X</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-XML">XML</a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Communicating-Microservices-and-REST-APIs">Communicating Microservices and REST APIs</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
</table>
<table class="cp-letters-footer-printindex"><tr><th>Jump to: &nbsp; </th><td><a class="summary-letter-printindex" href="#Concept-Index_cp_letter-A"><b>A</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-B"><b>B</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-C"><b>C</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-D"><b>D</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-E"><b>E</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-G"><b>G</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-H"><b>H</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-I"><b>I</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-J"><b>J</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-K"><b>K</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-L"><b>L</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-M"><b>M</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-N"><b>N</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-O"><b>O</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-P"><b>P</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-R"><b>R</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-S"><b>S</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-U"><b>U</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-V"><b>V</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Concept-Index_cp_letter-X"><b>X</b></a>
 &nbsp; 
</td></tr></table>
</div>

<hr>
</div>
<div class="unnumbered-level-extent" id="Program-Index">
<div class="nav-panel">
<p>
Next: <a href="#Files-and-Data-Types-Index" accesskey="n" rel="next">Files and Data Types Index</a>, Previous: <a href="#Concept-Index" accesskey="p" rel="prev">Concept Index</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="unnumbered" id="Program-Index-1">Program Index</h2>

<div class="printindex pg-printindex">
<table class="pg-letters-header-printindex"><tr><th>Jump to: &nbsp; </th><td><a class="summary-letter-printindex" href="#Program-Index_pg_letter-A"><b>A</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-C"><b>C</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-D"><b>D</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-E"><b>E</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-G"><b>G</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-H"><b>H</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-I"><b>I</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-J"><b>J</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-K"><b>K</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-L"><b>L</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-M"><b>M</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-N"><b>N</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-P"><b>P</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-Q"><b>Q</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-R"><b>R</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-S"><b>S</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-T"><b>T</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-U"><b>U</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-V"><b>V</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-X"><b>X</b></a>
 &nbsp; 
</td></tr></table>
<table class="pg-entries-printindex" border="0">
<tr><td></td><th class="entries-header-printindex">Index Entry</th><td>&nbsp;</td><th class="sections-header-printindex"> Section</th></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-A">A</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Ansible"><code>Ansible</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Provisioning">Provisioning</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-C">C</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Chef"><code>Chef</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Provisioning">Provisioning</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-chroot"><code>chroot</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Building-Microservices">Building Microservices</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-D">D</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-diff"><code>diff</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-Version-3-of-the-QuoteFinder-app">Introducing Version 3 of the QuoteFinder app</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker"><code>Docker</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Building-Microservices">Building Microservices</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-Compose"><code>Docker Compose</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Compose">Docker Compose</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-Hub-1"><code>Docker Hub</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#A-Quick-Rundown-of-Docker-Terminology">A Quick Rundown of Docker Terminology</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-E">E</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Express"><code>Express</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-the-QuoteFinder-application">Introducing the QuoteFinder application</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-G">G</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-grep"><code>grep</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Get-Started-with-Kubernetes">Get Started with Kubernetes</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-H">H</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Hadoop"><code>Hadoop</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Cloud-Orchestration">Cloud Orchestration</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Homebrew"><code>Homebrew</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Install-relevant-software">Install relevant software</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Hyper_002dV"><code>Hyper-V</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service">Not Building Microservices -- Infrastructure As A Service</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-I">I</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-info"><code>info</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-J">J</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Jade"><code>Jade</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-the-QuoteFinder-application">Introducing the QuoteFinder application</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-K">K</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-kubectl"><code>kubectl</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Get-Started-with-Kubernetes">Get Started with Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes"><code>Kubernetes</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Cloud-Orchestration">Cloud Orchestration</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-1"><code>Kubernetes</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-Kubernetes">Introduction to Kubernetes</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-L">L</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-less"><code>less</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-LXC-Linux-Containers"><code>LXC Linux Containers</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Building-Microservices">Building Microservices</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-M">M</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-man"><code>man</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-MongoDB"><code>MongoDB</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-the-QuoteFinder-application">Introducing the QuoteFinder application</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-more"><code>more</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-N">N</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-node_002ejs"><code>node.js</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-the-QuoteFinder-application">Introducing the QuoteFinder application</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-nodemon"><code>nodemon</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-P">P</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Parallells"><code>Parallells</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service">Not Building Microservices -- Infrastructure As A Service</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Podman"><code>Podman</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Building-Microservices">Building Microservices</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Pug"><code>Pug</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-the-QuoteFinder-application">Introducing the QuoteFinder application</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Puppet"><code>Puppet</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Provisioning">Provisioning</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-Q">Q</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Qemu"><code>Qemu</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service">Not Building Microservices -- Infrastructure As A Service</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-QFStandalone"><code>QFStandalone</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-the-QuoteFinder-application">Introducing the QuoteFinder application</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-QuoteFinder-Version-2"><code>QuoteFinder Version 2</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-Version-2-of-the-QuoteFinder-app">Introducing Version 2 of the QuoteFinder app</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-QuoteFinder-Version1"><code>QuoteFinder Version1</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-the-QuoteFinder-application">Introducing the QuoteFinder application</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-R">R</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Redis"><code>Redis</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Other-communication-means">Other communication means</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Redis-1"><code>Redis</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-Version-2-of-the-QuoteFinder-app">Introducing Version 2 of the QuoteFinder app</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-RSMQ"><code>RSMQ</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-Version-2-of-the-QuoteFinder-app">Introducing Version 2 of the QuoteFinder app</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-S">S</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-SaltStack"><code>SaltStack</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Cloud-Orchestration">Cloud Orchestration</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-socket_002eio"><code>socket.io</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-the-QuoteFinder-application">Introducing the QuoteFinder application</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-T">T</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Terraform"><code>Terraform</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Cloud-Orchestration">Cloud Orchestration</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-U">U</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Unix-pipe-_007c"><code>Unix pipe |</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Get-Started-with-Kubernetes">Get Started with Kubernetes</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-V">V</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Vagrant"><code>Vagrant</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Provisioning-your-Virtual-Machine">Provisioning your Virtual Machine</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Virtualbox"><code>Virtualbox</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service">Not Building Microservices -- Infrastructure As A Service</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-VMWare"><code>VMWare</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Not-Building-Microservices-_002d_002d-Infrastructure-As-A-Service">Not Building Microservices -- Infrastructure As A Service</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Program-Index_pg_letter-X">X</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-xargs"><code>xargs</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Get-Started-with-Kubernetes">Get Started with Kubernetes</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
</table>
<table class="pg-letters-footer-printindex"><tr><th>Jump to: &nbsp; </th><td><a class="summary-letter-printindex" href="#Program-Index_pg_letter-A"><b>A</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-C"><b>C</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-D"><b>D</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-E"><b>E</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-G"><b>G</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-H"><b>H</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-I"><b>I</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-J"><b>J</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-K"><b>K</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-L"><b>L</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-M"><b>M</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-N"><b>N</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-P"><b>P</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-Q"><b>Q</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-R"><b>R</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-S"><b>S</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-T"><b>T</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-U"><b>U</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-V"><b>V</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Program-Index_pg_letter-X"><b>X</b></a>
 &nbsp; 
</td></tr></table>
</div>

<hr>
</div>
<div class="unnumbered-level-extent" id="Files-and-Data-Types-Index">
<div class="nav-panel">
<p>
Next: <a href="#Functions-and-Commands-Index" accesskey="n" rel="next">Functions and Commands Index</a>, Previous: <a href="#Program-Index" accesskey="p" rel="prev">Program Index</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="unnumbered" id="Files-and-Data-Types-Index-1">Files and Data Types Index</h2>

<div class="printindex tp-printindex">
<table class="tp-letters-header-printindex"><tr><th>Jump to: &nbsp; </th><td><a class="summary-letter-printindex" href="#Files-and-Data-Types-Index_tp_letter-D"><b>D</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Files-and-Data-Types-Index_tp_letter-K"><b>K</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Files-and-Data-Types-Index_tp_letter-M"><b>M</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Files-and-Data-Types-Index_tp_letter-V"><b>V</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Files-and-Data-Types-Index_tp_letter-Y"><b>Y</b></a>
 &nbsp; 
</td></tr></table>
<table class="tp-entries-printindex" border="0">
<tr><td></td><th class="entries-header-printindex">Index Entry</th><td>&nbsp;</td><th class="sections-header-printindex"> Section</th></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Files-and-Data-Types-Index_tp_letter-D">D</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Dockerfile"><code>Dockerfile</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#A-Quick-Rundown-of-Docker-Terminology">A Quick Rundown of Docker Terminology</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Files-and-Data-Types-Index_tp_letter-K">K</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-Cluster-IP"><code>Kubernetes Cluster IP</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Get-Started-with-Kubernetes">Get Started with Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-External-IP"><code>Kubernetes External IP</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Get-Started-with-Kubernetes">Get Started with Kubernetes</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Kubernetes-volumeClaimTemplates"><code>Kubernetes volumeClaimTemplates</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Attach-the-Database">Attach the Database</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Files-and-Data-Types-Index_tp_letter-M">M</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-MQTT"><code>MQTT</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Other-communication-means">Other communication means</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Files-and-Data-Types-Index_tp_letter-V">V</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Vagrantfile"><code>Vagrantfile</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Provisioning-your-Virtual-Machine">Provisioning your Virtual Machine</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Files-and-Data-Types-Index_tp_letter-Y">Y</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-YAML"><code>YAML</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introduction-to-YAML-and-Docker_002dComposeyml">Introduction to YAML and Docker-Composeyml</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
</table>
<table class="tp-letters-footer-printindex"><tr><th>Jump to: &nbsp; </th><td><a class="summary-letter-printindex" href="#Files-and-Data-Types-Index_tp_letter-D"><b>D</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Files-and-Data-Types-Index_tp_letter-K"><b>K</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Files-and-Data-Types-Index_tp_letter-M"><b>M</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Files-and-Data-Types-Index_tp_letter-V"><b>V</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Files-and-Data-Types-Index_tp_letter-Y"><b>Y</b></a>
 &nbsp; 
</td></tr></table>
</div>

<hr>
</div>
<div class="unnumbered-level-extent" id="Functions-and-Commands-Index">
<div class="nav-panel">
<p>
Previous: <a href="#Files-and-Data-Types-Index" accesskey="p" rel="prev">Files and Data Types Index</a>, Up: <a href="#Top" accesskey="u" rel="up">Provisioning and Deployment</a> &nbsp; [<a href="#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<h2 class="unnumbered" id="Functions-and-Commands-Index-1">Functions and Commands Index</h2>

<div class="printindex fn-printindex">
<table class="fn-letters-header-printindex"><tr><th>Jump to: &nbsp; </th><td><a class="summary-letter-printindex" href="#Functions-and-Commands-Index_fn_letter-D"><b>D</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Functions-and-Commands-Index_fn_letter-J"><b>J</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Functions-and-Commands-Index_fn_letter-Y"><b>Y</b></a>
 &nbsp; 
</td></tr></table>
<table class="fn-entries-printindex" border="0">
<tr><td></td><th class="entries-header-printindex">Index Entry</th><td>&nbsp;</td><th class="sections-header-printindex"> Section</th></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Functions-and-Commands-Index_fn_letter-D">D</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-ADD"><code>Docker ADD</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-build"><code>docker build</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-CMD"><code>Docker CMD</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-Compose-deploy"><code>Docker Compose deploy</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Scaling-the-Deployment">Scaling the Deployment</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-Compose-replicas"><code>Docker Compose replicas</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Scaling-the-Deployment">Scaling the Deployment</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-container"><code>docker container</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-container-ls"><code>docker container ls</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-container-ps"><code>docker container ps</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-container-rm"><code>docker container rm</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-container-run"><code>docker container run</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-container-start"><code>docker container start</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-container-stop"><code>docker container stop</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-COPY"><code>Docker COPY</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-ENTRYPOINT"><code>Docker ENTRYPOINT</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-ENV"><code>Docker ENV</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-EXPOSE"><code>Docker EXPOSE</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-FROM"><code>Docker FROM</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-image"><code>docker image</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-image-build"><code>docker image build</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-image-ls"><code>docker image ls</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-image-rm"><code>docker image rm</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-ps"><code>docker ps</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-RUN"><code>Docker RUN</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-docker-run"><code>docker run</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Commands">Docker Commands</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-USER"><code>Docker USER</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-VOLUME"><code>Docker VOLUME</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-Docker-WORKDIR"><code>Docker WORKDIR</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Dockerfile">Dockerfile</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Functions-and-Commands-Index_fn_letter-J">J</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-JavaScript-Promise"><code>JavaScript Promise</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Introducing-the-QuoteFinder-application">Introducing the QuoteFinder application</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
<tr><th id="Functions-and-Commands-Index_fn_letter-Y">Y</th><td></td><td></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-YAML-Ansible"><code>YAML Ansible</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Provisioning">Provisioning</a></td></tr>
<tr><td></td><td class="printindex-index-entry"><a href="#index-YAML-Docker-Compose"><code>YAML Docker Compose</code></a>:</td><td>&nbsp;</td><td class="printindex-index-section"><a href="#Docker-Compose">Docker Compose</a></td></tr>
<tr><td colspan="4"> <hr></td></tr>
</table>
<table class="fn-letters-footer-printindex"><tr><th>Jump to: &nbsp; </th><td><a class="summary-letter-printindex" href="#Functions-and-Commands-Index_fn_letter-D"><b>D</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Functions-and-Commands-Index_fn_letter-J"><b>J</b></a>
 &nbsp; 
<a class="summary-letter-printindex" href="#Functions-and-Commands-Index_fn_letter-Y"><b>Y</b></a>
 &nbsp; 
</td></tr></table>
</div>

</div>
</div>



</body>
</html>
